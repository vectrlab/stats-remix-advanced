<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Statistics Reference | Advanced Statistics Remix</title>
  <meta name="description" content="A textbook for advanced statistics" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Statistics Reference | Advanced Statistics Remix" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A textbook for advanced statistics" />
  <meta name="github-repo" content="vectrlab/stat-course-pack" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Statistics Reference | Advanced Statistics Remix" />
  
  <meta name="twitter:description" content="A textbook for advanced statistics" />
  

<meta name="author" content="David Schuster" />


<meta name="date" content="2021-11-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="factorial-analysis-of-variance-anova.html"/>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Course Pack for Statistics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this Book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#attribution"><i class="fa fa-check"></i>Attribution</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="statistics-for-research.html"><a href="statistics-for-research.html"><i class="fa fa-check"></i><b>1</b> Statistics for Research</a>
<ul>
<li class="chapter" data-level="1.1" data-path="statistics-for-research.html"><a href="statistics-for-research.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="statistics-for-research.html"><a href="statistics-for-research.html#measurement"><i class="fa fa-check"></i><b>1.2</b> Measurement</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="statistics-for-research.html"><a href="statistics-for-research.html#level-of-measurement"><i class="fa fa-check"></i><b>1.2.1</b> Level of Measurement</a></li>
<li class="chapter" data-level="1.2.2" data-path="statistics-for-research.html"><a href="statistics-for-research.html#continuous-or-discrete"><i class="fa fa-check"></i><b>1.2.2</b> Continuous or Discrete</a></li>
<li class="chapter" data-level="1.2.3" data-path="statistics-for-research.html"><a href="statistics-for-research.html#qualitative-or-quantitative"><i class="fa fa-check"></i><b>1.2.3</b> Qualitative or Quantitative</a></li>
<li class="chapter" data-level="1.2.4" data-path="statistics-for-research.html"><a href="statistics-for-research.html#distribution-a-collection-of-our-observations"><i class="fa fa-check"></i><b>1.2.4</b> Distribution: A collection of our observations</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="statistics-for-research.html"><a href="statistics-for-research.html#descriptive-statistics-summarizing-our-observations"><i class="fa fa-check"></i><b>1.3</b> Descriptive Statistics: Summarizing our observations</a></li>
<li class="chapter" data-level="1.4" data-path="statistics-for-research.html"><a href="statistics-for-research.html#inferential-statistics-generalizing-from-our-observations"><i class="fa fa-check"></i><b>1.4</b> Inferential Statistics: Generalizing from our observations</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="statistics-for-research.html"><a href="statistics-for-research.html#populations-and-samples-who-or-what-the-research-is-about"><i class="fa fa-check"></i><b>1.4.1</b> Populations and Samples: Who (or what) the research is about</a></li>
<li class="chapter" data-level="1.4.2" data-path="statistics-for-research.html"><a href="statistics-for-research.html#constructs-provide-the-context"><i class="fa fa-check"></i><b>1.4.2</b> Constructs provide the context</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="statistics-for-research.html"><a href="statistics-for-research.html#the-cautionary-tale-of-simpsons-paradox"><i class="fa fa-check"></i><b>1.5</b> The cautionary tale of Simpson’s paradox</a></li>
<li class="chapter" data-level="1.6" data-path="statistics-for-research.html"><a href="statistics-for-research.html#studydesign"><i class="fa fa-check"></i><b>1.6</b> A brief introduction to research design</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="statistics-for-research.html"><a href="statistics-for-research.html#some-thoughts-about-psychological-measurement"><i class="fa fa-check"></i><b>1.6.1</b> Some thoughts about psychological measurement</a></li>
<li class="chapter" data-level="1.6.2" data-path="statistics-for-research.html"><a href="statistics-for-research.html#operationalisation-defining-your-measurement"><i class="fa fa-check"></i><b>1.6.2</b> Operationalisation: defining your measurement</a></li>
<li class="chapter" data-level="1.6.3" data-path="statistics-for-research.html"><a href="statistics-for-research.html#ivdv"><i class="fa fa-check"></i><b>1.6.3</b> The “role” of variables: predictors and outcomes</a></li>
<li class="chapter" data-level="1.6.4" data-path="statistics-for-research.html"><a href="statistics-for-research.html#researchdesigns"><i class="fa fa-check"></i><b>1.6.4</b> Experimental and non-experimental research</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="statistics-for-research.html"><a href="statistics-for-research.html#causality-research-and-statistics"><i class="fa fa-check"></i><b>1.7</b> Causality, Research, and Statistics</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="statistics-for-research.html"><a href="statistics-for-research.html#experimental-quasi-experimental-and-non-experimental-studies"><i class="fa fa-check"></i><b>1.7.1</b> Experimental, Quasi-Experimental, and Non-Experimental Studies</a></li>
<li class="chapter" data-level="1.7.2" data-path="statistics-for-research.html"><a href="statistics-for-research.html#demonstrating-causality"><i class="fa fa-check"></i><b>1.7.2</b> Demonstrating Causality</a></li>
<li class="chapter" data-level="1.7.3" data-path="statistics-for-research.html"><a href="statistics-for-research.html#statistics-and-causality"><i class="fa fa-check"></i><b>1.7.3</b> Statistics and Causality</a></li>
<li class="chapter" data-level="1.7.4" data-path="statistics-for-research.html"><a href="statistics-for-research.html#validity-and-reliability"><i class="fa fa-check"></i><b>1.7.4</b> Validity and Reliability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introR.html"><a href="introR.html"><i class="fa fa-check"></i><b>2</b> Getting started with R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introR.html"><a href="introR.html#videos"><i class="fa fa-check"></i><b>2.1</b> Videos</a></li>
<li class="chapter" data-level="2.2" data-path="introR.html"><a href="introR.html#introduction-1"><i class="fa fa-check"></i><b>2.2</b> Introduction</a></li>
<li class="chapter" data-level="2.3" data-path="introR.html"><a href="introR.html#gettingR"><i class="fa fa-check"></i><b>2.3</b> Installing R</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introR.html"><a href="introR.html#installing-r-on-a-windows-computer"><i class="fa fa-check"></i><b>2.3.1</b> Installing R on a Windows computer</a></li>
<li class="chapter" data-level="2.3.2" data-path="introR.html"><a href="introR.html#installing-r-on-a-mac"><i class="fa fa-check"></i><b>2.3.2</b> Installing R on a Mac</a></li>
<li class="chapter" data-level="2.3.3" data-path="introR.html"><a href="introR.html#installing-r-on-a-linux-computer"><i class="fa fa-check"></i><b>2.3.3</b> Installing R on a Linux computer</a></li>
<li class="chapter" data-level="2.3.4" data-path="introR.html"><a href="introR.html#installingrstudio"><i class="fa fa-check"></i><b>2.3.4</b> Downloading and installing RStudio</a></li>
<li class="chapter" data-level="2.3.5" data-path="introR.html"><a href="introR.html#startingR"><i class="fa fa-check"></i><b>2.3.5</b> Starting up R</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introR.html"><a href="introR.html#firstcommand"><i class="fa fa-check"></i><b>2.4</b> Typing commands at the R console</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introR.html"><a href="introR.html#an-important-digression-about-formatting"><i class="fa fa-check"></i><b>2.4.1</b> An important digression about formatting</a></li>
<li class="chapter" data-level="2.4.2" data-path="introR.html"><a href="introR.html#be-very-careful-to-avoid-typos"><i class="fa fa-check"></i><b>2.4.2</b> Be very careful to avoid typos</a></li>
<li class="chapter" data-level="2.4.3" data-path="introR.html"><a href="introR.html#r-is-a-bit-flexible-with-spacing"><i class="fa fa-check"></i><b>2.4.3</b> R is (a bit) flexible with spacing</a></li>
<li class="chapter" data-level="2.4.4" data-path="introR.html"><a href="introR.html#r-can-sometimes-tell-that-youre-not-finished-yet-but-not-often"><i class="fa fa-check"></i><b>2.4.4</b> R can sometimes tell that you’re not finished yet (but not often)</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introR.html"><a href="introR.html#arithmetic"><i class="fa fa-check"></i><b>2.5</b> Doing simple calculations with R</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="introR.html"><a href="introR.html#adding-subtracting-multiplying-and-dividing"><i class="fa fa-check"></i><b>2.5.1</b> Adding, subtracting, multiplying and dividing</a></li>
<li class="chapter" data-level="2.5.2" data-path="introR.html"><a href="introR.html#taking-powers"><i class="fa fa-check"></i><b>2.5.2</b> Taking powers</a></li>
<li class="chapter" data-level="2.5.3" data-path="introR.html"><a href="introR.html#bedmas"><i class="fa fa-check"></i><b>2.5.3</b> Doing calculations in the right order</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="introR.html"><a href="introR.html#assign"><i class="fa fa-check"></i><b>2.6</b> Storing a number as a variable</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introR.html"><a href="introR.html#variable-assignment-using---and--"><i class="fa fa-check"></i><b>2.6.1</b> Variable assignment using <code>&lt;-</code> and <code>-&gt;</code></a></li>
<li class="chapter" data-level="2.6.2" data-path="introR.html"><a href="introR.html#doing-calculations-using-variables"><i class="fa fa-check"></i><b>2.6.2</b> Doing calculations using variables</a></li>
<li class="chapter" data-level="2.6.3" data-path="introR.html"><a href="introR.html#rules-and-conventions-for-naming-variables"><i class="fa fa-check"></i><b>2.6.3</b> Rules and conventions for naming variables</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introR.html"><a href="introR.html#usingfunctions"><i class="fa fa-check"></i><b>2.7</b> Using functions to do calculations</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="introR.html"><a href="introR.html#functionarguments"><i class="fa fa-check"></i><b>2.7.1</b> Function arguments, their names and their defaults</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="introR.html"><a href="introR.html#RStudio1"><i class="fa fa-check"></i><b>2.8</b> Letting RStudio help you with your commands</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="introR.html"><a href="introR.html#autocomplete-using-tab"><i class="fa fa-check"></i><b>2.8.1</b> Autocomplete using “tab”</a></li>
<li class="chapter" data-level="2.8.2" data-path="introR.html"><a href="introR.html#browsing-your-command-history"><i class="fa fa-check"></i><b>2.8.2</b> Browsing your command history</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="introR.html"><a href="introR.html#vectors"><i class="fa fa-check"></i><b>2.9</b> Storing many numbers as a vector</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="introR.html"><a href="introR.html#creating-a-vector"><i class="fa fa-check"></i><b>2.9.1</b> Creating a vector</a></li>
<li class="chapter" data-level="2.9.2" data-path="introR.html"><a href="introR.html#a-handy-digression"><i class="fa fa-check"></i><b>2.9.2</b> A handy digression</a></li>
<li class="chapter" data-level="2.9.3" data-path="introR.html"><a href="introR.html#vectorsubset"><i class="fa fa-check"></i><b>2.9.3</b> Getting information out of vectors</a></li>
<li class="chapter" data-level="2.9.4" data-path="introR.html"><a href="introR.html#altering-the-elements-of-a-vector"><i class="fa fa-check"></i><b>2.9.4</b> Altering the elements of a vector</a></li>
<li class="chapter" data-level="2.9.5" data-path="introR.html"><a href="introR.html#veclength"><i class="fa fa-check"></i><b>2.9.5</b> Useful things to know about vectors</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="introR.html"><a href="introR.html#text"><i class="fa fa-check"></i><b>2.10</b> Storing text data</a>
<ul>
<li class="chapter" data-level="2.10.1" data-path="introR.html"><a href="introR.html#simpletext"><i class="fa fa-check"></i><b>2.10.1</b> Working with text</a></li>
</ul></li>
<li class="chapter" data-level="2.11" data-path="introR.html"><a href="introR.html#logicals"><i class="fa fa-check"></i><b>2.11</b> Storing “true or false” data</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="introR.html"><a href="introR.html#assessing-mathematical-truths"><i class="fa fa-check"></i><b>2.11.1</b> Assessing mathematical truths</a></li>
<li class="chapter" data-level="2.11.2" data-path="introR.html"><a href="introR.html#logical-operations"><i class="fa fa-check"></i><b>2.11.2</b> Logical operations</a></li>
<li class="chapter" data-level="2.11.3" data-path="introR.html"><a href="introR.html#storing-and-using-logical-data"><i class="fa fa-check"></i><b>2.11.3</b> Storing and using logical data</a></li>
<li class="chapter" data-level="2.11.4" data-path="introR.html"><a href="introR.html#vectors-of-logicals"><i class="fa fa-check"></i><b>2.11.4</b> Vectors of logicals</a></li>
<li class="chapter" data-level="2.11.5" data-path="introR.html"><a href="introR.html#logictext"><i class="fa fa-check"></i><b>2.11.5</b> Applying logical operation to text</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="introR.html"><a href="introR.html#indexing"><i class="fa fa-check"></i><b>2.12</b> Indexing vectors</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="introR.html"><a href="introR.html#extracting-multiple-elements"><i class="fa fa-check"></i><b>2.12.1</b> Extracting multiple elements</a></li>
<li class="chapter" data-level="2.12.2" data-path="introR.html"><a href="introR.html#logical-indexing"><i class="fa fa-check"></i><b>2.12.2</b> Logical indexing</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="introR.html"><a href="introR.html#quitting-r"><i class="fa fa-check"></i><b>2.13</b> Quitting R</a></li>
<li class="chapter" data-level="2.14" data-path="introR.html"><a href="introR.html#summary"><i class="fa fa-check"></i><b>2.14</b> Summary</a></li>
<li class="chapter" data-level="2.15" data-path="introR.html"><a href="introR.html#mechanics"><i class="fa fa-check"></i><b>2.15</b> Additional R concepts</a></li>
<li class="chapter" data-level="2.16" data-path="introR.html"><a href="introR.html#comments"><i class="fa fa-check"></i><b>2.16</b> Using comments</a></li>
<li class="chapter" data-level="2.17" data-path="introR.html"><a href="introR.html#packageinstall"><i class="fa fa-check"></i><b>2.17</b> Installing and loading packages</a>
<ul>
<li class="chapter" data-level="2.17.1" data-path="introR.html"><a href="introR.html#the-package-panel-in-rstudio"><i class="fa fa-check"></i><b>2.17.1</b> The package panel in RStudio</a></li>
<li class="chapter" data-level="2.17.2" data-path="introR.html"><a href="introR.html#packageload"><i class="fa fa-check"></i><b>2.17.2</b> Loading a package</a></li>
<li class="chapter" data-level="2.17.3" data-path="introR.html"><a href="introR.html#packageunload"><i class="fa fa-check"></i><b>2.17.3</b> Unloading a package</a></li>
<li class="chapter" data-level="2.17.4" data-path="introR.html"><a href="introR.html#a-few-extra-comments"><i class="fa fa-check"></i><b>2.17.4</b> A few extra comments</a></li>
<li class="chapter" data-level="2.17.5" data-path="introR.html"><a href="introR.html#downloading-new-packages"><i class="fa fa-check"></i><b>2.17.5</b> Downloading new packages</a></li>
<li class="chapter" data-level="2.17.6" data-path="introR.html"><a href="introR.html#updating-r-and-r-packages"><i class="fa fa-check"></i><b>2.17.6</b> Updating R and R packages</a></li>
<li class="chapter" data-level="2.17.7" data-path="introR.html"><a href="introR.html#what-packages-does-this-book-use"><i class="fa fa-check"></i><b>2.17.7</b> What packages does this book use?</a></li>
</ul></li>
<li class="chapter" data-level="2.18" data-path="introR.html"><a href="introR.html#workspace"><i class="fa fa-check"></i><b>2.18</b> Managing the workspace</a>
<ul>
<li class="chapter" data-level="2.18.1" data-path="introR.html"><a href="introR.html#listing-the-contents-of-the-workspace"><i class="fa fa-check"></i><b>2.18.1</b> Listing the contents of the workspace</a></li>
<li class="chapter" data-level="2.18.2" data-path="introR.html"><a href="introR.html#removing-variables-from-the-workspace"><i class="fa fa-check"></i><b>2.18.2</b> Removing variables from the workspace</a></li>
</ul></li>
<li class="chapter" data-level="2.19" data-path="introR.html"><a href="introR.html#navigation"><i class="fa fa-check"></i><b>2.19</b> Navigating the file system</a>
<ul>
<li class="chapter" data-level="2.19.1" data-path="introR.html"><a href="introR.html#filesystem"><i class="fa fa-check"></i><b>2.19.1</b> The file system itself</a></li>
<li class="chapter" data-level="2.19.2" data-path="introR.html"><a href="introR.html#navigationR"><i class="fa fa-check"></i><b>2.19.2</b> Navigating the file system using the R console</a></li>
<li class="chapter" data-level="2.19.3" data-path="introR.html"><a href="introR.html#why-do-the-windows-paths-use-the-wrong-slash"><i class="fa fa-check"></i><b>2.19.3</b> Why do the Windows paths use the wrong slash?</a></li>
<li class="chapter" data-level="2.19.4" data-path="introR.html"><a href="introR.html#nav3"><i class="fa fa-check"></i><b>2.19.4</b> Navigating the file system using the RStudio file panel</a></li>
</ul></li>
<li class="chapter" data-level="2.20" data-path="introR.html"><a href="introR.html#load"><i class="fa fa-check"></i><b>2.20</b> Loading and saving data</a>
<ul>
<li class="chapter" data-level="2.20.1" data-path="introR.html"><a href="introR.html#loading-workspace-files-using-r"><i class="fa fa-check"></i><b>2.20.1</b> Loading workspace files using R</a></li>
<li class="chapter" data-level="2.20.2" data-path="introR.html"><a href="introR.html#loading-workspace-files-using-rstudio"><i class="fa fa-check"></i><b>2.20.2</b> Loading workspace files using RStudio</a></li>
<li class="chapter" data-level="2.20.3" data-path="introR.html"><a href="introR.html#loadingcsv"><i class="fa fa-check"></i><b>2.20.3</b> Importing data from CSV files using loadingcsv</a></li>
<li class="chapter" data-level="2.20.4" data-path="introR.html"><a href="introR.html#importing-data-from-csv-files-using-rstudio"><i class="fa fa-check"></i><b>2.20.4</b> Importing data from CSV files using RStudio</a></li>
<li class="chapter" data-level="2.20.5" data-path="introR.html"><a href="introR.html#saving-a-workspace-file-using-save"><i class="fa fa-check"></i><b>2.20.5</b> Saving a workspace file using <code>save</code></a></li>
<li class="chapter" data-level="2.20.6" data-path="introR.html"><a href="introR.html#save1"><i class="fa fa-check"></i><b>2.20.6</b> Saving a workspace file using RStudio</a></li>
<li class="chapter" data-level="2.20.7" data-path="introR.html"><a href="introR.html#other-things-you-might-want-to-save"><i class="fa fa-check"></i><b>2.20.7</b> Other things you might want to save</a></li>
</ul></li>
<li class="chapter" data-level="2.21" data-path="introR.html"><a href="introR.html#useful"><i class="fa fa-check"></i><b>2.21</b> Useful things to know about variables</a>
<ul>
<li class="chapter" data-level="2.21.1" data-path="introR.html"><a href="introR.html#specials"><i class="fa fa-check"></i><b>2.21.1</b> Special values</a></li>
<li class="chapter" data-level="2.21.2" data-path="introR.html"><a href="introR.html#names"><i class="fa fa-check"></i><b>2.21.2</b> Assigning names to vector elements</a></li>
<li class="chapter" data-level="2.21.3" data-path="introR.html"><a href="introR.html#variable-classes"><i class="fa fa-check"></i><b>2.21.3</b> Variable classes</a></li>
</ul></li>
<li class="chapter" data-level="2.22" data-path="introR.html"><a href="introR.html#factors"><i class="fa fa-check"></i><b>2.22</b> Factors</a>
<ul>
<li class="chapter" data-level="2.22.1" data-path="introR.html"><a href="introR.html#introducing-factors"><i class="fa fa-check"></i><b>2.22.1</b> Introducing factors</a></li>
<li class="chapter" data-level="2.22.2" data-path="introR.html"><a href="introR.html#labelling-the-factor-levels"><i class="fa fa-check"></i><b>2.22.2</b> Labelling the factor levels</a></li>
<li class="chapter" data-level="2.22.3" data-path="introR.html"><a href="introR.html#moving-on"><i class="fa fa-check"></i><b>2.22.3</b> Moving on…</a></li>
</ul></li>
<li class="chapter" data-level="2.23" data-path="introR.html"><a href="introR.html#dataframes"><i class="fa fa-check"></i><b>2.23</b> Data frames</a>
<ul>
<li class="chapter" data-level="2.23.1" data-path="introR.html"><a href="introR.html#introducing-data-frames"><i class="fa fa-check"></i><b>2.23.1</b> Introducing data frames</a></li>
<li class="chapter" data-level="2.23.2" data-path="introR.html"><a href="introR.html#pulling-out-the-contents-of-the-data-frame-using"><i class="fa fa-check"></i><b>2.23.2</b> Pulling out the contents of the data frame using <code>$</code></a></li>
<li class="chapter" data-level="2.23.3" data-path="introR.html"><a href="introR.html#getting-information-about-a-data-frame"><i class="fa fa-check"></i><b>2.23.3</b> Getting information about a data frame</a></li>
<li class="chapter" data-level="2.23.4" data-path="introR.html"><a href="introR.html#looking-for-more-on-data-frames"><i class="fa fa-check"></i><b>2.23.4</b> Looking for more on data frames?</a></li>
</ul></li>
<li class="chapter" data-level="2.24" data-path="introR.html"><a href="introR.html#lists"><i class="fa fa-check"></i><b>2.24</b> Lists</a></li>
<li class="chapter" data-level="2.25" data-path="introR.html"><a href="introR.html#formulas"><i class="fa fa-check"></i><b>2.25</b> Formulas</a></li>
<li class="chapter" data-level="2.26" data-path="introR.html"><a href="introR.html#generics"><i class="fa fa-check"></i><b>2.26</b> Generic functions</a></li>
<li class="chapter" data-level="2.27" data-path="introR.html"><a href="introR.html#help"><i class="fa fa-check"></i><b>2.27</b> Getting help</a>
<ul>
<li class="chapter" data-level="2.27.1" data-path="introR.html"><a href="introR.html#how-to-read-the-help-documentation"><i class="fa fa-check"></i><b>2.27.1</b> How to read the help documentation</a></li>
<li class="chapter" data-level="2.27.2" data-path="introR.html"><a href="introR.html#other-resources"><i class="fa fa-check"></i><b>2.27.2</b> Other resources</a></li>
</ul></li>
<li class="chapter" data-level="2.28" data-path="introR.html"><a href="introR.html#summary-1"><i class="fa fa-check"></i><b>2.28</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptives.html"><a href="descriptives.html"><i class="fa fa-check"></i><b>3</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="descriptives.html"><a href="descriptives.html#videos-1"><i class="fa fa-check"></i><b>3.1</b> Videos</a></li>
<li class="chapter" data-level="3.2" data-path="descriptives.html"><a href="descriptives.html#introduction-2"><i class="fa fa-check"></i><b>3.2</b> Introduction</a></li>
<li class="chapter" data-level="3.3" data-path="descriptives.html"><a href="descriptives.html#centraltendency"><i class="fa fa-check"></i><b>3.3</b> Measures of central tendency</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="descriptives.html"><a href="descriptives.html#mean"><i class="fa fa-check"></i><b>3.3.1</b> The mean</a></li>
<li class="chapter" data-level="3.3.2" data-path="descriptives.html"><a href="descriptives.html#calculating-the-mean-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Calculating the mean in R</a></li>
<li class="chapter" data-level="3.3.3" data-path="descriptives.html"><a href="descriptives.html#median"><i class="fa fa-check"></i><b>3.3.3</b> The median</a></li>
<li class="chapter" data-level="3.3.4" data-path="descriptives.html"><a href="descriptives.html#mean-or-median-whats-the-difference"><i class="fa fa-check"></i><b>3.3.4</b> Mean or median? What’s the difference?</a></li>
<li class="chapter" data-level="3.3.5" data-path="descriptives.html"><a href="descriptives.html#housingpriceexample"><i class="fa fa-check"></i><b>3.3.5</b> A real life example</a></li>
<li class="chapter" data-level="3.3.6" data-path="descriptives.html"><a href="descriptives.html#trimmedmean"><i class="fa fa-check"></i><b>3.3.6</b> Trimmed mean</a></li>
<li class="chapter" data-level="3.3.7" data-path="descriptives.html"><a href="descriptives.html#mode"><i class="fa fa-check"></i><b>3.3.7</b> Mode</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="descriptives.html"><a href="descriptives.html#var"><i class="fa fa-check"></i><b>3.4</b> Measures of variability</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="descriptives.html"><a href="descriptives.html#range"><i class="fa fa-check"></i><b>3.4.1</b> Range</a></li>
<li class="chapter" data-level="3.4.2" data-path="descriptives.html"><a href="descriptives.html#interquartile-range"><i class="fa fa-check"></i><b>3.4.2</b> Interquartile range</a></li>
<li class="chapter" data-level="3.4.3" data-path="descriptives.html"><a href="descriptives.html#aad"><i class="fa fa-check"></i><b>3.4.3</b> Mean absolute deviation</a></li>
<li class="chapter" data-level="3.4.4" data-path="descriptives.html"><a href="descriptives.html#variance"><i class="fa fa-check"></i><b>3.4.4</b> Variance</a></li>
<li class="chapter" data-level="3.4.5" data-path="descriptives.html"><a href="descriptives.html#sd"><i class="fa fa-check"></i><b>3.4.5</b> Standard deviation</a></li>
<li class="chapter" data-level="3.4.6" data-path="descriptives.html"><a href="descriptives.html#mad"><i class="fa fa-check"></i><b>3.4.6</b> Median absolute deviation</a></li>
<li class="chapter" data-level="3.4.7" data-path="descriptives.html"><a href="descriptives.html#which-measure-to-use"><i class="fa fa-check"></i><b>3.4.7</b> Which measure to use?</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="descriptives.html"><a href="descriptives.html#skewandkurtosis"><i class="fa fa-check"></i><b>3.5</b> Skew and kurtosis</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="descriptives.html"><a href="descriptives.html#more-detail-on-skewness-measures"><i class="fa fa-check"></i><b>3.5.1</b> More detail on skewness measures</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="descriptives.html"><a href="descriptives.html#descriptive-summary"><i class="fa fa-check"></i><b>3.6</b> Getting an overall summary of a variable</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="descriptives.html"><a href="descriptives.html#summarising-a-variable"><i class="fa fa-check"></i><b>3.6.1</b> “Summarising” a variable</a></li>
<li class="chapter" data-level="3.6.2" data-path="descriptives.html"><a href="descriptives.html#summarising-a-data-frame"><i class="fa fa-check"></i><b>3.6.2</b> “Summarising” a data frame</a></li>
<li class="chapter" data-level="3.6.3" data-path="descriptives.html"><a href="descriptives.html#describing-a-data-frame"><i class="fa fa-check"></i><b>3.6.3</b> “Describing” a data frame</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="descriptives.html"><a href="descriptives.html#groupdescriptives"><i class="fa fa-check"></i><b>3.7</b> Descriptive statistics separately for each group</a></li>
<li class="chapter" data-level="3.8" data-path="descriptives.html"><a href="descriptives.html#good-descriptive-statistics-are-descriptive"><i class="fa fa-check"></i><b>3.8</b> Good descriptive statistics are descriptive!</a></li>
<li class="chapter" data-level="3.9" data-path="descriptives.html"><a href="descriptives.html#graphics"><i class="fa fa-check"></i><b>3.9</b> Drawing graphs</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="descriptives.html"><a href="descriptives.html#introplotting"><i class="fa fa-check"></i><b>3.9.1</b> An introduction to plotting</a></li>
<li class="chapter" data-level="3.9.2" data-path="descriptives.html"><a href="descriptives.html#hist"><i class="fa fa-check"></i><b>3.9.2</b> Histograms</a></li>
<li class="chapter" data-level="3.9.3" data-path="descriptives.html"><a href="descriptives.html#boxplots"><i class="fa fa-check"></i><b>3.9.3</b> Boxplots</a></li>
<li class="chapter" data-level="3.9.4" data-path="descriptives.html"><a href="descriptives.html#bargraph"><i class="fa fa-check"></i><b>3.9.4</b> Bar graphs</a></li>
<li class="chapter" data-level="3.9.5" data-path="descriptives.html"><a href="descriptives.html#saveimage"><i class="fa fa-check"></i><b>3.9.5</b> Saving image files using R and Rstudio</a></li>
<li class="chapter" data-level="3.9.6" data-path="descriptives.html"><a href="descriptives.html#summary-2"><i class="fa fa-check"></i><b>3.9.6</b> Summary</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html"><i class="fa fa-check"></i><b>4</b> Inferential statistics: The Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#videos-2"><i class="fa fa-check"></i><b>4.1</b> Videos</a></li>
<li class="chapter" data-level="4.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#estimation"><i class="fa fa-check"></i><b>4.2</b> Introduction</a></li>
<li class="chapter" data-level="4.3" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#probstats"><i class="fa fa-check"></i><b>4.3</b> How are probability and statistics different?</a></li>
<li class="chapter" data-level="4.4" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#probmeaning"><i class="fa fa-check"></i><b>4.4</b> What does probability mean?</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#the-frequentist-view"><i class="fa fa-check"></i><b>4.4.1</b> The frequentist view</a></li>
<li class="chapter" data-level="4.4.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#the-bayesian-view"><i class="fa fa-check"></i><b>4.4.2</b> The Bayesian view</a></li>
<li class="chapter" data-level="4.4.3" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#whats-the-difference-and-who-is-right"><i class="fa fa-check"></i><b>4.4.3</b> What’s the difference? And who is right?</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#srs"><i class="fa fa-check"></i><b>4.5</b> Samples, populations and sampling</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#pop"><i class="fa fa-check"></i><b>4.5.1</b> Defining a population</a></li>
<li class="chapter" data-level="4.5.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#simple-random-samples"><i class="fa fa-check"></i><b>4.5.2</b> Simple random samples</a></li>
<li class="chapter" data-level="4.5.3" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#most-samples-are-not-simple-random-samples"><i class="fa fa-check"></i><b>4.5.3</b> Most samples are not simple random samples</a></li>
<li class="chapter" data-level="4.5.4" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#how-much-does-it-matter-if-you-dont-have-a-simple-random-sample"><i class="fa fa-check"></i><b>4.5.4</b> How much does it matter if you don’t have a simple random sample?</a></li>
<li class="chapter" data-level="4.5.5" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#population-parameters-and-sample-statistics"><i class="fa fa-check"></i><b>4.5.5</b> Population parameters and sample statistics</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#lawlargenumbers"><i class="fa fa-check"></i><b>4.6</b> The law of large numbers</a></li>
<li class="chapter" data-level="4.7" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#samplesandclt"><i class="fa fa-check"></i><b>4.7</b> Sampling distributions and the central limit theorem</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#samplingdists"><i class="fa fa-check"></i><b>4.7.1</b> Sampling distribution of the mean</a></li>
<li class="chapter" data-level="4.7.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#sample-size-and-population-size"><i class="fa fa-check"></i><b>4.7.2</b> Sample size and population size</a></li>
<li class="chapter" data-level="4.7.3" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#sampling-error"><i class="fa fa-check"></i><b>4.7.3</b> Sampling error</a></li>
<li class="chapter" data-level="4.7.4" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#another-sampling-distribution"><i class="fa fa-check"></i><b>4.7.4</b> Another sampling distribution</a></li>
<li class="chapter" data-level="4.7.5" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#defining-the-central-limit-theorem"><i class="fa fa-check"></i><b>4.7.5</b> Defining the central limit theorem</a></li>
<li class="chapter" data-level="4.7.6" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#more-on-standard-error"><i class="fa fa-check"></i><b>4.7.6</b> More on standard error</a></li>
<li class="chapter" data-level="4.7.7" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#the-sampling-distribution-tells-us-about-the-probability-of-sample-means"><i class="fa fa-check"></i><b>4.7.7</b> The sampling distribution tells us about the probability of sample means</a></li>
<li class="chapter" data-level="4.7.8" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#sampling-distributions-exist-for-any-sample-statistic"><i class="fa fa-check"></i><b>4.7.8</b> Sampling distributions exist for any sample statistic!</a></li>
<li class="chapter" data-level="4.7.9" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#clt"><i class="fa fa-check"></i><b>4.7.9</b> The central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#pointestimates"><i class="fa fa-check"></i><b>4.8</b> Estimating population parameters</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#estimating-the-population-mean"><i class="fa fa-check"></i><b>4.8.1</b> Estimating the population mean</a></li>
<li class="chapter" data-level="4.8.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#estimating-the-population-standard-deviation"><i class="fa fa-check"></i><b>4.8.2</b> Estimating the population standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#ci"><i class="fa fa-check"></i><b>4.9</b> Estimating a confidence interval</a>
<ul>
<li class="chapter" data-level="4.9.1" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#a-slight-mistake-in-the-formula"><i class="fa fa-check"></i><b>4.9.1</b> A slight mistake in the formula</a></li>
<li class="chapter" data-level="4.9.2" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#interpreting-a-confidence-interval"><i class="fa fa-check"></i><b>4.9.2</b> Interpreting a confidence interval</a></li>
<li class="chapter" data-level="4.9.3" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#calculating-confidence-intervals-in-r"><i class="fa fa-check"></i><b>4.9.3</b> Calculating confidence intervals in R</a></li>
<li class="chapter" data-level="4.9.4" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#ciplots"><i class="fa fa-check"></i><b>4.9.4</b> Plotting confidence intervals in R</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="inferential-statistics-the-central-limit-theorem.html"><a href="inferential-statistics-the-central-limit-theorem.html#summary-3"><i class="fa fa-check"></i><b>4.10</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hypothesistesting.html"><a href="hypothesistesting.html"><i class="fa fa-check"></i><b>5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="5.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#videos-3"><i class="fa fa-check"></i><b>5.1</b> Videos</a></li>
<li class="chapter" data-level="5.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#introduction-3"><i class="fa fa-check"></i><b>5.2</b> Introduction</a></li>
<li class="chapter" data-level="5.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#hypotheses"><i class="fa fa-check"></i><b>5.3</b> A menagerie of hypotheses</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#research-hypotheses-versus-statistical-hypotheses"><i class="fa fa-check"></i><b>5.3.1</b> Research hypotheses versus statistical hypotheses</a></li>
<li class="chapter" data-level="5.3.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#null-hypotheses-and-alternative-hypotheses"><i class="fa fa-check"></i><b>5.3.2</b> Null hypotheses and alternative hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="hypothesistesting.html"><a href="hypothesistesting.html#errortypes"><i class="fa fa-check"></i><b>5.4</b> Two types of errors</a></li>
<li class="chapter" data-level="5.5" data-path="hypothesistesting.html"><a href="hypothesistesting.html#teststatistics"><i class="fa fa-check"></i><b>5.5</b> Test statistics and sampling distributions</a></li>
<li class="chapter" data-level="5.6" data-path="hypothesistesting.html"><a href="hypothesistesting.html#decisionmaking"><i class="fa fa-check"></i><b>5.6</b> Making decisions</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#critical-regions-and-critical-values"><i class="fa fa-check"></i><b>5.6.1</b> Critical regions and critical values</a></li>
<li class="chapter" data-level="5.6.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-note-on-statistical-significance"><i class="fa fa-check"></i><b>5.6.2</b> A note on statistical “significance”</a></li>
<li class="chapter" data-level="5.6.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#onesidedtests"><i class="fa fa-check"></i><b>5.6.3</b> The difference between one sided and two sided tests</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="hypothesistesting.html"><a href="hypothesistesting.html#pvalue"><i class="fa fa-check"></i><b>5.7</b> The <span class="math inline">\(p\)</span> value of a test</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-softer-view-of-decision-making"><i class="fa fa-check"></i><b>5.7.1</b> A softer view of decision making</a></li>
<li class="chapter" data-level="5.7.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-probability-of-extreme-data"><i class="fa fa-check"></i><b>5.7.2</b> The probability of extreme data</a></li>
<li class="chapter" data-level="5.7.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#a-common-mistake"><i class="fa fa-check"></i><b>5.7.3</b> A common mistake</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="hypothesistesting.html"><a href="hypothesistesting.html#writeup"><i class="fa fa-check"></i><b>5.8</b> Reporting the results of a hypothesis test</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-issue"><i class="fa fa-check"></i><b>5.8.1</b> The issue</a></li>
<li class="chapter" data-level="5.8.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#two-proposed-solutions"><i class="fa fa-check"></i><b>5.8.2</b> Two proposed solutions</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="hypothesistesting.html"><a href="hypothesistesting.html#running-the-hypothesis-test-in-practice"><i class="fa fa-check"></i><b>5.9</b> Running the hypothesis test in practice</a></li>
<li class="chapter" data-level="5.10" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effectsize"><i class="fa fa-check"></i><b>5.10</b> Effect size, sample size and power</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#the-power-function"><i class="fa fa-check"></i><b>5.10.1</b> The power function</a></li>
<li class="chapter" data-level="5.10.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#effect-size"><i class="fa fa-check"></i><b>5.10.2</b> Effect size</a></li>
<li class="chapter" data-level="5.10.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#increasing-the-power-of-your-study"><i class="fa fa-check"></i><b>5.10.3</b> Increasing the power of your study</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="hypothesistesting.html"><a href="hypothesistesting.html#nhstmess"><i class="fa fa-check"></i><b>5.11</b> Some issues to consider</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="hypothesistesting.html"><a href="hypothesistesting.html#neyman-versus-fisher"><i class="fa fa-check"></i><b>5.11.1</b> Neyman versus Fisher</a></li>
<li class="chapter" data-level="5.11.2" data-path="hypothesistesting.html"><a href="hypothesistesting.html#bayesians-versus-frequentists"><i class="fa fa-check"></i><b>5.11.2</b> Bayesians versus frequentists</a></li>
<li class="chapter" data-level="5.11.3" data-path="hypothesistesting.html"><a href="hypothesistesting.html#traps"><i class="fa fa-check"></i><b>5.11.3</b> Traps</a></li>
</ul></li>
<li class="chapter" data-level="5.12" data-path="hypothesistesting.html"><a href="hypothesistesting.html#summary-4"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html"><i class="fa fa-check"></i><b>6</b> Issues in Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="6.1" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#videos-4"><i class="fa fa-check"></i><b>6.1</b> Videos</a></li>
<li class="chapter" data-level="6.2" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#introduction-4"><i class="fa fa-check"></i><b>6.2</b> Introduction</a></li>
<li class="chapter" data-level="6.3" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#the-researcher-affects-nhst-outcomes"><i class="fa fa-check"></i><b>6.3</b> The researcher affects NHST outcomes</a></li>
<li class="chapter" data-level="6.4" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#nhst-misunderstandings"><i class="fa fa-check"></i><b>6.4</b> NHST Misunderstandings</a></li>
<li class="chapter" data-level="6.5" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#nhst-issues"><i class="fa fa-check"></i><b>6.5</b> NHST Issues</a></li>
<li class="chapter" data-level="6.6" data-path="issues-in-hypothesis-testing.html"><a href="issues-in-hypothesis-testing.html#conclusions"><i class="fa fa-check"></i><b>6.6</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html"><i class="fa fa-check"></i><b>7</b> Data Cleaning and Missing Values Analysis</a>
<ul>
<li class="chapter" data-level="7.1" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#videos-5"><i class="fa fa-check"></i><b>7.1</b> Videos</a></li>
<li class="chapter" data-level="7.2" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#introduction-dealing-with-the-unexpected"><i class="fa fa-check"></i><b>7.2</b> Introduction: Dealing with the Unexpected</a></li>
<li class="chapter" data-level="7.3" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#data-cleaning"><i class="fa fa-check"></i><b>7.3</b> Data Cleaning</a></li>
<li class="chapter" data-level="7.4" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#a-general-plan-for-data-cleaning"><i class="fa fa-check"></i><b>7.4</b> A General Plan for Data Cleaning</a></li>
<li class="chapter" data-level="7.5" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#step-0.-design-your-research-to-mimimize-data-problems"><i class="fa fa-check"></i><b>7.5</b> Step 0. Design your Research to Mimimize Data Problems</a></li>
<li class="chapter" data-level="7.6" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#step-1.-examine-your-data"><i class="fa fa-check"></i><b>7.6</b> Step 1. Examine Your Data</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#sort"><i class="fa fa-check"></i><b>7.6.1</b> Sorting, flipping and merging data</a></li>
<li class="chapter" data-level="7.6.2" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#binding-vectors-together"><i class="fa fa-check"></i><b>7.6.2</b> Binding vectors together</a></li>
<li class="chapter" data-level="7.6.3" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#reshape"><i class="fa fa-check"></i><b>7.6.3</b> Reshaping a data frame</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#step-2.-outlier-analysis"><i class="fa fa-check"></i><b>7.7</b> Step 2. Outlier Analysis</a></li>
<li class="chapter" data-level="7.8" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#step-3.-missing-values-analysis"><i class="fa fa-check"></i><b>7.8</b> Step 3. Missing values analysis</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="introR.html"><a href="introR.html#specials"><i class="fa fa-check"></i><b>7.8.1</b> Special values in R</a></li>
<li class="chapter" data-level="7.8.2" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#missing"><i class="fa fa-check"></i><b>7.8.2</b> Handling missing values in R</a></li>
<li class="chapter" data-level="7.8.3" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#why-values-are-missing-mcar-mar-and-mnar"><i class="fa fa-check"></i><b>7.8.3</b> Why values are missing: MCAR, MAR, and MNAR</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#step-4.-test-specific-assumption-checking"><i class="fa fa-check"></i><b>7.9</b> Step 4. Test-specific assumption checking</a></li>
<li class="chapter" data-level="7.10" data-path="data-cleaning-and-missing-values-analysis.html"><a href="data-cleaning-and-missing-values-analysis.html#communicate-results-of-data-cleaning-in-apa-style"><i class="fa fa-check"></i><b>7.10</b> Communicate results of data cleaning in APA style</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>8</b> Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="regression.html"><a href="regression.html#videos-6"><i class="fa fa-check"></i><b>8.1</b> Videos</a></li>
<li class="chapter" data-level="8.2" data-path="regression.html"><a href="regression.html#introduction-5"><i class="fa fa-check"></i><b>8.2</b> Introduction</a></li>
<li class="chapter" data-level="8.3" data-path="regression.html"><a href="regression.html#the-general-linear-model-glm"><i class="fa fa-check"></i><b>8.3</b> The General Linear Model (GLM)</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="regression.html"><a href="regression.html#the-traditional-approach-two-kinds-of-parametric-statistical-tests"><i class="fa fa-check"></i><b>8.3.1</b> The Traditional approach: Two kinds of parametric statistical tests</a></li>
<li class="chapter" data-level="8.3.2" data-path="regression.html"><a href="regression.html#the-glm-approach"><i class="fa fa-check"></i><b>8.3.2</b> The GLM approach</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression.html"><a href="regression.html#correl"><i class="fa fa-check"></i><b>8.4</b> Correlations</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="regression.html"><a href="regression.html#the-data"><i class="fa fa-check"></i><b>8.4.1</b> The data</a></li>
<li class="chapter" data-level="8.4.2" data-path="regression.html"><a href="regression.html#the-strength-and-direction-of-a-relationship"><i class="fa fa-check"></i><b>8.4.2</b> The strength and direction of a relationship</a></li>
<li class="chapter" data-level="8.4.3" data-path="regression.html"><a href="regression.html#the-correlation-coefficient"><i class="fa fa-check"></i><b>8.4.3</b> The correlation coefficient</a></li>
<li class="chapter" data-level="8.4.4" data-path="regression.html"><a href="regression.html#calculating-correlations-in-r"><i class="fa fa-check"></i><b>8.4.4</b> Calculating correlations in R</a></li>
<li class="chapter" data-level="8.4.5" data-path="regression.html"><a href="regression.html#interpretingcorrelations"><i class="fa fa-check"></i><b>8.4.5</b> Interpreting a correlation</a></li>
<li class="chapter" data-level="8.4.6" data-path="regression.html"><a href="regression.html#spearmans-rank-correlations"><i class="fa fa-check"></i><b>8.4.6</b> Spearman’s rank correlations</a></li>
<li class="chapter" data-level="8.4.7" data-path="regression.html"><a href="regression.html#the-correlate-function"><i class="fa fa-check"></i><b>8.4.7</b> The <code>correlate()</code> function</a></li>
<li class="chapter" data-level="8.4.8" data-path="regression.html"><a href="regression.html#missing-values-in-pairwise-calculations-1"><i class="fa fa-check"></i><b>8.4.8</b> Missing values in pairwise calculations</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="regression.html"><a href="regression.html#introregression"><i class="fa fa-check"></i><b>8.5</b> Linear regression</a></li>
<li class="chapter" data-level="8.6" data-path="regression.html"><a href="regression.html#regressionestimation"><i class="fa fa-check"></i><b>8.6</b> Estimating a linear regression model</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="regression.html"><a href="regression.html#lm"><i class="fa fa-check"></i><b>8.6.1</b> Using the <code>lm()</code> function</a></li>
<li class="chapter" data-level="8.6.2" data-path="regression.html"><a href="regression.html#interpreting-the-estimated-model"><i class="fa fa-check"></i><b>8.6.2</b> Interpreting the estimated model</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="regression.html"><a href="regression.html#multipleregression"><i class="fa fa-check"></i><b>8.7</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="regression.html"><a href="regression.html#doing-it-in-r"><i class="fa fa-check"></i><b>8.7.1</b> Doing it in R</a></li>
<li class="chapter" data-level="8.7.2" data-path="regression.html"><a href="regression.html#formula-for-the-general-case"><i class="fa fa-check"></i><b>8.7.2</b> Formula for the general case</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="regression.html"><a href="regression.html#r2"><i class="fa fa-check"></i><b>8.8</b> Quantifying the fit of the regression model</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="regression.html"><a href="regression.html#the-r2-value"><i class="fa fa-check"></i><b>8.8.1</b> The <span class="math inline">\(R^2\)</span> value</a></li>
<li class="chapter" data-level="8.8.2" data-path="regression.html"><a href="regression.html#the-relationship-between-regression-and-correlation"><i class="fa fa-check"></i><b>8.8.2</b> The relationship between regression and correlation</a></li>
<li class="chapter" data-level="8.8.3" data-path="regression.html"><a href="regression.html#the-adjusted-r2-value"><i class="fa fa-check"></i><b>8.8.3</b> The adjusted <span class="math inline">\(R^2\)</span> value</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="regression.html"><a href="regression.html#regressiontests"><i class="fa fa-check"></i><b>8.9</b> Hypothesis tests for regression models</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="regression.html"><a href="regression.html#testing-the-model-as-a-whole-the-omnibus-test"><i class="fa fa-check"></i><b>8.9.1</b> Testing the model as a whole: The omnibus test</a></li>
<li class="chapter" data-level="8.9.2" data-path="regression.html"><a href="regression.html#tests-for-individual-coefficients"><i class="fa fa-check"></i><b>8.9.2</b> Tests for individual coefficients</a></li>
<li class="chapter" data-level="8.9.3" data-path="regression.html"><a href="regression.html#regressionsummary"><i class="fa fa-check"></i><b>8.9.3</b> Running the hypothesis tests in R</a></li>
</ul></li>
<li class="chapter" data-level="8.10" data-path="regression.html"><a href="regression.html#corrhyp"><i class="fa fa-check"></i><b>8.10</b> Testing the significance of a correlation</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="regression.html"><a href="regression.html#hypothesis-tests-for-a-single-correlation"><i class="fa fa-check"></i><b>8.10.1</b> Hypothesis tests for a single correlation</a></li>
<li class="chapter" data-level="8.10.2" data-path="regression.html"><a href="regression.html#corrhyp2"><i class="fa fa-check"></i><b>8.10.2</b> Hypothesis tests for all pairwise correlations</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="regression.html"><a href="regression.html#regressioncoefs"><i class="fa fa-check"></i><b>8.11</b> Regarding regression coefficients</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="regression.html"><a href="regression.html#confidence-intervals-for-the-coefficients"><i class="fa fa-check"></i><b>8.11.1</b> Confidence intervals for the coefficients</a></li>
<li class="chapter" data-level="8.11.2" data-path="regression.html"><a href="regression.html#calculating-standardised-regression-coefficients"><i class="fa fa-check"></i><b>8.11.2</b> Calculating standardised regression coefficients</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="regression.html"><a href="regression.html#regressionassumptions"><i class="fa fa-check"></i><b>8.12</b> Assumptions of regression</a></li>
<li class="chapter" data-level="8.13" data-path="regression.html"><a href="regression.html#regressiondiagnostics"><i class="fa fa-check"></i><b>8.13</b> Model checking</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="regression.html"><a href="regression.html#three-kinds-of-residuals"><i class="fa fa-check"></i><b>8.13.1</b> Three kinds of residuals</a></li>
<li class="chapter" data-level="8.13.2" data-path="regression.html"><a href="regression.html#regressionoutliers"><i class="fa fa-check"></i><b>8.13.2</b> Three kinds of anomalous data</a></li>
<li class="chapter" data-level="8.13.3" data-path="regression.html"><a href="regression.html#regressionnormality"><i class="fa fa-check"></i><b>8.13.3</b> Checking the normality of the residuals</a></li>
<li class="chapter" data-level="8.13.4" data-path="regression.html"><a href="regression.html#regressionlinearity"><i class="fa fa-check"></i><b>8.13.4</b> Checking the linearity of the relationship</a></li>
<li class="chapter" data-level="8.13.5" data-path="regression.html"><a href="regression.html#regressionhomogeneity"><i class="fa fa-check"></i><b>8.13.5</b> Checking the homogeneity of variance</a></li>
<li class="chapter" data-level="8.13.6" data-path="regression.html"><a href="regression.html#regressioncollinearity"><i class="fa fa-check"></i><b>8.13.6</b> Checking for collinearity</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="regression.html"><a href="regression.html#modelselreg"><i class="fa fa-check"></i><b>8.14</b> Model selection</a>
<ul>
<li class="chapter" data-level="8.14.1" data-path="regression.html"><a href="regression.html#backward-elimination"><i class="fa fa-check"></i><b>8.14.1</b> Backward elimination</a></li>
<li class="chapter" data-level="8.14.2" data-path="regression.html"><a href="regression.html#forward-selection"><i class="fa fa-check"></i><b>8.14.2</b> Forward selection</a></li>
<li class="chapter" data-level="8.14.3" data-path="regression.html"><a href="regression.html#a-caveat"><i class="fa fa-check"></i><b>8.14.3</b> A caveat</a></li>
<li class="chapter" data-level="8.14.4" data-path="regression.html"><a href="regression.html#comparing-two-regression-models"><i class="fa fa-check"></i><b>8.14.4</b> Comparing two regression models</a></li>
</ul></li>
<li class="chapter" data-level="8.15" data-path="regression.html"><a href="regression.html#practical-issues-in-correlation-and-regression"><i class="fa fa-check"></i><b>8.15</b> Practical Issues in Correlation and Regression</a>
<ul>
<li class="chapter" data-level="8.15.1" data-path="regression.html"><a href="regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>8.15.1</b> Correlation is not causation</a></li>
<li class="chapter" data-level="8.15.2" data-path="regression.html"><a href="regression.html#interpreting-nhst-in-big-data"><i class="fa fa-check"></i><b>8.15.2</b> Interpreting NHST in Big Data</a></li>
<li class="chapter" data-level="8.15.3" data-path="regression.html"><a href="regression.html#outliers"><i class="fa fa-check"></i><b>8.15.3</b> Outliers</a></li>
<li class="chapter" data-level="8.15.4" data-path="regression.html"><a href="regression.html#restriction-of-range"><i class="fa fa-check"></i><b>8.15.4</b> Restriction of Range</a></li>
<li class="chapter" data-level="8.15.5" data-path="regression.html"><a href="regression.html#regression-toward-the-mean"><i class="fa fa-check"></i><b>8.15.5</b> Regression Toward the Mean</a></li>
<li class="chapter" data-level="8.15.6" data-path="regression.html"><a href="regression.html#report-effect-size"><i class="fa fa-check"></i><b>8.15.6</b> Report Effect Size</a></li>
<li class="chapter" data-level="8.15.7" data-path="regression.html"><a href="regression.html#what-are-degrees-of-freedom-again"><i class="fa fa-check"></i><b>8.15.7</b> What are Degrees of Freedom, again?</a></li>
</ul></li>
<li class="chapter" data-level="8.16" data-path="regression.html"><a href="regression.html#summary-5"><i class="fa fa-check"></i><b>8.16</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ttest.html"><a href="ttest.html"><i class="fa fa-check"></i><b>9</b> T-Tests</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ttest.html"><a href="ttest.html#videos-7"><i class="fa fa-check"></i><b>9.1</b> Videos</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ttest.html"><a href="ttest.html#t-tests"><i class="fa fa-check"></i><b>9.1.1</b> T-Tests</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ttest.html"><a href="ttest.html#groupcomparisonscompared"><i class="fa fa-check"></i><b>9.2</b> Comparison of tests that compare groups</a></li>
<li class="chapter" data-level="9.3" data-path="ttest.html"><a href="ttest.html#introduction-6"><i class="fa fa-check"></i><b>9.3</b> Introduction</a></li>
<li class="chapter" data-level="9.4" data-path="ttest.html"><a href="ttest.html#onesamplettest"><i class="fa fa-check"></i><b>9.4</b> The one-sample <span class="math inline">\(t\)</span>-test</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="ttest.html"><a href="ttest.html#introducing-the-t-test"><i class="fa fa-check"></i><b>9.4.1</b> Introducing the <span class="math inline">\(t\)</span>-test</a></li>
<li class="chapter" data-level="9.4.2" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r"><i class="fa fa-check"></i><b>9.4.2</b> Doing the test in R</a></li>
<li class="chapter" data-level="9.4.3" data-path="ttest.html"><a href="ttest.html#ttestoneassumptions"><i class="fa fa-check"></i><b>9.4.3</b> Assumptions of the one sample <span class="math inline">\(t\)</span>-test</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="ttest.html"><a href="ttest.html#studentttest"><i class="fa fa-check"></i><b>9.5</b> The independent samples <span class="math inline">\(t\)</span>-test (Student test)</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ttest.html"><a href="ttest.html#the-data-1"><i class="fa fa-check"></i><b>9.5.1</b> The data</a></li>
<li class="chapter" data-level="9.5.2" data-path="ttest.html"><a href="ttest.html#introducing-the-test"><i class="fa fa-check"></i><b>9.5.2</b> Introducing the test</a></li>
<li class="chapter" data-level="9.5.3" data-path="ttest.html"><a href="ttest.html#a-pooled-estimate-of-the-standard-deviation"><i class="fa fa-check"></i><b>9.5.3</b> A “pooled estimate” of the standard deviation</a></li>
<li class="chapter" data-level="9.5.4" data-path="ttest.html"><a href="ttest.html#the-same-pooled-estimate-described-differently"><i class="fa fa-check"></i><b>9.5.4</b> The same pooled estimate, described differently</a></li>
<li class="chapter" data-level="9.5.5" data-path="ttest.html"><a href="ttest.html#completing-the-test"><i class="fa fa-check"></i><b>9.5.5</b> Completing the test</a></li>
<li class="chapter" data-level="9.5.6" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-1"><i class="fa fa-check"></i><b>9.5.6</b> Doing the test in R</a></li>
<li class="chapter" data-level="9.5.7" data-path="ttest.html"><a href="ttest.html#positive-and-negative-t-values"><i class="fa fa-check"></i><b>9.5.7</b> Positive and negative <span class="math inline">\(t\)</span> values</a></li>
<li class="chapter" data-level="9.5.8" data-path="ttest.html"><a href="ttest.html#studentassumptions"><i class="fa fa-check"></i><b>9.5.8</b> Assumptions of the test</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="ttest.html"><a href="ttest.html#welchttest"><i class="fa fa-check"></i><b>9.6</b> The independent samples <span class="math inline">\(t\)</span>-test (Welch test)</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-2"><i class="fa fa-check"></i><b>9.6.1</b> Doing the test in R</a></li>
<li class="chapter" data-level="9.6.2" data-path="ttest.html"><a href="ttest.html#assumptions-of-the-test"><i class="fa fa-check"></i><b>9.6.2</b> Assumptions of the test</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="ttest.html"><a href="ttest.html#pairedsamplesttest"><i class="fa fa-check"></i><b>9.7</b> The paired-samples <span class="math inline">\(t\)</span>-test</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="ttest.html"><a href="ttest.html#the-data-2"><i class="fa fa-check"></i><b>9.7.1</b> The data</a></li>
<li class="chapter" data-level="9.7.2" data-path="ttest.html"><a href="ttest.html#what-is-the-paired-samples-t-test"><i class="fa fa-check"></i><b>9.7.2</b> What is the paired samples <span class="math inline">\(t\)</span>-test?</a></li>
<li class="chapter" data-level="9.7.3" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-part-1"><i class="fa fa-check"></i><b>9.7.3</b> Doing the test in R, part 1</a></li>
<li class="chapter" data-level="9.7.4" data-path="ttest.html"><a href="ttest.html#doing-the-test-in-r-part-2"><i class="fa fa-check"></i><b>9.7.4</b> Doing the test in R, part 2</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="ttest.html"><a href="ttest.html#one-sided-tests"><i class="fa fa-check"></i><b>9.8</b> One sided tests</a></li>
<li class="chapter" data-level="9.9" data-path="ttest.html"><a href="ttest.html#ttestfunction"><i class="fa fa-check"></i><b>9.9</b> Using the t.test() function</a></li>
<li class="chapter" data-level="9.10" data-path="ttest.html"><a href="ttest.html#cohensd"><i class="fa fa-check"></i><b>9.10</b> Effect size</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="ttest.html"><a href="ttest.html#cohens-d-from-one-sample"><i class="fa fa-check"></i><b>9.10.1</b> Cohen’s <span class="math inline">\(d\)</span> from one sample</a></li>
<li class="chapter" data-level="9.10.2" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-student-t-test"><i class="fa fa-check"></i><b>9.10.2</b> Cohen’s <span class="math inline">\(d\)</span> from a Student <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="9.10.3" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-welch-test"><i class="fa fa-check"></i><b>9.10.3</b> Cohen’s <span class="math inline">\(d\)</span> from a Welch test</a></li>
<li class="chapter" data-level="9.10.4" data-path="ttest.html"><a href="ttest.html#cohens-d-from-a-paired-samples-test"><i class="fa fa-check"></i><b>9.10.4</b> Cohen’s <span class="math inline">\(d\)</span> from a paired-samples test</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="ttest.html"><a href="ttest.html#shapiro"><i class="fa fa-check"></i><b>9.11</b> Checking the normality of a sample</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="ttest.html"><a href="ttest.html#qq-plots"><i class="fa fa-check"></i><b>9.11.1</b> QQ plots</a></li>
<li class="chapter" data-level="9.11.2" data-path="ttest.html"><a href="ttest.html#shapiro-wilk-tests"><i class="fa fa-check"></i><b>9.11.2</b> Shapiro-Wilk tests</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="ttest.html"><a href="ttest.html#wilcox"><i class="fa fa-check"></i><b>9.12</b> Testing non-normal data with Wilcoxon tests</a>
<ul>
<li class="chapter" data-level="9.12.1" data-path="ttest.html"><a href="ttest.html#two-sample-wilcoxon-test"><i class="fa fa-check"></i><b>9.12.1</b> Two sample Wilcoxon test</a></li>
<li class="chapter" data-level="9.12.2" data-path="ttest.html"><a href="ttest.html#one-sample-wilcoxon-test"><i class="fa fa-check"></i><b>9.12.2</b> One sample Wilcoxon test</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="ttest.html"><a href="ttest.html#summary-6"><i class="fa fa-check"></i><b>9.13</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>10</b> One-way ANOVA</a>
<ul>
<li class="chapter" data-level="10.1" data-path="anova.html"><a href="anova.html#videos-8"><i class="fa fa-check"></i><b>10.1</b> Videos</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="anova.html"><a href="anova.html#one-way-between-subjects-anova"><i class="fa fa-check"></i><b>10.1.1</b> One-Way, Between-Subjects ANOVA</a></li>
<li class="chapter" data-level="10.1.2" data-path="anova.html"><a href="anova.html#repeated-measures-anova"><i class="fa fa-check"></i><b>10.1.2</b> Repeated Measures ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="anova.html"><a href="anova.html#anxifree"><i class="fa fa-check"></i><b>10.2</b> An illustrative data set</a></li>
<li class="chapter" data-level="10.3" data-path="anova.html"><a href="anova.html#anovaintro"><i class="fa fa-check"></i><b>10.3</b> How ANOVA works</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="anova.html"><a href="anova.html#two-formulas-for-the-variance-of-y"><i class="fa fa-check"></i><b>10.3.1</b> Two formulas for the variance of <span class="math inline">\(Y\)</span></a></li>
<li class="chapter" data-level="10.3.2" data-path="anova.html"><a href="anova.html#from-variances-to-sums-of-squares"><i class="fa fa-check"></i><b>10.3.2</b> From variances to sums of squares</a></li>
<li class="chapter" data-level="10.3.3" data-path="anova.html"><a href="anova.html#from-sums-of-squares-to-the-f-test"><i class="fa fa-check"></i><b>10.3.3</b> From sums of squares to the <span class="math inline">\(F\)</span>-test</a></li>
<li class="chapter" data-level="10.3.4" data-path="anova.html"><a href="anova.html#anovamodel"><i class="fa fa-check"></i><b>10.3.4</b> The model for the data and the meaning of <span class="math inline">\(F\)</span> (advanced)</a></li>
<li class="chapter" data-level="10.3.5" data-path="anova.html"><a href="anova.html#anovacalc"><i class="fa fa-check"></i><b>10.3.5</b> A worked example</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="anova.html"><a href="anova.html#introduceaov"><i class="fa fa-check"></i><b>10.4</b> Running an ANOVA in R</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="anova.html"><a href="anova.html#using-the-aov-function-to-specify-your-anova"><i class="fa fa-check"></i><b>10.4.1</b> Using the <code>aov()</code> function to specify your ANOVA</a></li>
<li class="chapter" data-level="10.4.2" data-path="anova.html"><a href="anova.html#aovobjects"><i class="fa fa-check"></i><b>10.4.2</b> Understanding what the <code>aov()</code> function produces</a></li>
<li class="chapter" data-level="10.4.3" data-path="anova.html"><a href="anova.html#running-the-hypothesis-tests-for-the-anova"><i class="fa fa-check"></i><b>10.4.3</b> Running the hypothesis tests for the ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="anova.html"><a href="anova.html#etasquared"><i class="fa fa-check"></i><b>10.5</b> Effect size</a></li>
<li class="chapter" data-level="10.6" data-path="anova.html"><a href="anova.html#anovaandt"><i class="fa fa-check"></i><b>10.6</b> On the relationship between ANOVA and the Student <span class="math inline">\(t\)</span> test</a></li>
<li class="chapter" data-level="10.7" data-path="anova.html"><a href="anova.html#summary-7"><i class="fa fa-check"></i><b>10.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html"><i class="fa fa-check"></i><b>11</b> Multiple comparisons</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#posthoc"><i class="fa fa-check"></i><b>11.1</b> Multiple comparisons and post hoc tests</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#running-pairwise-t-tests"><i class="fa fa-check"></i><b>11.1.1</b> Running “pairwise” <span class="math inline">\(t\)</span>-tests</a></li>
<li class="chapter" data-level="11.1.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#corrections-for-multiple-testing"><i class="fa fa-check"></i><b>11.1.2</b> Corrections for multiple testing</a></li>
<li class="chapter" data-level="11.1.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#bonferroni-corrections"><i class="fa fa-check"></i><b>11.1.3</b> Bonferroni corrections</a></li>
<li class="chapter" data-level="11.1.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#holm-corrections"><i class="fa fa-check"></i><b>11.1.4</b> Holm corrections</a></li>
<li class="chapter" data-level="11.1.5" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#writing-up-the-post-hoc-test"><i class="fa fa-check"></i><b>11.1.5</b> Writing up the post hoc test</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#anovaassumptions"><i class="fa fa-check"></i><b>11.2</b> Assumptions of one-way ANOVA</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#how-robust-is-anova"><i class="fa fa-check"></i><b>11.2.1</b> How robust is ANOVA?</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#levene"><i class="fa fa-check"></i><b>11.3</b> Checking the homogeneity of variance assumption</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#running-the-levenes-test-in-r"><i class="fa fa-check"></i><b>11.3.1</b> Running the Levene’s test in R</a></li>
<li class="chapter" data-level="11.3.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#additional-comments"><i class="fa fa-check"></i><b>11.3.2</b> Additional comments</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#welchoneway"><i class="fa fa-check"></i><b>11.4</b> Removing the homogeneity of variance assumption</a></li>
<li class="chapter" data-level="11.5" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#anovanormality"><i class="fa fa-check"></i><b>11.5</b> Checking the normality assumption</a></li>
<li class="chapter" data-level="11.6" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#kruskalwallis"><i class="fa fa-check"></i><b>11.6</b> Removing the normality assumption</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#the-logic-behind-the-kruskal-wallis-test"><i class="fa fa-check"></i><b>11.6.1</b> The logic behind the Kruskal-Wallis test</a></li>
<li class="chapter" data-level="11.6.2" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#additional-details"><i class="fa fa-check"></i><b>11.6.2</b> Additional details</a></li>
<li class="chapter" data-level="11.6.3" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#how-to-run-the-kruskal-wallis-test-in-r"><i class="fa fa-check"></i><b>11.6.3</b> How to run the Kruskal-Wallis test in R</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="multiple-comparisons.html"><a href="multiple-comparisons.html#summary-8"><i class="fa fa-check"></i><b>11.7</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>12</b> Factorial Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="12.1" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#video"><i class="fa fa-check"></i><b>12.1</b> Video</a></li>
<li class="chapter" data-level="12.2" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#introduction-7"><i class="fa fa-check"></i><b>12.2</b> Introduction</a></li>
<li class="chapter" data-level="12.3" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#why-do-a-factorial-anova"><i class="fa fa-check"></i><b>12.3</b> Why do a factorial ANOVA?</a></li>
<li class="chapter" data-level="12.4" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#interactions"><i class="fa fa-check"></i><b>12.4</b> Interactions</a></li>
<li class="chapter" data-level="12.5" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#main-effects"><i class="fa fa-check"></i><b>12.5</b> Main Effects</a></li>
<li class="chapter" data-level="12.6" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#simple-effects"><i class="fa fa-check"></i><b>12.6</b> Simple Effects</a></li>
<li class="chapter" data-level="12.7" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#interaction-effect"><i class="fa fa-check"></i><b>12.7</b> Interaction Effect</a></li>
<li class="chapter" data-level="12.8" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#factorial-anova-is-really-3-anovas"><i class="fa fa-check"></i><b>12.8</b> Factorial ANOVA is really 3 ANOVAs</a></li>
<li class="chapter" data-level="12.9" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#interpret-interaction-effects-first"><i class="fa fa-check"></i><b>12.9</b> Interpret Interaction Effects First</a></li>
<li class="chapter" data-level="12.10" data-path="factorial-analysis-of-variance-anova.html"><a href="factorial-analysis-of-variance-anova.html#graphing-factorial-anova-means"><i class="fa fa-check"></i><b>12.10</b> Graphing Factorial ANOVA Means</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="statistics-reference.html"><a href="statistics-reference.html"><i class="fa fa-check"></i><b>13</b> Statistics Reference</a>
<ul>
<li class="chapter" data-level="13.1" data-path="statistics-reference.html"><a href="statistics-reference.html#one-sample-z-test"><i class="fa fa-check"></i><b>13.1</b> One-Sample <em>z</em>-Test</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition"><i class="fa fa-check"></i><b>13.1.1</b> Definition</a></li>
<li class="chapter" data-level="13.1.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic"><i class="fa fa-check"></i><b>13.1.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.1.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data"><i class="fa fa-check"></i><b>13.1.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.1.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it"><i class="fa fa-check"></i><b>13.1.4</b> When to use it</a></li>
<li class="chapter" data-level="13.1.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example"><i class="fa fa-check"></i><b>13.1.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="statistics-reference.html"><a href="statistics-reference.html#correlation"><i class="fa fa-check"></i><b>13.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-1"><i class="fa fa-check"></i><b>13.2.1</b> Definition</a></li>
<li class="chapter" data-level="13.2.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-1"><i class="fa fa-check"></i><b>13.2.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.2.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-1"><i class="fa fa-check"></i><b>13.2.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.2.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-1"><i class="fa fa-check"></i><b>13.2.4</b> When to use it</a></li>
<li class="chapter" data-level="13.2.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-1"><i class="fa fa-check"></i><b>13.2.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="statistics-reference.html"><a href="statistics-reference.html#linear-regression"><i class="fa fa-check"></i><b>13.3</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-2"><i class="fa fa-check"></i><b>13.3.1</b> Definition</a></li>
<li class="chapter" data-level="13.3.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-2"><i class="fa fa-check"></i><b>13.3.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.3.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-2"><i class="fa fa-check"></i><b>13.3.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.3.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-2"><i class="fa fa-check"></i><b>13.3.4</b> When to use it</a></li>
<li class="chapter" data-level="13.3.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-2"><i class="fa fa-check"></i><b>13.3.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="statistics-reference.html"><a href="statistics-reference.html#one-sample-t-test"><i class="fa fa-check"></i><b>13.4</b> One-Sample <em>t</em>-Test</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-3"><i class="fa fa-check"></i><b>13.4.1</b> Definition</a></li>
<li class="chapter" data-level="13.4.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-3"><i class="fa fa-check"></i><b>13.4.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.4.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-3"><i class="fa fa-check"></i><b>13.4.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.4.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-3"><i class="fa fa-check"></i><b>13.4.4</b> When to use it</a></li>
<li class="chapter" data-level="13.4.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-3"><i class="fa fa-check"></i><b>13.4.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="statistics-reference.html"><a href="statistics-reference.html#paired-samples-t-test"><i class="fa fa-check"></i><b>13.5</b> Paired Samples T-Test</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-4"><i class="fa fa-check"></i><b>13.5.1</b> Definition</a></li>
<li class="chapter" data-level="13.5.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-4"><i class="fa fa-check"></i><b>13.5.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.5.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-4"><i class="fa fa-check"></i><b>13.5.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.5.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-4"><i class="fa fa-check"></i><b>13.5.4</b> When to use it</a></li>
<li class="chapter" data-level="13.5.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-4"><i class="fa fa-check"></i><b>13.5.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="statistics-reference.html"><a href="statistics-reference.html#independent-samples-t-test"><i class="fa fa-check"></i><b>13.6</b> Independent Samples <span class="math inline">\(t\)</span>-Test</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-5"><i class="fa fa-check"></i><b>13.6.1</b> Definition</a></li>
<li class="chapter" data-level="13.6.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-5"><i class="fa fa-check"></i><b>13.6.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.6.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-5"><i class="fa fa-check"></i><b>13.6.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.6.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-5"><i class="fa fa-check"></i><b>13.6.4</b> When to use it</a></li>
<li class="chapter" data-level="13.6.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-5"><i class="fa fa-check"></i><b>13.6.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="statistics-reference.html"><a href="statistics-reference.html#one-way-anova"><i class="fa fa-check"></i><b>13.7</b> One-Way ANOVA</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-6"><i class="fa fa-check"></i><b>13.7.1</b> Definition</a></li>
<li class="chapter" data-level="13.7.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-6"><i class="fa fa-check"></i><b>13.7.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.7.3" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-6"><i class="fa fa-check"></i><b>13.7.3</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.7.4" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-6"><i class="fa fa-check"></i><b>13.7.4</b> When to use it</a></li>
<li class="chapter" data-level="13.7.5" data-path="statistics-reference.html"><a href="statistics-reference.html#example-1-between-subjects"><i class="fa fa-check"></i><b>13.7.5</b> Example 1: Between-Subjects</a></li>
<li class="chapter" data-level="13.7.6" data-path="statistics-reference.html"><a href="statistics-reference.html#example-2-within-subjects"><i class="fa fa-check"></i><b>13.7.6</b> Example 2: Within-Subjects</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="statistics-reference.html"><a href="statistics-reference.html#statguide-factorial"><i class="fa fa-check"></i><b>13.8</b> Factorial ANOVA</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="statistics-reference.html"><a href="statistics-reference.html#definition-7"><i class="fa fa-check"></i><b>13.8.1</b> Definition</a></li>
<li class="chapter" data-level="13.8.2" data-path="statistics-reference.html"><a href="statistics-reference.html#test-statistic-7"><i class="fa fa-check"></i><b>13.8.2</b> Test Statistic</a></li>
<li class="chapter" data-level="13.8.3" data-path="statistics-reference.html"><a href="statistics-reference.html#between-within-and-mixed-anova"><i class="fa fa-check"></i><b>13.8.3</b> Between, Within, and Mixed ANOVA</a></li>
<li class="chapter" data-level="13.8.4" data-path="statistics-reference.html"><a href="statistics-reference.html#assumptions-required-data-7"><i class="fa fa-check"></i><b>13.8.4</b> Assumptions &amp; Required Data</a></li>
<li class="chapter" data-level="13.8.5" data-path="statistics-reference.html"><a href="statistics-reference.html#when-to-use-it-7"><i class="fa fa-check"></i><b>13.8.5</b> When to use it</a></li>
<li class="chapter" data-level="13.8.6" data-path="statistics-reference.html"><a href="statistics-reference.html#example-mixed-anova"><i class="fa fa-check"></i><b>13.8.6</b> Example: Mixed ANOVA</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Advanced Statistics Remix</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistics-reference" class="section level1" number="13">
<h1><span class="header-section-number">Chapter 13</span> Statistics Reference</h1>
<div id="one-sample-z-test" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> One-Sample <em>z</em>-Test</h2>
<p><a href="https://youtu.be/TE61rB6ajTY">Video: The one-sample Z-test</a></p>
<div id="definition" class="section level3" number="13.1.1">
<h3><span class="header-section-number">13.1.1</span> Definition</h3>
<p>The one-sample z-test tests the null hypothesis that a mean is equivalent to the mean of a known population.</p>
</div>
<div id="test-statistic" class="section level3" number="13.1.2">
<h3><span class="header-section-number">13.1.2</span> Test Statistic</h3>
<p>The test statistic is <span class="math inline">\(z\)</span>, which measures the distance between two means. In this case, one mean is from our sample and the other mean is a known constant. The sampling distribution of <span class="math inline">\(z\)</span> is the normal distribution with a standard deviation defined by the formula for standard error (<span class="math inline">\(\sigma_{\bar{X}}\)</span>).</p>
<p><span class="math inline">\(z = \frac{\bar{X}-\mu}{\sigma_{\bar{X}}} = \frac{\bar{X}-\mu_{hyp}}{\frac{\sigma}{\sqrt{N}}}\)</span></p>
<div class="figure"><span style="display:block;" id="fig:znull"></span>
<img src="schuster-statistics-remix_files/figure-html/znull-1.png" alt="The null hypothesis distribution of $z$" width="672" />
<p class="caption">
Figure 13.1: The null hypothesis distribution of <span class="math inline">\(z\)</span>
</p>
</div>
</div>
<div id="assumptions-required-data" class="section level3" number="13.1.3">
<h3><span class="header-section-number">13.1.3</span> Assumptions &amp; Required Data</h3>
<ul>
<li>1 variable measured using a quantitative, continuous scale</li>
<li>The variable was measured for a sample that was taken randomly, with replacement, from a population</li>
<li>The normality assumption, meaning at least one of these:
<ul>
<li><span class="math inline">\(N \ge 30\)</span></li>
<li>The variable is normally distributed in the population</li>
</ul></li>
<li>The population mean, <span class="math inline">\(\mu\)</span>, is known.</li>
<li>The population standard deviation, <span class="math inline">\(\sigma\)</span>, is known</li>
</ul>
</div>
<div id="when-to-use-it" class="section level3" number="13.1.4">
<h3><span class="header-section-number">13.1.4</span> When to use it</h3>
<p>Use a <span class="math inline">\(z\)</span>-test when you are comparing a single sample mean to a known population parameter and can meet the assumptions.</p>
<p>If the population standard deviation is unknown, or if the normality assumption cannot be met, consider a <span class="math inline">\(t\)</span>-test.</p>
</div>
<div id="example" class="section level3" number="13.1.5">
<h3><span class="header-section-number">13.1.5</span> Example</h3>
<p>Imagine a high school has a graduation test with <span class="math inline">\(M = .80\)</span> with a standard deviation (<span class="math inline">\(\sigma\)</span>) of <span class="math inline">\(\sigma = .10\)</span>. A random sample of <span class="math inline">\(N = 35\)</span> students at the high school participate in an after-school program aimed at increasing performance on the graduation test.</p>
<div id="data" class="section level4" number="13.1.5.1">
<h4><span class="header-section-number">13.1.5.1</span> Data</h4>
<p>The data are test scores from 35 students.</p>
<pre><code>##  [1] 1.06 0.85 0.89 0.80 0.80 0.90 0.93 0.80 0.92 1.10 0.99 0.86 0.93 0.95
## [15] 1.03 0.94 1.11 0.84 0.95 0.99 0.85 0.72 0.92 0.88 0.81 0.91 0.90 0.72
## [29] 0.99 0.84 0.93 0.96 0.85 0.83 0.96</code></pre>
<pre><code>## [1] 0.906</code></pre>
<p>The students in the program took the test and performed higher than the population average (<span class="math inline">\(M=\)</span><code>print(mean(sample))</code>). Is there evidence that the after school program is effective?</p>
</div>
<div id="hypotheses-1" class="section level4" number="13.1.5.2">
<h4><span class="header-section-number">13.1.5.2</span> Hypotheses</h4>
<p>Because researchers are interested in detecting higher performance on the test, a one-tailed test is used to increase statistical power. If, instead, researchers wanted to see if the sample had higher or lower performance, a two-tailed test should be used.</p>
<pre><code>$H_0=\mu\le.80$

$H_a=\mu\gt.80$</code></pre>
</div>
<div id="analysis" class="section level4" number="13.1.5.3">
<h4><span class="header-section-number">13.1.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining a sample mean this distance from the population mean. We will determine this using the sampling distribution of the null hypothesis for <span class="math inline">\(z\)</span> (the normal distribution).</p>
<p>Unlike later statistical tests, R does not provide a built-in <span class="math inline">\(z\)</span>-test. This is actually a feature, as it lets us demonstrate the steps in more detail.</p>
<p>The most challenging part is the function <code>pnorm()</code>, which gives the area to the left of a score on the a standard normal distribution. By using the argument `<code>lower.tail = FALSE</code>, the function will give the area to the right of the score.</p>
<div class="sourceCode" id="cb943"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb943-1"><a href="statistics-reference.html#cb943-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> .<span class="dv">80</span></span>
<span id="cb943-2"><a href="statistics-reference.html#cb943-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> .<span class="dv">10</span></span>
<span id="cb943-3"><a href="statistics-reference.html#cb943-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(data)</span>
<span id="cb943-4"><a href="statistics-reference.html#cb943-4" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> (<span class="fu">mean</span>(sample) <span class="sc">-</span> mu) <span class="sc">/</span> (sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n))</span>
<span id="cb943-5"><a href="statistics-reference.html#cb943-5" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<pre><code>## [1] 1.06</code></pre>
<div class="sourceCode" id="cb945"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb945-1"><a href="statistics-reference.html#cb945-1" aria-hidden="true" tabindex="-1"></a>p_value <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(z, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>) <span class="co"># gives area to the right of the score, which is the p-value</span></span>
<span id="cb945-2"><a href="statistics-reference.html#cb945-2" aria-hidden="true" tabindex="-1"></a>p_value</span></code></pre></div>
<pre><code>## [1] 0.1445723</code></pre>
<p>To visualize this result, we can graph the location of the test statistic in the sampling distribution, shading everything beyond the test statistic in one tail:</p>
<div class="sourceCode" id="cb947"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb947-1"><a href="statistics-reference.html#cb947-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb947-2"><a href="statistics-reference.html#cb947-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="cn">NULL</span>, <span class="fu">aes</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>,<span class="dv">4</span>))) <span class="sc">+</span></span>
<span id="cb947-3"><a href="statistics-reference.html#cb947-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">stat =</span> <span class="st">&quot;function&quot;</span>, <span class="at">fun =</span> dnorm, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, z), <span class="at">alpha =</span> <span class="fl">0.5</span>,<span class="at">fill=</span><span class="fu">alpha</span>(<span class="st">&quot;grey&quot;</span>,<span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb947-4"><a href="statistics-reference.html#cb947-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">stat =</span> <span class="st">&quot;function&quot;</span>, <span class="at">fun =</span> dnorm, <span class="at">fill=</span><span class="st">&quot;blue&quot;</span>, <span class="at">xlim =</span> <span class="fu">c</span>(z, <span class="dv">4</span>), <span class="at">alpha =</span> <span class="fl">0.7</span>)</span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/zvisualization-1.png" width="672" /></p>
<p>The shaded area is well over 5 percent, showing visually that <span class="math inline">\(p&gt;\alpha\)</span>.</p>
</div>
<div id="decision" class="section level4" number="13.1.5.4">
<h4><span class="header-section-number">13.1.5.4</span> Decision</h4>
<p>Because <span class="math inline">\(p&gt;{\alpha}\)</span>, the null hypothesis is retained and the results are inconclusive. These data do not provide evidence of effectiveness of the program.</p>
</div>
<div id="variations" class="section level4" number="13.1.5.5">
<h4><span class="header-section-number">13.1.5.5</span> Variations</h4>
<ul>
<li><p>This was a one-tailed test on the right side of the distribution. The use of <code>rnorm()</code> would need to be adapted if the one-tailed test was on the left side of the distribution (to detect if scores were lower than the population). Simply omit <code>lower.tail = FALSE</code> to have <code>rnorm()</code> calculate from the left side (lower tail).</p></li>
<li><p>In a two-tailed test, the shading would need to be repeated on the left side, and the shaded area on both sides would need to be added together. You can save a step by knowing that each tail is always the same area. To convert this one-tailed p-value into a two-tailed p-value, you would need to double it, giving you a two-tailed p-value of <code>{r, echo=FALSE} print(p_value*2)</code>. When doing a two-tailed test, check to make sure you are calculating in the correct tail; if your two-tailed test had a sample mean lower than the population mean, you would want to shade/calculate to the left.</p></li>
<li><p>If <span class="math inline">\(p &lt; \alpha\)</span>, you would have rejected the null hypothesis and concluded that there was a difference between your sample mean and the population.</p></li>
</ul>
</div>
</div>
</div>
<div id="correlation" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Correlation</h2>
<div id="definition-1" class="section level3" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Definition</h3>
<p>A correlation analysis measures the strength and direction of a relationship between two variables. The hypothesis test for a correlation tests the null hypothesis that there is no linear relationship between two variables. This is also called a bivariate correlation (because it involves two variables) and the Pearson correlation coefficient.</p>
</div>
<div id="test-statistic-1" class="section level3" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Test Statistic</h3>
<p>The test statistic is actually a <span class="math inline">\(t\)</span> distribution calculated from the observed value of <span class="math inline">\(r\)</span>, which measures the strength and direction of the relationship. The statistic <span class="math inline">\(r\)</span> has values <span class="math inline">\(-1\le{r}\le 1\)</span>, with -1 indicating a perfect negative relationship and +1 indicating a perfect positive relationship. <span class="math inline">\(r = 0\)</span> indicates no relationship between the variables and is rarely observed to be exactly 0 in practice. To conduct a hypothesis test, <span class="math inline">\(r\)</span> is converted to a value of <span class="math inline">\(t\)</span> because this function of the sampling distribution of <span class="math inline">\(r\)</span> follows a <span class="math inline">\(t\)</span>-distribution:</p>
<p><span class="math inline">\(t = r\sqrt{\frac{n-2}{1-r^2}}\)</span></p>
<p>This function can be reversed as <span class="math inline">\(r=\frac{t}{\sqrt{n-2+t^2}}\)</span></p>
<div class="figure"><span style="display:block;" id="fig:corrnull"></span>
<img src="schuster-statistics-remix_files/figure-html/corrnull-1.png" alt="The null hypothesis distribution of $t$ with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df." width="672" />
<p class="caption">
Figure 13.2: The null hypothesis distribution of <span class="math inline">\(t\)</span> with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df.
</p>
</div>
<p>The <span class="math inline">\(t\)</span> distribution is actually a family of distributions defined by degrees of freedom. <strong>Degrees of freedom</strong> is a concept that can be interpreted multiple ways. For now, it is sufficient to say that it is based on sample size. The value of degrees of freedom grows by 1 with each additional unit increased in the sample. In other words, the specific sampling distribution used in the hypothesis test depends on the sample size (and degrees of freedom).</p>
</div>
<div id="assumptions-required-data-1" class="section level3" number="13.2.3">
<h3><span class="header-section-number">13.2.3</span> Assumptions &amp; Required Data</h3>
<p>For more detail, see <a href="regression.html#regressionassumptions">8.12</a>.</p>
<ul>
<li>2 quantitative variables (interval or ratio), or one quantitative variable with a dichotomous (two possible values) variable. The later version is called a point-biserial correlation and is mathematically the same as the Pearson correlation coefficient. Note that this procedure is not appropriate for ordinal variables, and Spearman’s rank correlation coefficient should be used instead.</li>
<li>Normality, meaning normal distribution of residuals.</li>
<li>Linearity</li>
<li>Homogeneity of variance (also called homoscedasiticty and equality of variance)</li>
<li>No outliers</li>
</ul>
</div>
<div id="when-to-use-it-1" class="section level3" number="13.2.4">
<h3><span class="header-section-number">13.2.4</span> When to use it</h3>
<p>Use a correlation when you want to detect a linear relationship between two variables.</p>
</div>
<div id="example-1" class="section level3" number="13.2.5">
<h3><span class="header-section-number">13.2.5</span> Example</h3>
<p><span class="citation"><a href="#ref-Navarro2018" role="doc-biblioref">Navarro</a> (<a href="#ref-Navarro2018" role="doc-biblioref">2018</a>)</span> wanted to see if there was a relationship between hours slept in a night and their rating of grumpiness the next day.</p>
<div id="data-1" class="section level4" number="13.2.5.1">
<h4><span class="header-section-number">13.2.5.1</span> Data</h4>
<p>The data are two variables, one indicating sleep and the other indicating grumpiness. Data were collected for 100 nights.</p>
<pre><code>##     dan.sleep baby.sleep dan.grump day
## 1        7.59      10.18        56   1
## 2        7.91      11.66        60   2
## 3        5.14       7.92        82   3
## 4        7.71       9.61        55   4
## 5        6.68       9.75        67   5
## 6        5.99       5.04        72   6
## 7        8.19      10.45        53   7
## 8        7.19       8.27        60   8
## 9        7.40       6.06        60   9
## 10       6.58       7.09        71  10
## 11       6.49      11.68        72  11
## 12       6.27       6.13        65  12
## 13       5.95       7.83        74  13
## 14       6.65       5.60        67  14
## 15       6.41       6.03        66  15
## 16       6.33       8.19        69  16
## 17       6.30       6.38        73  17
## 18       8.47      11.11        52  18
## 19       7.21       5.51        61  19
## 20       7.53       6.69        53  20
## 21       8.00       9.74        54  21
## 22       7.35       9.02        63  22
## 23       6.86       6.44        74  23
## 24       7.86       9.43        56  24
## 25       4.86       3.46        82  25
## 26       5.87       6.32        72  26
## 27       8.40       7.95        59  27
## 28       6.93       7.69        66  28
## 29       7.21       7.45        60  29
## 30       6.99       7.56        67  30
## 31       8.17       7.95        44  31
## 32       7.85      11.61        53  32
## 33       6.27       4.70        76  33
## 34       8.66       8.52        41  34
## 35       4.98       4.70        86  35
## 36       6.19       8.32        60  36
## 37       6.41       9.38        63  37
## 38       4.84       4.18        89  38
## 39       7.03       5.98        61  39
## 40       7.66       9.29        57  40
## 41       7.51       6.01        59  41
## 42       7.92      10.54        60  42
## 43       8.12      11.78        48  43
## 44       7.47      11.60        53  44
## 45       7.99      11.35        50  45
## 46       5.44       5.63        72  46
## 47       8.16       6.98        57  47
## 48       7.62       6.03        60  48
## 49       5.87       4.66        70  49
## 50       9.00       9.81        46  50
## 51       8.31      12.07        58  51
## 52       6.71       7.57        68  52
## 53       7.43      11.35        58  53
## 54       5.90       5.47        71  54
## 55       8.52       8.29        52  55
## 56       6.03       6.80        74  56
## 57       7.29      10.63        59  57
## 58       7.32       8.59        59  58
## 59       6.88       7.82        67  59
## 60       6.22       7.18        67  60
## 61       6.94       8.29        61  61
## 62       7.01      11.08        64  62
## 63       7.20       6.46        61  63
## 64       6.30       3.25        61  64
## 65       8.72       9.74        54  65
## 66       7.82       8.75        62  66
## 67       8.14      11.75        52  67
## 68       7.27       9.31        64  68
## 69       6.70       7.73        65  69
## 70       7.55       8.68        65  70
## 71       7.38       9.77        57  71
## 72       7.73       9.71        59  72
## 73       5.32       4.17        79  73
## 74       7.86      10.18        53  74
## 75       6.35       9.28        67  75
## 76       7.11       7.23        61  76
## 77       5.45       6.38        82  77
## 78       7.80       9.20        68  78
## 79       7.13       8.20        67  79
## 80       8.35      10.16        54  80
## 81       6.93       8.95        53  81
## 82       7.07       6.80        62  82
## 83       8.66       8.34        50  83
## 84       5.09       6.25        80  84
## 85       4.91       6.75        91  85
## 86       7.03       9.09        62  86
## 87       7.02      10.42        64  87
## 88       7.67       8.89        57  88
## 89       8.15       9.43        54  89
## 90       5.88       6.79        72  90
## 91       5.72       6.91        78  91
## 92       6.66       6.05        63  92
## 93       6.85       6.32        59  93
## 94       5.57       8.62        74  94
## 95       5.16       7.84        76  95
## 96       5.31       5.89        79  96
## 97       7.77       9.77        51  97
## 98       5.38       6.97        82  98
## 99       7.02       6.56        55  99
## 100      6.45       7.93        74 100</code></pre>
</div>
<div id="hypotheses-2" class="section level4" number="13.2.5.2">
<h4><span class="header-section-number">13.2.5.2</span> Hypotheses</h4>
<p>Given their often-exploratory use, correlations are typically conducted as two-tailed tests. However, a one-tailed correlation could be conducted if researchers predict a direction for the effect.</p>
<p>Hypotheses are always written with population parameters (since we are making hypotheses about truth in the population, not what we have observed in our sample). The population parameter corresponding to the test statistic <span class="math inline">\(r\)</span> is <span class="math inline">\(\rho\)</span> (rho). The null is that there is no relationship. The alternative hypothesis is that there is a relationship.</p>
<p><span class="math inline">\(H_0=\rho=0\)</span></p>
<p><span class="math inline">\(H_a=\rho\ne0\)</span></p>
</div>
<div id="analysis-1" class="section level4" number="13.2.5.3">
<h4><span class="header-section-number">13.2.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining an effect size (<span class="math inline">\(r\)</span>) this strong at our sample size through random sampling from a population with effect size <span class="math inline">\(\rho=0\)</span>. We will determine this using the sampling distribution of the null hypothesis for <span class="math inline">\(t\)</span>.</p>
<p>There are several ways to generate correlations in R:</p>
<ul>
<li><code>cor()</code> will output just the correlation coefficient</li>
<li><code>cor.test()</code> will perform NHST and give a p-value</li>
</ul>
<div class="sourceCode" id="cb949"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb949-1"><a href="statistics-reference.html#cb949-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>( <span class="at">x =</span> parenthood<span class="sc">$</span>dan.sleep, <span class="at">y =</span> parenthood<span class="sc">$</span>dan.grump )</span></code></pre></div>
<pre><code>## [1] -0.903384</code></pre>
<div class="sourceCode" id="cb951"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb951-1"><a href="statistics-reference.html#cb951-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor.test</span>(<span class="at">x =</span> parenthood<span class="sc">$</span>dan.sleep, <span class="at">y =</span> parenthood<span class="sc">$</span>dan.grump)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  parenthood$dan.sleep and parenthood$dan.grump
## t = -20.854, df = 98, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.9340614 -0.8594714
## sample estimates:
##       cor 
## -0.903384</code></pre>
<p>To visualize this result, we can graph a scatterplot, with observed values of one variable plotted against the observed value of the second variable:</p>
<div class="sourceCode" id="cb953"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb953-1"><a href="statistics-reference.html#cb953-1" aria-hidden="true" tabindex="-1"></a>oneCorPlot <span class="ot">&lt;-</span> <span class="cf">function</span>(x,y,...) {</span>
<span id="cb953-2"><a href="statistics-reference.html#cb953-2" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb953-3"><a href="statistics-reference.html#cb953-3" aria-hidden="true" tabindex="-1"></a>        <span class="fu">plot</span>(x,y,<span class="at">pch=</span><span class="dv">19</span>,<span class="at">col=</span>(<span class="st">&quot;black&quot;</span>),...)</span>
<span id="cb953-4"><a href="statistics-reference.html#cb953-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb953-5"><a href="statistics-reference.html#cb953-5" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb953-6"><a href="statistics-reference.html#cb953-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb953-7"><a href="statistics-reference.html#cb953-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">oneCorPlot</span>( parenthood<span class="sc">$</span>dan.sleep, parenthood<span class="sc">$</span>dan.grump, </span>
<span id="cb953-8"><a href="statistics-reference.html#cb953-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;Sleep (hours)&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Grumpiness&quot;</span></span>
<span id="cb953-9"><a href="statistics-reference.html#cb953-9" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/corrvisualization-1.png" width="672" /></p>
<p>The magnitude of r (it’s value) indicates the strength of the relationship. The closer the value of <span class="math inline">\(r\)</span> to <span class="math inline">\(\pm1\)</span>, the more closely the points hug a straight line. The line will have a positive slope if the relationship is positive and a negative slope if the relationship is negative.</p>
</div>
<div id="decision-1" class="section level4" number="13.2.5.4">
<h4><span class="header-section-number">13.2.5.4</span> Decision</h4>
<p>Because <span class="math inline">\(p&lt;{\alpha}\)</span>, the null hypothesis is rejected and we conclude that there is a relationship between sleep and grumpiness. Further, because the value of <span class="math inline">\(r\)</span> is negative, the relationship between grumpiness and sleep is that higher amounts of sleep are associated with lower levels of grumpiness.</p>
</div>
<div id="variations-1" class="section level4" number="13.2.5.5">
<h4><span class="header-section-number">13.2.5.5</span> Variations</h4>
<ul>
<li>If data are ordinal, Spearman’s rank order correlation can be calculated by adding the argument method = “separman” using the following syntax:</li>
</ul>
<p><code>cor( x, y, method = "spearman")</code></p>
<ul>
<li><p>In a two-tailed test, the shading would need to be repeated on the left side, and the shaded area on both sides would need to be added together. You can save a step by knowing that each tail is always the same area. To convert this one-tailed p-value into a two-tailed p-value, you would need to double it, giving you a two-tailed p-value of <code>{r, echo=FALSE} print(p_value*2)</code>. When doing a two-tailed test, check to make sure you are calculating in the correct tail; if your two-tailed test had a sample mean lower than the population mean, you would want to shade/calculate to the left.</p></li>
<li><p>If <span class="math inline">\(p \ge \alpha\)</span>, you would have retained the null hypothesis and made no conclusion.</p></li>
<li><p>You can calculate a <strong>correlation matrix</strong> that shows all possible bivariate correlations from a dataframe. Simply include the entire dataframe as the argument instead of two variables, like this:</p></li>
</ul>
<div class="sourceCode" id="cb954"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb954-1"><a href="statistics-reference.html#cb954-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>( <span class="at">x =</span> parenthood)</span></code></pre></div>
<pre><code>##              dan.sleep  baby.sleep   dan.grump         day
## dan.sleep   1.00000000  0.62794934 -0.90338404 -0.09840768
## baby.sleep  0.62794934  1.00000000 -0.56596373 -0.01043394
## dan.grump  -0.90338404 -0.56596373  1.00000000  0.07647926
## day        -0.09840768 -0.01043394  0.07647926  1.00000000</code></pre>
<p>When using a correlation matrix, p-values are not interpretable because the probability of a type I error on one or more of these correlations is higher than .05 (because the alpha level of .05 is used on each one, and many tests are being conducted).</p>
</div>
</div>
</div>
<div id="linear-regression" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Linear Regression</h2>
<div id="definition-2" class="section level3" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Definition</h3>
<p>Linear regression creates a linear model that can be used to predict an outcome variable from one or more predictor variables. The hypothesis test for a linear regression occurs in two stages. The first stage, called the <strong>omnibus test</strong>, is a hypothesis test of the entire model. If this test is significant, researchers can conclude that the collection of variables significantly predicts the outcome. Assuming significance, the second stage follows in which each predictor variable is tested with a against the null hypothesis that its regression coefficient is zero.</p>
</div>
<div id="test-statistic-2" class="section level3" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Test Statistic</h3>
<p>The omnibus test uses an <span class="math inline">\(F\)</span>-test to test the null hypothesis that there is no linear relationship between the outcome variable and the linear combination of the predictor variables. Or, that the variance explained by the predictor variables is no more than the variance explained by the mean. Tests of each coefficient use <span class="math inline">\(t\)</span>-tests. The statistics <span class="math inline">\(F\)</span> and <span class="math inline">\(t\)</span> are related such that <span class="math inline">\(t=\sqrt{F}\)</span> and <span class="math inline">\(F=t^2\)</span>.</p>
<p><span class="math display">\[
F =  \frac{\mbox{MS}_{model}}{\mbox{MS}_{residual}}
\]</span>
<span class="math display">\[
t = \frac{\hat{b}}{\mbox{SE}({\hat{b})}}
\]</span></p>
<p>As with <span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span> is a family of distributions defined around two degrees of freedom.</p>
<div class="figure"><span style="display:block;" id="fig:regressionnull"></span>
<img src="schuster-statistics-remix_files/figure-html/regressionnull-1.png" alt="Graph of the sampling distribution of F used under Creative Commons License from Hartmann, K., Krois, J., Waske, B. (2018): E-Learning Project SOGA: Statistics and Geospatial Data Analysis. Department of Earth Sciences, Freie Universitaet Berlin." width="672" />
<p class="caption">
Figure 13.3: Graph of the sampling distribution of F used under Creative Commons License from Hartmann, K., Krois, J., Waske, B. (2018): E-Learning Project SOGA: Statistics and Geospatial Data Analysis. Department of Earth Sciences, Freie Universitaet Berlin.
</p>
</div>
</div>
<div id="assumptions-required-data-2" class="section level3" number="13.3.3">
<h3><span class="header-section-number">13.3.3</span> Assumptions &amp; Required Data</h3>
<p>For more detail, see <a href="regression.html#regressionassumptions">8.12</a>.</p>
<ul>
<li>A single quantitative outcome variable (interval or ratio), and one or more quantitative or dichotomous (two possible values) variables. Note that this procedure is not appropriate for ordinal variables.</li>
<li>Normality of residuals</li>
<li>Linearity</li>
<li>Homogeneity of variance (also called homoscedasiticty and equality of variance)</li>
<li>Uncorrelated predictors</li>
<li>Residuals that are independent of each other</li>
<li>No outliers</li>
</ul>
</div>
<div id="when-to-use-it-2" class="section level3" number="13.3.4">
<h3><span class="header-section-number">13.3.4</span> When to use it</h3>
<p>Use a regression when you want to formulate and test a linear model, including mediating and moderating variables. Regression can also be used to run ANOVAs.</p>
</div>
<div id="example-2" class="section level3" number="13.3.5">
<h3><span class="header-section-number">13.3.5</span> Example</h3>
<p>The same data from the correlation guide will be used. <span class="citation"><a href="#ref-Navarro2018" role="doc-biblioref">Navarro</a> (<a href="#ref-Navarro2018" role="doc-biblioref">2018</a>)</span> wanted to see if hours slept in a night and hours the baby slept in a night could predict their rating of grumpiness the next day.</p>
<div id="data-2" class="section level4" number="13.3.5.1">
<h4><span class="header-section-number">13.3.5.1</span> Data</h4>
<p>The data are three variables, one indicating hours slept (predictor 1), one indicating the hours slept by the baby (predictor 2), and the other (the outcome) indicating grumpiness. Data were collected for 100 nights.</p>
<pre><code>##     dan.sleep baby.sleep dan.grump day
## 1        7.59      10.18        56   1
## 2        7.91      11.66        60   2
## 3        5.14       7.92        82   3
## 4        7.71       9.61        55   4
## 5        6.68       9.75        67   5
## 6        5.99       5.04        72   6
## 7        8.19      10.45        53   7
## 8        7.19       8.27        60   8
## 9        7.40       6.06        60   9
## 10       6.58       7.09        71  10
## 11       6.49      11.68        72  11
## 12       6.27       6.13        65  12
## 13       5.95       7.83        74  13
## 14       6.65       5.60        67  14
## 15       6.41       6.03        66  15
## 16       6.33       8.19        69  16
## 17       6.30       6.38        73  17
## 18       8.47      11.11        52  18
## 19       7.21       5.51        61  19
## 20       7.53       6.69        53  20
## 21       8.00       9.74        54  21
## 22       7.35       9.02        63  22
## 23       6.86       6.44        74  23
## 24       7.86       9.43        56  24
## 25       4.86       3.46        82  25
## 26       5.87       6.32        72  26
## 27       8.40       7.95        59  27
## 28       6.93       7.69        66  28
## 29       7.21       7.45        60  29
## 30       6.99       7.56        67  30
## 31       8.17       7.95        44  31
## 32       7.85      11.61        53  32
## 33       6.27       4.70        76  33
## 34       8.66       8.52        41  34
## 35       4.98       4.70        86  35
## 36       6.19       8.32        60  36
## 37       6.41       9.38        63  37
## 38       4.84       4.18        89  38
## 39       7.03       5.98        61  39
## 40       7.66       9.29        57  40
## 41       7.51       6.01        59  41
## 42       7.92      10.54        60  42
## 43       8.12      11.78        48  43
## 44       7.47      11.60        53  44
## 45       7.99      11.35        50  45
## 46       5.44       5.63        72  46
## 47       8.16       6.98        57  47
## 48       7.62       6.03        60  48
## 49       5.87       4.66        70  49
## 50       9.00       9.81        46  50
## 51       8.31      12.07        58  51
## 52       6.71       7.57        68  52
## 53       7.43      11.35        58  53
## 54       5.90       5.47        71  54
## 55       8.52       8.29        52  55
## 56       6.03       6.80        74  56
## 57       7.29      10.63        59  57
## 58       7.32       8.59        59  58
## 59       6.88       7.82        67  59
## 60       6.22       7.18        67  60
## 61       6.94       8.29        61  61
## 62       7.01      11.08        64  62
## 63       7.20       6.46        61  63
## 64       6.30       3.25        61  64
## 65       8.72       9.74        54  65
## 66       7.82       8.75        62  66
## 67       8.14      11.75        52  67
## 68       7.27       9.31        64  68
## 69       6.70       7.73        65  69
## 70       7.55       8.68        65  70
## 71       7.38       9.77        57  71
## 72       7.73       9.71        59  72
## 73       5.32       4.17        79  73
## 74       7.86      10.18        53  74
## 75       6.35       9.28        67  75
## 76       7.11       7.23        61  76
## 77       5.45       6.38        82  77
## 78       7.80       9.20        68  78
## 79       7.13       8.20        67  79
## 80       8.35      10.16        54  80
## 81       6.93       8.95        53  81
## 82       7.07       6.80        62  82
## 83       8.66       8.34        50  83
## 84       5.09       6.25        80  84
## 85       4.91       6.75        91  85
## 86       7.03       9.09        62  86
## 87       7.02      10.42        64  87
## 88       7.67       8.89        57  88
## 89       8.15       9.43        54  89
## 90       5.88       6.79        72  90
## 91       5.72       6.91        78  91
## 92       6.66       6.05        63  92
## 93       6.85       6.32        59  93
## 94       5.57       8.62        74  94
## 95       5.16       7.84        76  95
## 96       5.31       5.89        79  96
## 97       7.77       9.77        51  97
## 98       5.38       6.97        82  98
## 99       7.02       6.56        55  99
## 100      6.45       7.93        74 100</code></pre>
</div>
<div id="hypotheses-3" class="section level4" number="13.3.5.2">
<h4><span class="header-section-number">13.3.5.2</span> Hypotheses</h4>
<p>All <span class="math inline">\(F\)</span>-tests have two-tailed, directionless hypotheses. Because the omnibus test uses the <span class="math inline">\(F\)</span>-distribution, all regression omnibus tests are two-tailed.</p>
<p>The null is that the mean (which is the y-intercept, or <span class="math inline">\(b_0\)</span>) predicts the outcome variable (<span class="math inline">\(Y_i\)</span>) as well as the model. The alternative hypothesis is that the predictors add explained variance.</p>
<p><span class="math display">\[
H_0: Y_i = b_0 + \epsilon_i
\]</span>
<span class="math display">\[
H_a: Y_i = \left( \sum_{k=1}^K b_{k} X_{ik} \right) + b_0 + \epsilon_i
\]</span></p>
</div>
<div id="analysis-2" class="section level4" number="13.3.5.3">
<h4><span class="header-section-number">13.3.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining an effect size (in this case, the predictive power of our model over the null model with only the mean, measured using <span class="math inline">\(R^2\)</span>) this strong at our sample size through random sampling from a population with no effect (a null model). We will determine this using an analysis of variance using the sampling distribution of the null hypothesis for <span class="math inline">\(F\)</span>.</p>
<div class="sourceCode" id="cb957"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb957-1"><a href="statistics-reference.html#cb957-1" aria-hidden="true" tabindex="-1"></a>regression<span class="fl">.2</span> <span class="ot">&lt;-</span> <span class="fu">lm</span>( <span class="at">formula =</span> dan.grump <span class="sc">~</span> dan.sleep <span class="sc">+</span> baby.sleep,  </span>
<span id="cb957-2"><a href="statistics-reference.html#cb957-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">data =</span> parenthood )</span>
<span id="cb957-3"><a href="statistics-reference.html#cb957-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(regression<span class="fl">.2</span>)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = dan.grump ~ dan.sleep + baby.sleep, data = parenthood)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -11.0345  -2.2198  -0.4016   2.6775  11.7496 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 125.96557    3.04095  41.423   &lt;2e-16 ***
## dan.sleep    -8.95025    0.55346 -16.172   &lt;2e-16 ***
## baby.sleep    0.01052    0.27106   0.039    0.969    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.354 on 97 degrees of freedom
## Multiple R-squared:  0.8161, Adjusted R-squared:  0.8123 
## F-statistic: 215.2 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb959"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb959-1"><a href="statistics-reference.html#cb959-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(regression<span class="fl">.2</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                  2.5 %      97.5 %
## (Intercept) 119.930125 132.0010063
## dan.sleep   -10.048710  -7.8517895
## baby.sleep   -0.527462   0.5485109</code></pre>
<p>The omnibus test can be found in the last row as F-statistic. Here, the omnibus test was significant, <span class="math inline">\(F\)</span>(2, 97) = 215.2, <span class="math inline">\(p\)</span> &lt; .001, <span class="math inline">\(R^2=0.82\)</span>, suggesting that the model significantly predicts grumpiness.</p>
<p>While a multiple regression with more than one predictor cannot be visualized easily, you could generate <a href="https://www.statology.org/plot-multiple-linear-regression-in-r/">added variable plots</a> for each predictor.</p>
</div>
<div id="decision-2" class="section level4" number="13.3.5.4">
<h4><span class="header-section-number">13.3.5.4</span> Decision</h4>
<div id="omnibus-test" class="section level5" number="13.3.5.4.1">
<h5><span class="header-section-number">13.3.5.4.1</span> Omnibus Test</h5>
<p>Because <span class="math inline">\(p&lt;{\alpha}\)</span>, the null hypothesis is rejected and we conclude that grumpiness can be predicted by the linear combination of hours slept and hours the baby slept. However, we do not know which variable(s) significantly explain variance. Because we have a significant omnibus test, we are now justified in testing the coefficients.</p>
</div>
<div id="test-of-coefficients" class="section level5" number="13.3.5.4.2">
<h5><span class="header-section-number">13.3.5.4.2</span> Test of Coefficients</h5>
<p><span class="math inline">\(t\)</span>-tests are conducted for each coefficient in the <code>summary()</code> table. The hours slept coefficient was a significant predictor, <span class="math inline">\(t\)</span>(97) = -16.17, <span class="math inline">\(p\)</span> &lt; .001, 95% CI [-10.05, -7.85]. As hours slept increased, grumpiness decreased. The hours the baby slept was not a significant predictor, <span class="math inline">\(t\)</span>(97) = -16.17, <span class="math inline">\(p\)</span> &lt; .001, 95% CI [-0.53, 0.55].</p>
<p>Note that the degrees of freedom are the residual degrees of freedom (the second number). <span class="math inline">\(F\)</span> tests are always reported with the model degrees of freedom first (2) and the residual degrees of freedom second (97).</p>
</div>
</div>
<div id="variations-2" class="section level4" number="13.3.5.5">
<h4><span class="header-section-number">13.3.5.5</span> Variations</h4>
<p>This guide will be updated to add assumption checking and diagnostics procedures for regression.</p>

</div>
</div>
</div>
<div id="one-sample-t-test" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> One-Sample <em>t</em>-Test</h2>
<div id="definition-3" class="section level3" number="13.4.1">
<h3><span class="header-section-number">13.4.1</span> Definition</h3>
<p>The one-sample t-test tests the null hypothesis that a mean is equivalent to the mean of a known population. Unlike the <span class="math inline">\(z\)</span>-test, the <span class="math inline">\(t\)</span>-test uses the sample deviation as an estimator for the population standard deviation.</p>
</div>
<div id="test-statistic-3" class="section level3" number="13.4.2">
<h3><span class="header-section-number">13.4.2</span> Test Statistic</h3>
<p>The test statistic is <span class="math inline">\(t\)</span>, which measures the distance between two means. In this case, one mean is from our sample and the other mean is a known constant.</p>
<p><span class="math inline">\({t}=\frac{\bar{X}-\mu_0}{\frac{s}{\sqrt{n}}}\)</span></p>
<p><span class="math inline">\(\sigma_{\bar{X}}=\frac{\sigma}{\sqrt{n}}\)</span> (standard error of the mean)</p>
<p>Confidence interval (results in a lower and upper bound): <span class="math inline">\({CI}=\bar{X}\pm t_{critical} * \sigma_{\bar{X}}\)</span></p>
<p>Note that the confidence interval is given as a minimum and maximum value.</p>
<p><span class="math inline">\(df=n-1\)</span></p>
<div class="figure"><span style="display:block;" id="fig:onetnull"></span>
<img src="schuster-statistics-remix_files/figure-html/onetnull-1.png" alt="The null hypothesis distribution of $t$ with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df." width="672" />
<p class="caption">
Figure 13.4: The null hypothesis distribution of <span class="math inline">\(t\)</span> with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df.
</p>
</div>
<p>The <span class="math inline">\(t\)</span> distribution is actually a family of distributions defined by degrees of freedom. <strong>Degrees of freedom</strong> is a concept that can be interpreted multiple ways. For now, it is sufficient to say that it is based on sample size. The value of degrees of freedom grows by 1 with each additional unit increased in the sample. In other words, the specific sampling distribution used in the hypothesis test depends on the sample size (and degrees of freedom).</p>
</div>
<div id="assumptions-required-data-3" class="section level3" number="13.4.3">
<h3><span class="header-section-number">13.4.3</span> Assumptions &amp; Required Data</h3>
<ul>
<li>1 variable measured using a quantitative, continuous scale</li>
<li>The variable was measured for a sample that was taken randomly, with replacement, from a population</li>
<li>The normality assumption, meaning at least one of these:
<ul>
<li><span class="math inline">\(N \ge 30\)</span></li>
<li>The variable is normally distributed in the population</li>
</ul></li>
<li>The population mean, <span class="math inline">\(\mu\)</span>, is known.</li>
<li>The population standard deviation, <span class="math inline">\(\sigma\)</span>, is estimated from the sample standard deviation, <span class="math inline">\(s\)</span>.</li>
</ul>
</div>
<div id="when-to-use-it-3" class="section level3" number="13.4.4">
<h3><span class="header-section-number">13.4.4</span> When to use it</h3>
<p>Use a <span class="math inline">\(t\)</span>-test when you are comparing a single sample mean to a known population parameter and can meet the assumptions. This is nearly every situation in which you would use a <span class="math inline">\(z\)</span>-test. In fact, as sample size surpasses 30, the <span class="math inline">\(t\)</span> and <span class="math inline">\(z\)</span> distributions converge.</p>
</div>
<div id="example-3" class="section level3" number="13.4.5">
<h3><span class="header-section-number">13.4.5</span> Example</h3>
<p>Imagine a high school has a graduation test with <span class="math inline">\(M = .80\)</span> with a standard deviation (<span class="math inline">\(\sigma\)</span>) of <span class="math inline">\(\sigma = .10\)</span>. A random sample of <span class="math inline">\(N = 35\)</span> students at the high school participate in an after-school program aimed at increasing performance on the graduation test.</p>
<div id="data-3" class="section level4" number="13.4.5.1">
<h4><span class="header-section-number">13.4.5.1</span> Data</h4>
<p>The data are test scores from 35 students.</p>
<pre><code>##  [1] 0.81 0.73 0.87 0.93 0.93 0.86 1.00 0.72 1.06 0.78 0.86 1.00 0.79 0.75
## [15] 0.96 1.03 0.86 0.78 0.89 0.97 0.84 1.05 0.80 0.99 0.74 0.85 0.92 0.79
## [29] 1.05 0.71 0.88 0.92 0.95 0.89 1.00</code></pre>
<pre><code>## [1] 0.8845714</code></pre>
<p>The students in the program took the test and performed higher than the population average (<span class="math inline">\(M=\)</span><code>mean(sample)</code>). Is there evidence that the after school program is effective?</p>
</div>
<div id="hypotheses-4" class="section level4" number="13.4.5.2">
<h4><span class="header-section-number">13.4.5.2</span> Hypotheses</h4>
<p>Because researchers are interested in detecting higher performance on the test, a one-tailed test is used to increase statistical power. If, instead, researchers wanted to see if the sample had higher or lower performance, a two-tailed test should be used.</p>
<p><span class="math display">\[
\begin{array}{ll}
H_0 = \mu \le .80  \\
H_a = \mu &gt; .80
\end{array}
\]</span></p>
</div>
<div id="analysis-3" class="section level4" number="13.4.5.3">
<h4><span class="header-section-number">13.4.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining a sample mean this distance from the population mean. We will determine this using the sampling distribution of the null hypothesis for <span class="math inline">\(t\)</span>.</p>
<div class="sourceCode" id="cb963"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb963-1"><a href="statistics-reference.html#cb963-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(sample, <span class="at">mu =</span> .<span class="dv">8</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>) <span class="co"># two-sided, greater, or less</span></span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  sample
## t = 4.8632, df = 34, p-value = 1.291e-05
## alternative hypothesis: true mean is greater than 0.8
## 95 percent confidence interval:
##  0.8551663       Inf
## sample estimates:
## mean of x 
## 0.8845714</code></pre>
<p>Note that in the syntax for the t-test, you can specify an alternative hypothesis of “two-sided” (two-tailed), “greater,” or “less.”</p>
</div>
<div id="effect-size-1" class="section level4" number="13.4.5.4">
<h4><span class="header-section-number">13.4.5.4</span> Effect Size</h4>
<p>Cohen’s d is a measure of effect size for a t-test.</p>
<p><span class="math inline">\(d=(\mu- \mu_0)/s\)</span></p>
</div>
<div id="decision-3" class="section level4" number="13.4.5.5">
<h4><span class="header-section-number">13.4.5.5</span> Decision</h4>
<p>Because <span class="math inline">\(p &lt; \alpha\)</span>, you reject the null hypothesis and concluded that there was a difference between your sample mean and the population.</p>
</div>
<div id="variations-3" class="section level4" number="13.4.5.6">
<h4><span class="header-section-number">13.4.5.6</span> Variations</h4>
<ul>
<li><p>This was a one-tailed test on the right side of the distribution. The use of <code>alternative = "greater"</code> would need to be adapted if the one-tailed test was on the left side of the distribution (to detect if scores were lower than the population). Simply change <code>alternative = "greater"</code> to have <code>"less"</code> calculate from the left side (lower tail).</p></li>
<li><p>In a two-tailed test, the shading would need to be repeated on the left side, and the shaded area on both sides would need to be added together. Simply change <code>alternative = "greater"</code> to have <code>"two-sided"</code>. If you omit the <code>alternative</code> argument completely, the default is a two-tailed test.</p></li>
<li><p>If <span class="math inline">\(p&gt;{\alpha}\)</span>, the null hypothesis would have been retained and the results inconclusive.</p></li>
</ul>
</div>
</div>
</div>
<div id="paired-samples-t-test" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> Paired Samples T-Test</h2>
<div id="definition-4" class="section level3" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Definition</h3>
<p>A paired samples t-test measures the difference between two means collected from a within-subjects (also called repeated measures) design. In a within-subjects design, each unit is measured exactly twice. A longitudinal study that measured participants at two points in time could be analyzed with a paired-samples t-test. The hypothesis test for this t-test tests the null hypothesis that there is no difference between the two measurements.</p>
</div>
<div id="test-statistic-4" class="section level3" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Test Statistic</h3>
<p>The test statistic is <span class="math inline">\(t\)</span>, which measures the difference between the two measurements.</p>
<span class="math display">\[
t = \frac{\bar{D}}{\hat\sigma_D / \sqrt{N}}
\]</span>
<div class="figure"><span style="display:block;" id="fig:pairedtnull"></span>
<img src="schuster-statistics-remix_files/figure-html/pairedtnull-1.png" alt="The null hypothesis distribution of $t$ with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df." width="672" />
<p class="caption">
Figure 13.5: The null hypothesis distribution of <span class="math inline">\(t\)</span> with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df.
</p>
</div>
<p>The <span class="math inline">\(t\)</span> distribution is actually a family of distributions defined by degrees of freedom. <strong>Degrees of freedom</strong> is a concept that can be interpreted multiple ways. For now, it is sufficient to say that it is based on sample size. The value of degrees of freedom grows by 1 with each additional unit increased in the sample. In other words, the specific sampling distribution used in the hypothesis test depends on the sample size (and degrees of freedom).</p>
</div>
<div id="assumptions-required-data-4" class="section level3" number="13.5.3">
<h3><span class="header-section-number">13.5.3</span> Assumptions &amp; Required Data</h3>
<ul>
<li>One variable measured twice, stored in a dataframe as two quantitative variables, each one reflecting one measurement (e.g., time1 and time2).</li>
<li>The normality assumption, meaning at least one of these:
<ul>
<li><span class="math inline">\(N \ge 30\)</span></li>
<li>The variable is normally distributed in the population</li>
</ul></li>
<li>Independence of observations. Participants do not affect each others’ scores.</li>
<li>Homogeneity of variance (aka “homoscedasticity”). Population standard deviation is equivalent across the conditions.</li>
</ul>
</div>
<div id="when-to-use-it-4" class="section level3" number="13.5.4">
<h3><span class="header-section-number">13.5.4</span> When to use it</h3>
<p>Use a paired-samples <span class="math inline">\(t\)</span>-test when you are comparing exactly two related observations or have a within-subjects design with exactly two levels of the independent variable.</p>
</div>
<div id="example-4" class="section level3" number="13.5.5">
<h3><span class="header-section-number">13.5.5</span> Example</h3>
<div id="data-4" class="section level4" number="13.5.5.1">
<h4><span class="header-section-number">13.5.5.1</span> Data</h4>
<p>Did students’ test scores significantly differ between exam 1 and exam 2?</p>
<pre><code>##    exam1 exam2
## 1   1.02  0.96
## 2   1.04  0.93
## 3   0.83  0.95
## 4   0.89  1.02
## 5   0.88  0.89
## 6   0.88  0.98
## 7   0.96  1.09
## 8   0.95  0.90
## 9   0.96  0.84
## 10  0.89  0.93
## 11  1.08  0.81
## 12  0.79  0.93
## 13  0.78  1.03
## 14  0.94  1.04
## 15  0.79  0.78
## 16  0.72  1.05
## 17  0.79  0.94
## 18  1.23  0.90
## 19  0.80  0.95
## 20  0.90  0.74
## 21  1.08  1.06
## 22  0.93  0.82
## 23  0.96  0.90
## 24  0.87  0.83
## 25  0.88  1.04
## 26  0.99  0.78
## 27  0.90  0.89
## 28  0.95  0.83
## 29  0.70  0.85
## 30  0.81  0.92
## 31  0.90  0.82
## 32  0.83  0.90
## 33  0.96  0.88
## 34  1.04  0.97
## 35  0.77  1.02</code></pre>
</div>
<div id="hypotheses-5" class="section level4" number="13.5.5.2">
<h4><span class="header-section-number">13.5.5.2</span> Hypotheses</h4>
<p><span class="math inline">\(t\)</span>-tests can be one-tailed or two-tailed. A one-tailed <span class="math inline">\(t\)</span>-test could be conducted if researchers predict a direction for the effect.</p>
<p><span class="math display">\[
\begin{array}{ll}
H_0: &amp; \mu_D = 0  \\
H_1: &amp; \mu_D \neq 0
\end{array}
\]</span></p>
</div>
<div id="analysis-4" class="section level4" number="13.5.5.3">
<h4><span class="header-section-number">13.5.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining a sample mean this distance from the population mean. We will determine this using the sampling distribution of the null hypothesis for <span class="math inline">\(t\)</span>.</p>
<p>We need to take our wide format data and make it long format data.</p>
<div class="sourceCode" id="cb966"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb966-1"><a href="statistics-reference.html#cb966-1" aria-hidden="true" tabindex="-1"></a><span class="co"># exams &lt;- wideToLong(exams, within=&quot;time&quot;)</span></span>
<span id="cb966-2"><a href="statistics-reference.html#cb966-2" aria-hidden="true" tabindex="-1"></a><span class="co"># exams &lt;- sortFrame(exams, id)</span></span>
<span id="cb966-3"><a href="statistics-reference.html#cb966-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(exams)</span></code></pre></div>
<pre><code>##   exam1 exam2
## 1  1.02  0.96
## 2  1.04  0.93
## 3  0.83  0.95
## 4  0.89  1.02
## 5  0.88  0.89
## 6  0.88  0.98</code></pre>
<p>Then, we can run the <span class="math inline">\(t\)</span>-test:</p>
<div class="sourceCode" id="cb968"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb968-1"><a href="statistics-reference.html#cb968-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(<span class="at">x =</span> exams<span class="sc">$</span>exam1, <span class="at">y =</span> exams<span class="sc">$</span>exam2, <span class="at">paired =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  exams$exam1 and exams$exam2
## t = -0.54231, df = 34, p-value = 0.5911
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.06510678  0.03767821
## sample estimates:
## mean of the differences 
##             -0.01371429</code></pre>
</div>
<div id="decision-4" class="section level4" number="13.5.5.4">
<h4><span class="header-section-number">13.5.5.4</span> Decision</h4>
<p>The <span class="math inline">\(t\)</span>-test was not significant, <span class="math inline">\(p\)</span> = 0.6589, t(34) = 0.44. The results are inconclusive.</p>
</div>
<div id="effect-size-2" class="section level4" number="13.5.5.5">
<h4><span class="header-section-number">13.5.5.5</span> Effect Size</h4>
<p>Paired samples <span class="math inline">\(t\)</span>-tests have their own version of Cohen’s <span class="math inline">\(d\)</span> that is called <span class="math inline">\(d_z\)</span>. The calculation is different, so it is important to label it as <span class="math inline">\(d_z\)</span>.</p>
<p><span class="math inline">\(d_z = \frac{\mbox{mean difference}}{\mbox{standard deviation}}\)</span></p>
<p><span class="math inline">\(d = d_z * \sqrt{2}\)</span></p>
</div>
<div id="power-analysis" class="section level4" number="13.5.5.6">
<h4><span class="header-section-number">13.5.5.6</span> Power Analysis</h4>
<p>In G*Power, select “t-tests” and then “Means: Difference between two dependent means (matched pairs).” Compute the required sample size by entering the effect size (<span class="math inline">\(d_z\)</span>), tail(s), alpha, and desired power. Clicking “Determine” will give you a variety of ways to estimate <span class="math inline">\(d_z\)</span>.</p>
</div>
</div>
</div>
<div id="independent-samples-t-test" class="section level2" number="13.6">
<h2><span class="header-section-number">13.6</span> Independent Samples <span class="math inline">\(t\)</span>-Test</h2>
<p>This section is still under construction. For now, please refer to the regular chapter on <span class="math inline">\(t\)</span>-tests.</p>
<div id="definition-5" class="section level3" number="13.6.1">
<h3><span class="header-section-number">13.6.1</span> Definition</h3>
<p>An independent samples <span class="math inline">\(t\)</span>-test measures the difference between two means collected from a <strong>between-subjects design</strong>. In a between-subjects design, the two samples are compared, often from two levels of a manipulation. The key difference from the within-subjects design is that the units (usually, that means participants) in a between-subjects design are independent (different people) and only measured once. When different groups in a study contain different units, a between-subjects design is being used.</p>
</div>
<div id="test-statistic-5" class="section level3" number="13.6.2">
<h3><span class="header-section-number">13.6.2</span> Test Statistic</h3>
<div class="figure"><span style="display:block;" id="fig:indtnull"></span>
<img src="schuster-statistics-remix_files/figure-html/indtnull-1.png" alt="The null hypothesis distribution of $t$ with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df." width="672" />
<p class="caption">
Figure 13.6: The null hypothesis distribution of <span class="math inline">\(t\)</span> with values of df between 2 and 10. Notice how the curve is starting to converge at the higher values of df.
</p>
</div>
<p>The <span class="math inline">\(t\)</span> distribution is actually a family of distributions defined by degrees of freedom. <strong>Degrees of freedom</strong> is a concept that can be interpreted multiple ways. For now, it is sufficient to say that it is based on sample size. The value of degrees of freedom grows by 1 with each additional unit increased in the sample. In other words, the specific sampling distribution used in the hypothesis test depends on the sample size (and degrees of freedom).</p>
</div>
<div id="assumptions-required-data-5" class="section level3" number="13.6.3">
<h3><span class="header-section-number">13.6.3</span> Assumptions &amp; Required Data</h3>
<ul>
<li>Independence of observations
– Normality as previously discussed; violations are a bigger problem if you also violate homogeneity of variance or have unequal sample sizes; the result is lower power</li>
<li>Homogeneity of variance aka equality of variances aka homoscedasticity: Each group has same variance. This can be tested with Levene’s test.</li>
</ul>
</div>
<div id="when-to-use-it-5" class="section level3" number="13.6.4">
<h3><span class="header-section-number">13.6.4</span> When to use it</h3>
</div>
<div id="example-5" class="section level3" number="13.6.5">
<h3><span class="header-section-number">13.6.5</span> Example</h3>
<div id="data-5" class="section level4" number="13.6.5.1">
<h4><span class="header-section-number">13.6.5.1</span> Data</h4>
</div>
<div id="hypotheses-6" class="section level4" number="13.6.5.2">
<h4><span class="header-section-number">13.6.5.2</span> Hypotheses</h4>
</div>
<div id="analysis-5" class="section level4" number="13.6.5.3">
<h4><span class="header-section-number">13.6.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining an effect size (in this case, the predictive power of our model over the null model with only the mean, measured using <span class="math inline">\(R^2\)</span>) this strong at our sample size through random sampling from a population with no effect (a null model). We will determine this using an analysis of variance using the sampling distribution of the null hypothesis for <span class="math inline">\(F\)</span>.</p>
</div>
<div id="decision-5" class="section level4" number="13.6.5.4">
<h4><span class="header-section-number">13.6.5.4</span> Decision</h4>
</div>
<div id="effect-size-3" class="section level4" number="13.6.5.5">
<h4><span class="header-section-number">13.6.5.5</span> Effect Size</h4>
<p>d using weighted (allows unequal sample size) and pooled (requires equal variance) standard deviation: different group sizes but same SDs - weighted average of sample variances. Same two variances but different means</p>
</div>
<div id="power-analysis-1" class="section level4" number="13.6.5.6">
<h4><span class="header-section-number">13.6.5.6</span> Power Analysis</h4>
</div>
</div>
</div>
<div id="one-way-anova" class="section level2" number="13.7">
<h2><span class="header-section-number">13.7</span> One-Way ANOVA</h2>
<div id="definition-6" class="section level3" number="13.7.1">
<h3><span class="header-section-number">13.7.1</span> Definition</h3>
<p>The analysis of variance (ANOVA) is an expansion of t-test to allow comparison of a categorical IV with more than two levels.</p>
<p>As with the other tests of group comparisons, ANOVA requires a continuous, quantitative DV variable.</p>
<p>ANOVA has two stages. The <strong>omnibus test</strong> tests the null that two or more groups have the same mean. If the omnibus test is significant, <strong>pairwise comparisons</strong> are the second step. There are two strategies for pairwise comparisons. <strong>Planned comparisons</strong> maximizes statistical power by only testing hypothesized pairwise comparisons. <strong>Post-hoc tests</strong> run statistical tests for every possible pairwise comparison and then makes some (or no) adjustment for the number of tests that have been run.</p>
<p>ANOVA solves the problem of inflated type I error that arises when running multiple t-tests. Every t-test has a <strong>testwise error rate</strong> equal to alpha. In other words, if we assume the null is true, what is the probability of rejecting the null on one t-test? It is alpha. If we assume the null is true, what is the probability of rejecting the null on <em>at least one of a series</em> of t-tests? It is higher than alpha. ANOVA solves the problem of a <strong>family</strong> or <strong>experimentwise error rate</strong> (the overall alpha level for a series of tests) by keeping the experimentwise error rate equal to .05. If you are curious, the experimentwise error rate is equal to:</p>
<p><span class="math inline">\(EER = 1-(1-\alpha)^m\)</span> where m is the number of tests.</p>
<p><span class="math inline">\(m = \frac{k(k-1)}{2}\)</span> where k is the number of levels of the IV.</p>
</div>
<div id="test-statistic-6" class="section level3" number="13.7.2">
<h3><span class="header-section-number">13.7.2</span> Test Statistic</h3>
<p>The test statistic for ANOVA is <span class="math inline">\(F\)</span>, which is equivalent to <span class="math inline">\(t^2\)</span>. Where <span class="math inline">\(t\)</span>-tests measure variability using standard deviation/standard error, <span class="math inline">\(F\)</span>-tests measure variability using variance.</p>
<p>F is a ratio of two kinds of variance, explained and unexplained. The variance formula could be described as the sum of squared mean differences (sum of squares) over degrees of freedom (df). Another name for a variance calculation is mean square. The explained variance is called <strong>mean square between-groups</strong>, and the unexplained variance is <strong>mean square within-groups</strong>. Because between and within are used to describe variance in ANOVA, it is helpful to memorize that between-groups variance is good/explained and within-groups variance is bad/unexplained. The denominator/within-groups variance is pooled variance; it is just the average variance of the groups. The variance of the group means is the numerator/between-groups variance. Think of the F ratio as a competition between these two kinds of variance.</p>
<p><span class="math inline">\(F_{observed} = \frac{MS_{between}}{MS_{within}}\)</span></p>
<p>If the null is true, and all group means are the same, then the value of the F ratio will be near 1. As group differences increase, the value of F will increase.</p>
<p><span class="math inline">\(F\)</span> is a one-tailed distribution, meaning that the omnibus F test does not include direction (i.e., all ANOVA tests are two-tailed). Notice how the ratio of two kinds of variance can never be negative.</p>
<div class="figure"><span style="display:block;" id="fig:anovanull"></span>
<img src="schuster-statistics-remix_files/figure-html/anovanull-1.png" alt="The null hypothesis distribution of $F$ with values of df between F(4, 2) and F(10, 2)." width="672" />
<p class="caption">
Figure 13.7: The null hypothesis distribution of <span class="math inline">\(F\)</span> with values of df between F(4, 2) and F(10, 2).
</p>
</div>
<p>Pairwise comparisons, whether planned or as post-hoc tests, are essentially just <span class="math inline">\(t\)</span>-tests.</p>
<div id="repeated-measures-anova-1" class="section level4" number="13.7.2.1">
<h4><span class="header-section-number">13.7.2.1</span> Repeated Measures ANOVA</h4>
<p>Repeated measures ANOVA is an extension of the paired samples <span class="math inline">\(t\)</span>-test to allow for within-subjects designs.</p>
<p>In a repeated measures ANOVA, variance due to individual differences is computed separately (i.e., how different were participants scores from each other?). The individual differences variance is subtracted from the error term. In other words, variability across different participants is removed from the denominator, thus raising the F value Therefore, when you observe large differences across participants, power is increased relative to the between-subjects version.</p>
<p>Practically, repeated measures ANOVA (and within-subjects design) requires fewer cases, but more time per case. You need fewer people, but more observations of them. Within subjects designs also are subject to:</p>
<ul>
<li><p>Simple order effects. Which condition is first affects participants scores; practice effects are an example. The solution is counterbalancing.</p></li>
<li><p>Differential carryover effects are when the effect of one condition bleeds into the second, and the effect is asymmetrical because it happens more in one order of conditions than the other. Imagine a study of shocking images versus neutral images (<span class="citation"><a href="#ref-Cohen2013" role="doc-biblioref">B. H. Cohen</a> (<a href="#ref-Cohen2013" role="doc-biblioref">2013</a>)</span>). Participants may be more affected by the shocking images and that could alter their scores in the neutral image trial. In this situation, counterbalancing will not help.</p></li>
</ul>
</div>
</div>
<div id="assumptions-required-data-6" class="section level3" number="13.7.3">
<h3><span class="header-section-number">13.7.3</span> Assumptions &amp; Required Data</h3>
<div id="between-subjects-anova" class="section level4" number="13.7.3.1">
<h4><span class="header-section-number">13.7.3.1</span> Between-Subjects ANOVA</h4>
<ul>
<li>Independence of observations. Participants do not affect the measurement of each other. For example, if you conduct a study on workplace satisfaction with some participants from the same office, independence of observations is a vioalted assumption. Other techniques, such as hierarchical linear modeling (a series of regression equations) would be more appropriate. Aside from these types of situations, it is relatively easy to meet this assumption through careful research design.</li>
<li>The normality assumption, meaning at least one of these:
<ul>
<li><span class="math inline">\(N \ge 30\)</span></li>
<li>The variable is normally distributed in the population</li>
</ul></li>
<li>Independence of observations. Participants do not affect each others’ scores.</li>
<li>Homogeneity of variance (aka “homoscedasticity”). Population standard deviation is equivalent across the conditions. This can be tested using Levene’s test. If this assumption is violated <em>and</em> group sizes are unequal, then a parametric ANOVA may not be appropriate. Alternatives for this case are Welch or Brown-Forsythe ANOVA. The syntax for Welch is <code>oneway.test(dataframe$dv ~ dataframe$iv, data = ex, na.action = na.exclude)</code>.</li>
<li>No outliers. Note our earlier guidance on balancing the impact of outliers with the need to maintain the sampling method.</li>
</ul>
</div>
<div id="repeated-measures-anova-2" class="section level4" number="13.7.3.2">
<h4><span class="header-section-number">13.7.3.2</span> Repeated Measures ANOVA</h4>
<ul>
<li>Random sampling. Although this is always a concern for external validity, it is more important for a repated measures ANOVA because each unit is in both conditions. Thus, units act as their own control group.</li>
<li>The normality assumption, meaning at least one of these:
<ul>
<li><span class="math inline">\(N \ge 30\)</span></li>
<li>The variable is normally distributed in the population</li>
</ul></li>
<li>No outliers. Note our earlier guidance on balancing the impact of outliers with the need to maintain the sampling method.</li>
<li>No subject x treatment interaction. This occurs when some participants respond differently to a treatment. Imagine a drug trial for people at various stages of an illness. If the pill is more effective at earlier stages and not at later stages, there will be an inflated Type II error rate. Repeated measures ANOVA assumes this is does not happen.</li>
<li>Sphericity.
<ul>
<li>It only applies when 3+ levels (<span class="math inline">\(k&gt;2\)</span>).</li>
<li>Imagine you found the difference between a pair of levels (e.g., time1 - time 2) and then found the variance of those difference scores. If you did that for every pair of two levels, you would want each variance calculation to be equal.</li>
<li>In case you are ever asked, sphericity guarantees no compound symmetry (homogeneity of variance and of covariance) and no additivity (a treatment x subject interaction).</li>
<li><strong>Sphericity is an assumption you need to care about, because violating it can inflate the F-ratio and Type I error rate</strong>.</li>
<li>Use Wauchly’s <span class="math inline">\(W\)</span> to test for sphericity. It gives a value of epsilon. 1.0 is perfect sphericity. If the significance test for <span class="math inline">\(W\)</span> is not significant, you conclude you have met the assumption. However, this test is not powerful when sample size is small, so it can be helpful to also look at the value of epsilon.</li>
<li>If sphericity is violated, you need to use an alternative statistic. Greenhouse Geisser is more common but conservative; Huynh and Feldt is more powerful when you are close to sphericity.</li>
<li>Do not try different statistics and only test for sphericity after you have failed to reject the null. That is p-hacking.</li>
</ul></li>
</ul>
</div>
</div>
<div id="when-to-use-it-6" class="section level3" number="13.7.4">
<h3><span class="header-section-number">13.7.4</span> When to use it</h3>
<p>If you have a quantitative DV and a single, discrete IV with two or more levels, you can run an ANOVA.</p>
</div>
<div id="example-1-between-subjects" class="section level3" number="13.7.5">
<h3><span class="header-section-number">13.7.5</span> Example 1: Between-Subjects</h3>
<p>Researchers are interested in participants’ reaction times to three types of alert displays: a visual alert, an auditory alert, and a speech alert. They randomly assign participants to one of these three conditions. Therefore, this is a between-subjects experimental design.</p>
<div id="data-6" class="section level4" number="13.7.5.1">
<h4><span class="header-section-number">13.7.5.1</span> Data</h4>
<p>Complicating matters, our data in this example are starting off in the wrong format. This format is called wide. We have one column per condition. This means that each row contains the data for three participants. We need this reshaped into one row per participant, called long.</p>
<div class="sourceCode" id="cb970"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb970-1"><a href="statistics-reference.html#cb970-1" aria-hidden="true" tabindex="-1"></a>RT_visual <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">218.24</span>, <span class="fl">218.34</span>, <span class="fl">229.05</span>, <span class="fl">219.12</span>, <span class="fl">218.42</span>)</span>
<span id="cb970-2"><a href="statistics-reference.html#cb970-2" aria-hidden="true" tabindex="-1"></a>RT_auditory <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">238.37</span>, <span class="fl">249.06</span>, <span class="fl">238.86</span>, <span class="fl">248.76</span>, <span class="fl">239.34</span>)</span>
<span id="cb970-3"><a href="statistics-reference.html#cb970-3" aria-hidden="true" tabindex="-1"></a>RT_speech <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">258.34</span>, <span class="fl">228.62</span>, <span class="fl">239.31</span>, <span class="fl">259.14</span>, <span class="fl">258.13</span>)</span>
<span id="cb970-4"><a href="statistics-reference.html#cb970-4" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb970-5"><a href="statistics-reference.html#cb970-5" aria-hidden="true" tabindex="-1"></a>dataframe <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(RT_visual, RT_auditory, RT_speech, id)</span>
<span id="cb970-6"><a href="statistics-reference.html#cb970-6" aria-hidden="true" tabindex="-1"></a>dataframe</span></code></pre></div>
<pre><code>##   RT_visual RT_auditory RT_speech id
## 1    218.24      238.37    258.34  1
## 2    218.34      249.06    228.62  2
## 3    229.05      238.86    239.31  3
## 4    219.12      248.76    259.14  4
## 5    218.42      239.34    258.13  5</code></pre>
<p>These data are in wide format (one column per condition). To use these data in a between-subjects ANOVA, we need them in long format (one row per participant).</p>
<p>The secret to this is naming the variables correctly. First, you need an id variable. Second, you should name all of your condition variables in this format: DV_level. In this example, our DV is reaction time (RT) and the levels are visual, auditory, and speech. <code>wideToLong()</code> is looking for this format or it won’t work.</p>
<div class="sourceCode" id="cb972"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb972-1"><a href="statistics-reference.html#cb972-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lsr)</span>
<span id="cb972-2"><a href="statistics-reference.html#cb972-2" aria-hidden="true" tabindex="-1"></a>longdata <span class="ot">&lt;-</span> <span class="fu">wideToLong</span>(dataframe, <span class="st">&quot;condition&quot;</span>)</span>
<span id="cb972-3"><a href="statistics-reference.html#cb972-3" aria-hidden="true" tabindex="-1"></a>longdata</span></code></pre></div>
<pre><code>##    id condition     RT
## 1   1    visual 218.24
## 2   2    visual 218.34
## 3   3    visual 229.05
## 4   4    visual 219.12
## 5   5    visual 218.42
## 6   1  auditory 238.37
## 7   2  auditory 249.06
## 8   3  auditory 238.86
## 9   4  auditory 248.76
## 10  5  auditory 239.34
## 11  1    speech 258.34
## 12  2    speech 228.62
## 13  3    speech 239.31
## 14  4    speech 259.14
## 15  5    speech 258.13</code></pre>
<p>All of this was to illustrate that for a between-subjects ANOVA, we need long format data. To avoid having to reshape your data, it is helpful to collect between-subjects data already in long format. The condition variable is a hint that the data are in long format.</p>
<p>With that out of the way, we can now use our dataframe, <code>longdata</code>. First, we will descriptively look at the group means:</p>
<div class="sourceCode" id="cb974"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb974-1"><a href="statistics-reference.html#cb974-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pastecs)</span>
<span id="cb974-2"><a href="statistics-reference.html#cb974-2" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>condition, stat.desc) <span class="co"># show descriptive stats on our RT DV grouped by condition</span></span></code></pre></div>
<pre><code>## longdata$condition: auditory
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.383700e+02 2.490600e+02 
##        range          sum       median         mean      SE.mean 
## 1.069000e+01 1.214390e+03 2.393400e+02 2.428780e+02 2.467781e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 6.851659e+00 3.044972e+01 5.518126e+00 2.271975e-02 
## -------------------------------------------------------- 
## longdata$condition: speech
##      nbr.val     nbr.null       nbr.na          min          max 
##    5.0000000    0.0000000    0.0000000  228.6200000  259.1400000 
##        range          sum       median         mean      SE.mean 
##   30.5200000 1243.5400000  258.1300000  248.7080000    6.2539039 
## CI.mean.0.95          var      std.dev     coef.var 
##   17.3636209  195.5565700   13.9841542    0.0562272 
## -------------------------------------------------------- 
## longdata$condition: visual
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.182400e+02 2.290500e+02 
##        range          sum       median         mean      SE.mean 
## 1.081000e+01 1.103170e+03 2.184200e+02 2.206340e+02 2.109700e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 5.857467e+00 2.225418e+01 4.717434e+00 2.138126e-02</code></pre>
<div class="sourceCode" id="cb976"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb976-1"><a href="statistics-reference.html#cb976-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb976-2"><a href="statistics-reference.html#cb976-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(longdata, <span class="fu">aes</span>(condition, RT)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.y =</span> mean, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">&quot;errorbar&quot;</span>, <span class="at">width=</span> <span class="fl">0.2</span>) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: `fun.y` is deprecated. Use `fun` instead.</code></pre>
<p><img src="schuster-statistics-remix_files/figure-html/anovavis3-1.png" width="672" /></p>
<p>And, we can create an interactive graph of the means using a package called Plotly. The error bars are 95% confidence intervals. I cannot embed Plotly in this book, but I can show you the syntax:</p>
<div class="sourceCode" id="cb978"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb978-1"><a href="statistics-reference.html#cb978-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;plotly&quot;)</span></span>
<span id="cb978-2"><a href="statistics-reference.html#cb978-2" aria-hidden="true" tabindex="-1"></a><span class="co"># library(plotly)</span></span>
<span id="cb978-3"><a href="statistics-reference.html#cb978-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ggplotly(ggplot(longdata, aes(condition, RT)) + stat_summary(fun.y = mean, geom = &quot;point&quot;) + labs(x =&quot;Condition&quot;, y=&quot;Outcome&quot;) + stat_summary(fun.data = mean_cl_normal, geom = &quot;errorbar&quot;, width= 0.2) + labs(x =&quot;Condition&quot;, y=&quot;Outcome&quot;)) # Plotly shows hoverable data points on mouseover</span></span></code></pre></div>
<p>A visual interpretation of this graph suggests that visual had the fastest reaction time, followed by auditory, and then speech. But are these significantly different from each other? We need to run the ANOVA to find out.</p>
</div>
<div id="hypotheses-7" class="section level4" number="13.7.5.2">
<h4><span class="header-section-number">13.7.5.2</span> Hypotheses</h4>
<p><span class="math display">\[
\begin{array}{ll}
H_0: &amp; \mu_{auditory} = \mu_{speech} = \mu_{visual}  \\
H_1: &amp; \mbox{the null is false}
\end{array}
\]</span>
#### Assumption Checking</p>
<div class="sourceCode" id="cb979"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb979-1"><a href="statistics-reference.html#cb979-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb979-2"><a href="statistics-reference.html#cb979-2" aria-hidden="true" tabindex="-1"></a><span class="fu">leveneTest</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>condition, <span class="at">center =</span> median)</span></code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  2  1.0249 0.3882
##       12</code></pre>
<p>Levene’s test is not significant, so we assume homogeneity of variance. However, I would be cautious about this interpretation because our sample size is small (<span class="math inline">\(N = 15\)</span>). Further, the error bars in the graph looked different to me (and the confidence intervals were numerically different in the table). But because our sample sizes are equal, we will continue with this example.</p>
</div>
<div id="analysis-6" class="section level4" number="13.7.5.3">
<h4><span class="header-section-number">13.7.5.3</span> Analysis</h4>
<p>Set the alpha level. By convention, an alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>Assume the null hypothesis is true. Assuming the null hypothesis is true means that we need to determine the probability of obtaining an effect size (in this case, the ratio of explained to unexplained variance) this strong at our sample size through random sampling from a population with no effect (a null model). We will determine this using an analysis of variance using the sampling distribution of the null hypothesis for <span class="math inline">\(F\)</span>.</p>
<div class="sourceCode" id="cb981"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb981-1"><a href="statistics-reference.html#cb981-1" aria-hidden="true" tabindex="-1"></a>anovaModel <span class="ot">&lt;-</span> <span class="fu">lm</span>(RT <span class="sc">~</span> condition, <span class="at">data =</span> longdata) <span class="co"># note there is an na.action argument if you need to exclude missing data</span></span>
<span id="cb981-2"><a href="statistics-reference.html#cb981-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(anovaModel)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = RT ~ condition, data = longdata)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -20.088  -3.778  -2.214   7.299  10.432 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      242.878      4.068  59.701 3.22e-16 ***
## conditionspeech    5.830      5.753   1.013  0.33090    
## conditionvisual  -22.244      5.753  -3.866  0.00224 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 9.097 on 12 degrees of freedom
## Multiple R-squared:  0.6885, Adjusted R-squared:  0.6366 
## F-statistic: 13.26 on 2 and 12 DF,  p-value: 0.0009136</code></pre>
<div class="sourceCode" id="cb983"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb983-1"><a href="statistics-reference.html#cb983-1" aria-hidden="true" tabindex="-1"></a>anovaModel <span class="ot">&lt;-</span> <span class="fu">aov</span>(RT <span class="sc">~</span> condition, <span class="at">data =</span> longdata)</span>
<span id="cb983-2"><a href="statistics-reference.html#cb983-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(anovaModel)</span></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## condition    2   2195  1097.4   13.26 0.000914 ***
## Residuals   12    993    82.8                     
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="omnibus-decision" class="section level4" number="13.7.5.4">
<h4><span class="header-section-number">13.7.5.4</span> Omnibus Decision</h4>
<p>The omnibus ANOVA was significant, <span class="math inline">\(F\)</span>(2, 12) = 13.26, <span class="math inline">\(p\)</span> &lt; .001, <span class="math inline">\(\eta^2\)</span> = .689. We can conclude there is some difference among these conditions. To determine which conditions are significantly different from the others, we need to perform post-hoc tests.</p>
</div>
<div id="multiple-comparisons-1" class="section level4" number="13.7.5.5">
<h4><span class="header-section-number">13.7.5.5</span> Multiple Comparisons</h4>
<p>A significant <span class="math inline">\(F\)</span>-test only tells us that at least one group is significantly different. Which groups are different from which groups? What are the directions of the effects (i.e., which mean is larger, and which is smaller)? This is purpose of multiple comparisons; we try to identify which mean differences reflect true effects.</p>
<p>There are multiple ways to do this; they differ in balance of Type I error control and power, but fundamentally are <span class="math inline">\(t\)</span>-tests (as they always compare two means). You’ll need to consider multiple comparisons whenever you have more than one comparison of means. You do not need multiple comparisons with only two levels of the IV, as there is only a single comparison to make, and that one comparison is accomplished with the onmibus test.</p>
<p>There are two approaches to multiple comparisons:</p>
<ol style="list-style-type: decimal">
<li><p>Post-hoc tests (a posteriori): Post-hoc tests are <strong>protected</strong> in that they are only run after a significant <span class="math inline">\(F\)</span> test. All are variations on a t-test with different adjustments to protect against the multiple t-test problem. Post-hoc tests are used whenever researchers want to examine all possible mean comparisons.</p></li>
<li><p>Planned comparisons (a priori): In a planned comparisons approach, the omnibus ANOVA can be skipped (although it usually is run anyway), and only test a subset of all possible comparisons are tested. Because you examine fewer comparisons, and your comparisons are not at all influenced by the data, you will examine fewer means and have the most power. For this to be meaningful, the researchers must declare their tested comparisons ahead of time and not alter the approach if undeclared comparisons turn out to be significant. Readers must either trust that researchers have done this faithfully, or preregistration would need to be used.</p></li>
</ol>
</div>
<div id="post-hoc-tests" class="section level4" number="13.7.5.6">
<h4><span class="header-section-number">13.7.5.6</span> Post-Hoc Tests</h4>
<p>Let’s explore the post-hoc test options, starting with the most <strong>liberal</strong> (least control of Type I error to maximize power) and ending with the most <strong>conservative</strong> (most control of Type I error at the cost of power).</p>
<div id="fishers-least-significant-difference-lsd" class="section level5" number="13.7.5.6.1">
<h5><span class="header-section-number">13.7.5.6.1</span> Fisher’s Least Significant Difference (LSD)</h5>
<p>Fisher’s protected <span class="math inline">\(t\)</span> Tests is also known as Fisher’s Least Significant Difference (LSD). This involves running follow up t-tests using the <span class="math inline">\(MS_wn\)</span> as a variance estimate. Essentially, you are running protected <span class="math inline">\(t\)</span>-tests. The problem of inflated Type I error exists when your omnibus <span class="math inline">\(F\)</span> is significant and there are many groups to compare (i.e., more than 3). It is the most liberal approach but maintains the most statistical power with 3 or fewer groups.</p>
<p>My recommendation is to use this approach if you have three or fewer groups.</p>
</div>
<div id="tukey-method" class="section level5" number="13.7.5.6.2">
<h5><span class="header-section-number">13.7.5.6.2</span> Tukey method</h5>
<p><strong>Tukey’s Honestly Significant Difference (HSD) test</strong> or Tukey’s range test is a method that compares the size of mean differences on the logic that the largest mean differences are real effects. Tukey’s HSD is still just a t-test, but it has a correction for familywise error rate. Instead of <span class="math inline">\(t\)</span>, a similar statistic <span class="math inline">\(q_k\)</span> (called the studentized range statistic) is computed, and a significance test is done using the <span class="math inline">\(q_k\)</span> distribution. The <span class="math inline">\(q_k\)</span> distribution depends on degrees of freedom (just like the t-test) but also incorporates <span class="math inline">\(k\)</span>, the number of groups that are being compared.</p>
<p>In all, Tukey gives you comparisons at a familywise error rate of .05. However, because you are peanlized for the number of comparisons you make, it can end up being too conservative, especially with many groups.</p>
<p>My recommendation is to use this approach for post-hoc testsing in between-subjects designs with more than 3 groups.</p>
<p>Tukey also has the homogeneity of variance assumption, so if that is violated and you have unequal group sizes, you may need to use an alternative statistic, such as Games-Howell or Fisher-Hayter. The larger point is that this list is not every possible approach to post-hoc testing. You can employ any post-hoc testing method you wish so long as you decide on your approach before starting your analysis and can make an argument for why you chose that particular method.</p>
<div class="sourceCode" id="cb985"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb985-1"><a href="statistics-reference.html#cb985-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(multcomp)</span></code></pre></div>
<pre><code>## Loading required package: mvtnorm</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<pre><code>## Loading required package: TH.data</code></pre>
<pre><code>## 
## Attaching package: &#39;TH.data&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     geyser</code></pre>
<div class="sourceCode" id="cb991"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb991-1"><a href="statistics-reference.html#cb991-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;multcomp&quot;)</span></span>
<span id="cb991-2"><a href="statistics-reference.html#cb991-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb991-3"><a href="statistics-reference.html#cb991-3" aria-hidden="true" tabindex="-1"></a>hsdModel <span class="ot">&lt;-</span> <span class="fu">glht</span>(anovaModel, <span class="at">linfct =</span> <span class="fu">mcp</span>(<span class="at">condition =</span> <span class="st">&quot;Tukey&quot;</span>))</span>
<span id="cb991-4"><a href="statistics-reference.html#cb991-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(hsdModel)</span></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = RT ~ condition, data = longdata)
## 
## Linear Hypotheses:
##                        Estimate Std. Error t value Pr(&gt;|t|)   
## speech - auditory == 0    5.830      5.753   1.013  0.58282   
## visual - auditory == 0  -22.244      5.753  -3.866  0.00576 **
## visual - speech == 0    -28.074      5.753  -4.880  0.00114 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>The Tukey post-hoc tests show that there was a significant difference between visual (<span class="math inline">\(M\)</span> = 220.63, <span class="math inline">\(SD\)</span> = 4.72) and auditory (<span class="math inline">\(M\)</span> = 242.87, <span class="math inline">\(SD\)</span> = 5.52) alerts, and between speech (<span class="math inline">\(M\)</span> = 248.71, <span class="math inline">\(SD\)</span> = 13.98) and visual alerts, but not between auditory and speech alerts.</p>
</div>
<div id="bonferroni-method" class="section level5" number="13.7.5.6.3">
<h5><span class="header-section-number">13.7.5.6.3</span> Bonferroni method</h5>
<p>This is the most conservative method of post-hoc tests. To keep the familywise error rate equal to alpha, we just divide alpha by the number of comparisons. If you make two comparisons, your new alpha level is <span class="math inline">\(\alpha = .025\)</span>. As you may imagine, this becomes <em>very</em> conservative as you increase the number of comparisons you need to make. But, in cases where you want the best control of Type I error, are not concerned about the loss of power, and/or are making this adjustment on a small number of tests, it can be simple to implement and useful. In statistical software, Bonferroni corrections are usually implemented by altering the <span class="math inline">\(p\)</span>-value, not alpha, so you can still interpret the output with an alpha level of <span class="math inline">\(\alpha = .05\)</span>.</p>
<div class="sourceCode" id="cb993"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb993-1"><a href="statistics-reference.html#cb993-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairwise.t.test</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>condition, <span class="at">paired =</span> <span class="cn">FALSE</span>, <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  longdata$RT and longdata$condition 
## 
##        auditory speech
## speech 0.9927   -     
## visual 0.0067   0.0011
## 
## P value adjustment method: bonferroni</code></pre>
<p>The bonferroni post-hoc tests show that there was a significant difference between visual (<span class="math inline">\(M\)</span> = 220.63, <span class="math inline">\(SD\)</span> = 4.72) and auditory (<span class="math inline">\(M\)</span> = 242.87, <span class="math inline">\(SD\)</span> = 5.52) alerts, and between speech (<span class="math inline">\(M\)</span> = 248.71, <span class="math inline">\(SD\)</span> = 13.98) and visual alerts, but not between auditory and speech alerts.</p>
</div>
<div id="alternatives-to-bonferroni-method" class="section level5" number="13.7.5.6.4">
<h5><span class="header-section-number">13.7.5.6.4</span> Alternatives to Bonferroni method</h5>
<p>Instead of “bonferroni,” you can choose another p.adjust.method argument of “holm,” “hochberg,” “hommel,” “BH,” “BY,” “fdr,” or “none.” The <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/p.adjust">R documentation</a> gives a nice summary of the choices and provides citations for further reading.</p>
</div>
</div>
<div id="planned-comparisons" class="section level4" number="13.7.5.7">
<h4><span class="header-section-number">13.7.5.7</span> Planned Comparisons</h4>
<p>As you have more groups in your study, you start to lose power by testing every possible combination. Sometimes, you are only interested in one or a few of the contrasts, or you might want to compare groups of means. For example, if you measure people’s mood in each month of the year (with 12 levels), you might want to compare spring measurements to fall measurements. Planned comparisons gives you more flexibility in the means you can test without a loss of statistical power for making all of the comparisons. There are caveats, though:</p>
<ol style="list-style-type: decimal">
<li><p>You need to specify the comparisons ahead of time. Your readers and reviewers need to be satisfied that you did specify the comparisons ahead of time.</p></li>
<li><p>You need to be interested in a subset of all possible comparisons. There is little point in a planned comparisons approach that tests every possible comparison.</p></li>
<li><p>You have to program the comparisons in R using <strong>user-defined contrast coding</strong>. Dummy coding is an example of contrast coding. User-defined contrast coding means you define each comparison using numerical codes. I will try to explain this briefly here, but we will give this topic more attention when we do factorial ANOVA. For now, just be aware that planned comparisons require contrast coding.</p>
<p>Imagine we have four levels of our IV: A, B, C, and D. We are interested a planned comparison of A vs B and C vs D. We give each group a coefficient (a weight) that defines if it is used in the comparison. We use a 0 to exclude the level from the comparison. We use a positive number to put it on one side of the comparison and a negative number to put it on the other side. An example may help:</p></li>
</ol>
<table style="width:40%;">
<colgroup>
<col width="18%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Comparison</th>
<th align="center">A</th>
<th align="center">B</th>
<th align="center">C</th>
<th align="center">D</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">A vs B</td>
<td align="center">1</td>
<td align="center">-1</td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="left">C vs D</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center">-1</td>
</tr>
</tbody>
</table>
<p>The table above defines two comparisons, one between A and B and a seond one between C and D.</p>
<p>There is one rule about writing these comparisons; they must be <strong>orthogonal</strong> (independent). You can verify that your comparisons are orthogonal by multiplying the coefficients <em>down</em>. That is, muliply the first A coefficient (1) by the second A coefficient (0). Then, add the products. Based on the table, that is <span class="math inline">\(1 * 0 + -1 * 0 + 0 * 1 + 0 * -1\)</span>, which gives a total of 0. The total should be zero for the comparisons to be orthogonal. If you have three coomparisons, you have to do this multiplication for every pair. Yes, it’s a bit of work, but this is the planning we sign up for when we do planned comparisons.</p>
<ol start="4" style="list-style-type: decimal">
<li>The convention seems to be to ignore familywise error rate, which is only appropriate if you have a small number of planned comparisons. You may consider one of the adjustment methods, like Bonferroni, if you have many planned comparisons to test.</li>
</ol>
</div>
<div id="effect-size-4" class="section level4" number="13.7.5.8">
<h4><span class="header-section-number">13.7.5.8</span> Effect Size</h4>
<p>Because <span class="math inline">\(\eta^2 = R^2\)</span>, you can find and report <span class="math inline">\(\eta^2\)</span> from the <code>lm()</code> function.</p>
</div>
<div id="power-analysis-2" class="section level4" number="13.7.5.9">
<h4><span class="header-section-number">13.7.5.9</span> Power Analysis</h4>
<p>In G*Power, select the F tests family, and then choose “ANOVA: Fixed effects, omnibus, one-way.”</p>
<p>The best way to estimate effect size is to rely on effect sizes in similar past research. You will commonly find eta squared (<span class="math inline">\(\eta^2\)</span>) in published work, not effect size <span class="math inline">\(f\)</span>. However, you can convert eta squared to <span class="math inline">\(f\)</span> to use in G*Power:</p>
<ol style="list-style-type: decimal">
<li>Click “Determine.”</li>
<li>Select the procedure of “Effect size from variance.”</li>
<li>Select “Direct.”</li>
<li>Enter a value for partial eta squared.</li>
<li>Click “Calculate and transfer to main window.” <strong>Don’t miss this step</strong>. It is easy to forget to update the value of f in the input parameters. If you do not update that value, your power analysis will not use this new effect size.</li>
</ol>
<p>One more (less common) option is to select “Effect size from means” in the “Determine” drawer to fill in the anticipated means to estimate effect size.</p>
</div>
</div>
<div id="example-2-within-subjects" class="section level3" number="13.7.6">
<h3><span class="header-section-number">13.7.6</span> Example 2: Within-Subjects</h3>
<p>This example is the same, but in this study, the researchers randomly assigned participants to one of these three condition orders. Participants completed a visual, auditory, and speech trial. Therefore, this is a within-subjects experimental design.</p>
<div id="data-7" class="section level4" number="13.7.6.1">
<h4><span class="header-section-number">13.7.6.1</span> Data</h4>
<p>If you run this analysis in SPSS or another package, it is more common to see it in wide format, with one row per participant, and each measurement represented by a separate column. That is how our data in this example started out:</p>
<div class="sourceCode" id="cb995"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb995-1"><a href="statistics-reference.html#cb995-1" aria-hidden="true" tabindex="-1"></a>RT_visual <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">218.24</span>, <span class="fl">218.34</span>, <span class="fl">229.05</span>, <span class="fl">219.12</span>, <span class="fl">218.42</span>)</span>
<span id="cb995-2"><a href="statistics-reference.html#cb995-2" aria-hidden="true" tabindex="-1"></a>RT_auditory <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">238.37</span>, <span class="fl">249.06</span>, <span class="fl">238.86</span>, <span class="fl">248.76</span>, <span class="fl">239.34</span>)</span>
<span id="cb995-3"><a href="statistics-reference.html#cb995-3" aria-hidden="true" tabindex="-1"></a>RT_speech <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">258.34</span>, <span class="fl">228.62</span>, <span class="fl">239.31</span>, <span class="fl">259.14</span>, <span class="fl">258.13</span>)</span>
<span id="cb995-4"><a href="statistics-reference.html#cb995-4" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>)</span>
<span id="cb995-5"><a href="statistics-reference.html#cb995-5" aria-hidden="true" tabindex="-1"></a>dataframe <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(RT_visual, RT_auditory, RT_speech, id)</span>
<span id="cb995-6"><a href="statistics-reference.html#cb995-6" aria-hidden="true" tabindex="-1"></a>dataframe</span></code></pre></div>
<pre><code>##   RT_visual RT_auditory RT_speech id
## 1    218.24      238.37    258.34  1
## 2    218.34      249.06    228.62  2
## 3    229.05      238.86    239.31  3
## 4    219.12      248.76    259.14  4
## 5    218.42      239.34    258.13  5</code></pre>
<p>These data are in wide format (one column per condition) in R, however, we still have to use the long format (one row per participant).</p>
<div class="sourceCode" id="cb997"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb997-1"><a href="statistics-reference.html#cb997-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lsr)</span>
<span id="cb997-2"><a href="statistics-reference.html#cb997-2" aria-hidden="true" tabindex="-1"></a>longdata <span class="ot">&lt;-</span> <span class="fu">wideToLong</span>(dataframe, <span class="st">&quot;condition&quot;</span>)</span>
<span id="cb997-3"><a href="statistics-reference.html#cb997-3" aria-hidden="true" tabindex="-1"></a>longdata</span></code></pre></div>
<pre><code>##    id condition     RT
## 1   1    visual 218.24
## 2   2    visual 218.34
## 3   3    visual 229.05
## 4   4    visual 219.12
## 5   5    visual 218.42
## 6   1  auditory 238.37
## 7   2  auditory 249.06
## 8   3  auditory 238.86
## 9   4  auditory 248.76
## 10  5  auditory 239.34
## 11  1    speech 258.34
## 12  2    speech 228.62
## 13  3    speech 239.31
## 14  4    speech 259.14
## 15  5    speech 258.13</code></pre>
<p>I will omit the parts of the analysis that are the same in the within-subjects design. All the descriptive analysis is the same.</p>
</div>
<div id="hypotheses-8" class="section level4" number="13.7.6.2">
<h4><span class="header-section-number">13.7.6.2</span> Hypotheses</h4>
<p>Hypotheses are written the same as for a between-subjects design.</p>
</div>
<div id="analysis-7" class="section level4" number="13.7.6.3">
<h4><span class="header-section-number">13.7.6.3</span> Analysis</h4>
<p>We are using ezANOVA() in the ez package.</p>
<div class="sourceCode" id="cb999"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb999-1"><a href="statistics-reference.html#cb999-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;ez&quot;) # you may need to install the ez package</span></span>
<span id="cb999-2"><a href="statistics-reference.html#cb999-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ez)</span>
<span id="cb999-3"><a href="statistics-reference.html#cb999-3" aria-hidden="true" tabindex="-1"></a>withinAnovaModel <span class="ot">&lt;-</span> <span class="fu">ezANOVA</span>(<span class="at">data =</span> longdata, <span class="at">dv =</span> .(RT), <span class="at">wid =</span> .(id), <span class="at">within =</span> .(condition), <span class="at">type =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>## Warning: Converting &quot;id&quot; to factor for ANOVA.</code></pre>
<div class="sourceCode" id="cb1001"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1001-1"><a href="statistics-reference.html#cb1001-1" aria-hidden="true" tabindex="-1"></a>withinAnovaModel</span></code></pre></div>
<pre><code>## $ANOVA
##      Effect DFn DFd        F           p p&lt;.05       ges
## 2 condition   2   8 10.74292 0.005418832     * 0.6884996
## 
## $`Mauchly&#39;s Test for Sphericity`
##      Effect         W         p p&lt;.05
## 2 condition 0.5783249 0.4398026      
## 
## $`Sphericity Corrections`
##      Effect       GGe      p[GG] p[GG]&lt;.05       HFe       p[HF] p[HF]&lt;.05
## 2 condition 0.7033956 0.01495468         * 0.9706036 0.005985676         *</code></pre>
</div>
<div id="sphericity-checking" class="section level4" number="13.7.6.4">
<h4><span class="header-section-number">13.7.6.4</span> Sphericity Checking</h4>
<p>We will need to diagnose sphericity. Fortunately, this is provided in the default output. The value of Mauchly’s <span class="math inline">\(W\)</span> in this example is 0.59, which is not significant (<span class="math inline">\(p\)</span> &gt; .05), and I WILL report the statistics in the first table. Had this been significant, I could have reported Greenhouse and Geisser (GG; 1959) or Huynh and Feldt (HF; 1976) versions of the statistics. Remember, it is important to decide which approach you will take before examining the p-values.</p>
</div>
<div id="omnibus-decision-1" class="section level4" number="13.7.6.5">
<h4><span class="header-section-number">13.7.6.5</span> Omnibus Decision</h4>
<p>The omnibus ANOVA was significant, <span class="math inline">\(F\)</span>(2, 8) = 10.74, <span class="math inline">\(p\)</span> = .005, <span class="math inline">\(\eta^2_G\)</span> = .689. We can conclude there is some difference among these conditions. To determine which conditions are significantly different from the others, we need to perform post-hoc tests.</p>
</div>
<div id="post-hoc-tests-1" class="section level4" number="13.7.6.6">
<h4><span class="header-section-number">13.7.6.6</span> Post-hoc Tests</h4>
<p>The post-hoc test methods are the same, except set paired = TRUE, so that paired samples t-tests are used.</p>
<p>Tukey’s HSD assumes independence of observations and is not available for within-subjects designs.</p>
</div>
<div id="effect-size-5" class="section level4" number="13.7.6.7">
<h4><span class="header-section-number">13.7.6.7</span> Effect Size</h4>
<p>The effect size statistic is called generalized eta squared (see also <a href="https://link.springer.com/content/pdf/10.3758%2FBF03192707.pdf">Bakeman, 2005</a>). Note that this differs in its calculation from eta squared, so you should take care to label it with the <span class="math inline">\(_G\)</span>.</p>
</div>
<div id="power-analysis-3" class="section level4" number="13.7.6.8">
<h4><span class="header-section-number">13.7.6.8</span> Power Analysis</h4>
<p>In G*Power, select the F tests family, and then choose “ANOVA: Repeated measures, within factors.”</p>
<p>As this is a one-way, repeated measures ANOVA, you can enter effect size, alpha, and power. Then, set number of groups to 1 (as there is no between-subjects factor) and the number of measurements to the number of levels of the IV. The corr among rep measures is the estimated correlation between your measures (e.g., how well can you predict a participant’s time 2 score if you know their time 1 score). This can be hard to estimate, but it’s a good exercise to think about how large you expect these individual differences to be. The larger the correlation among measures, the more you gain by using a within-subjects design.</p>

</div>
</div>
</div>
<div id="statguide-factorial" class="section level2" number="13.8">
<h2><span class="header-section-number">13.8</span> Factorial ANOVA</h2>
<div id="definition-7" class="section level3" number="13.8.1">
<h3><span class="header-section-number">13.8.1</span> Definition</h3>
<p>Including more than one independent variable (called a factor) in an analysis of variance (ANOVA) results in a factorial ANOVA.</p>
<p>Factorial ANOVA tests each of the factors individually, with results that are the same as if each factor was tested on its own one-way ANOVA. Factorial ANOVA adds a higher-level analysis, as well, called an <strong>interaction effect</strong>. Any two-way ANOVA (with two factors) has one potential interaction effect. A three-way ANOVA has four potential interaction effects. Imagine factors A (2 levels), B (3 levels), and C (2 levels). Such an ANOVA would be described as a 2 x 3 x 2 ANOVA. The factorial ANOVA would involve testing these omnibus effects:</p>
<ul>
<li><p>Main effect of A</p></li>
<li><p>Main effect of B</p></li>
<li><p>Main effect of C</p></li>
<li><p>Interaction effect A x B</p></li>
<li><p>Interaction effect B x C</p></li>
<li><p>Interaction effect A x C</p></li>
<li><p>Interaction effect A x B x C</p></li>
</ul>
<p>The three-way interaction is the highest <strong>order</strong> interaction. Order refers to the number of factors involved.</p>
<p>You can calculate the number of potential interation effects with the formula <span class="math inline">\(2^m-m-1\)</span>, where <span class="math inline">\(k\)</span> is the number of factors. This calculation for three factors reveals the four potential interaction effects listed previously.</p>
<p><em>Each</em> of these tests has stages. The <strong>omnibus test</strong> tests the null that two or more groups have the same mean. If the omnibus test is significant, <strong>pairwise comparisons</strong> are the second step. There are two strategies for pairwise comparisons. <strong>Planned comparisons</strong> maximizes statistical power by only testing hypothesized pairwise comparisons. <strong>Post-hoc tests</strong> run statistical tests for every possible pairwise comparison and then makes some (or no) adjustment for the number of tests that have been run.</p>
</div>
<div id="test-statistic-7" class="section level3" number="13.8.2">
<h3><span class="header-section-number">13.8.2</span> Test Statistic</h3>
<p>The test statistic for ANOVA is <span class="math inline">\(F\)</span>.</p>
<div class="figure"><span style="display:block;" id="fig:factorialstat"></span>
<img src="schuster-statistics-remix_files/figure-html/factorialstat-1.png" alt="The null hypothesis distribution of $F$ with values of df between F(4, 2) and F(10, 2)." width="672" />
<p class="caption">
Figure 13.8: The null hypothesis distribution of <span class="math inline">\(F\)</span> with values of df between F(4, 2) and F(10, 2).
</p>
</div>
<p>Pairwise comparisons, whether planned or as post-hoc tests, are essentially just <span class="math inline">\(t\)</span>-tests.</p>
</div>
<div id="between-within-and-mixed-anova" class="section level3" number="13.8.3">
<h3><span class="header-section-number">13.8.3</span> Between, Within, and Mixed ANOVA</h3>
<p>Because different ANOVAs are used for between- and within-subjects designs, there are more possibilities of combinations with a factorial model. A factorial ANOVA can be a between-subjects factorial ANOVA when all factors are between-subjects, a repeated measures factorial ANOVA when all factors are within-subjects, or a <strong>mixed ANOVA</strong> when one or more factors are between-subjects and one or more factors are within-subjects.</p>
</div>
<div id="assumptions-required-data-7" class="section level3" number="13.8.4">
<h3><span class="header-section-number">13.8.4</span> Assumptions &amp; Required Data</h3>
<p>The assumptions for a factorial ANOVA match the underlying one-way ANOVAs. That is, if you have a between-subjects factor, you need to consider homogeneity of variance and the other assumptions for between-subjects ANOVA. If you have a within-subjects factor, you need to consider sphericity and the other assumptions for repeated-measures ANOVA.</p>
</div>
<div id="when-to-use-it-7" class="section level3" number="13.8.5">
<h3><span class="header-section-number">13.8.5</span> When to use it</h3>
<p>If you have a quantitative DV and two or more discrete IVs with two or more levels each, you can run a factorial ANOVA.</p>
</div>
<div id="example-mixed-anova" class="section level3" number="13.8.6">
<h3><span class="header-section-number">13.8.6</span> Example: Mixed ANOVA</h3>
<p>Researchers are interested in participants’ reaction times to three types of alert displays: a visual alert, an auditory alert, and a speech alert. They randomly assign participants to one of these three conditions. Participants repeat the task two times, and researchers are interested if reaction time improves with practice. Therefore, this is a mixed design.</p>
<div id="data-8" class="section level4" number="13.8.6.1">
<h4><span class="header-section-number">13.8.6.1</span> Data</h4>
<p>I recommend starting with data formatted as follows:</p>
<ul>
<li><p>All repeated measures should be <strong>wide</strong>, with one column for each level of the within-subjects factor. In this example, we have two levels, Time 1 and Time 2, so we need a column for each. If you have more than one within-subjects factor, you need a column for each cell. Imagine you had another factor, Factor B at levels 1 and 2. You would need the following columns: DV_time1_B1, DV_time1_B2, DV_time2_B1, DV_time2_B2. Our task is a bit simpler here, since we only have one within-subjects factor.</p></li>
<li><p>All between-subjects factors should be represented with <strong>grouping variables</strong>, resulting in wide data with one row per participant. In this example, we have a grouping variable called “modality” that specifies the participant’s between-subjects condition. If you have more than one between-subjects factor, you will need additional grouping variables.</p></li>
<li><p>In all, we have data that are in wide format with one row per participant. Note that if you were to use SPSS, this is the format required in SPSS, so it is common.</p></li>
</ul>
<div class="sourceCode" id="cb1003"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1003-1"><a href="statistics-reference.html#cb1003-1" aria-hidden="true" tabindex="-1"></a>RT_t1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">238.37</span>, <span class="fl">249.06</span>, <span class="fl">238.86</span>, <span class="fl">248.76</span>, <span class="fl">239.34</span>, <span class="fl">218.24</span>, <span class="fl">218.34</span>, <span class="fl">229.05</span>, <span class="fl">219.12</span>, <span class="fl">218.42</span>, <span class="fl">258.34</span>, <span class="fl">228.62</span>, <span class="fl">239.31</span>, <span class="fl">259.14</span>, <span class="fl">258.13</span>)</span>
<span id="cb1003-2"><a href="statistics-reference.html#cb1003-2" aria-hidden="true" tabindex="-1"></a>RT_t2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">235.37</span>, <span class="fl">246.06</span>, <span class="fl">235.86</span>, <span class="fl">245.76</span>, <span class="fl">236.34</span>, <span class="fl">258.64</span>, <span class="fl">228.42</span>, <span class="fl">239.51</span>, <span class="fl">259.94</span>, <span class="fl">258.26</span>, <span class="fl">216.24</span>, <span class="fl">216.34</span>, <span class="fl">227.05</span>, <span class="fl">217.12</span>, <span class="fl">216.42</span>)</span>
<span id="cb1003-3"><a href="statistics-reference.html#cb1003-3" aria-hidden="true" tabindex="-1"></a>modality <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">replicate</span>(<span class="dv">5</span>, <span class="st">&quot;auditory&quot;</span>), <span class="fu">replicate</span>(<span class="dv">5</span>, <span class="st">&quot;speech&quot;</span>), <span class="fu">replicate</span>(<span class="dv">5</span>, <span class="st">&quot;visual&quot;</span>))</span>
<span id="cb1003-4"><a href="statistics-reference.html#cb1003-4" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>)</span>
<span id="cb1003-5"><a href="statistics-reference.html#cb1003-5" aria-hidden="true" tabindex="-1"></a>dataframe <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(RT_t1, RT_t2, modality, id)</span>
<span id="cb1003-6"><a href="statistics-reference.html#cb1003-6" aria-hidden="true" tabindex="-1"></a>dataframe</span></code></pre></div>
<pre><code>##     RT_t1  RT_t2 modality id
## 1  238.37 235.37 auditory  1
## 2  249.06 246.06 auditory  2
## 3  238.86 235.86 auditory  3
## 4  248.76 245.76 auditory  4
## 5  239.34 236.34 auditory  5
## 6  218.24 258.64   speech  6
## 7  218.34 228.42   speech  7
## 8  229.05 239.51   speech  8
## 9  219.12 259.94   speech  9
## 10 218.42 258.26   speech 10
## 11 258.34 216.24   visual 11
## 12 228.62 216.34   visual 12
## 13 239.31 227.05   visual 13
## 14 259.14 217.12   visual 14
## 15 258.13 216.42   visual 15</code></pre>
<p>R requires our data in long format, so we will do that conversion first. We will also take this opportunity to properly set our grouping variables and participant ID variable to factors so that R treats them as categories.</p>
<div class="sourceCode" id="cb1005"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1005-1"><a href="statistics-reference.html#cb1005-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;tidyverse&quot;)</span></span>
<span id="cb1005-2"><a href="statistics-reference.html#cb1005-2" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;rstatix&quot;)</span></span>
<span id="cb1005-3"><a href="statistics-reference.html#cb1005-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## Warning in (function (kind = NULL, normal.kind = NULL, sample.kind =
## NULL) : non-uniform &#39;Rounding&#39; sampler used</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────── tidyverse 1.3.1 ──</code></pre>
<pre><code>## ✓ tibble  3.1.4     ✓ dplyr   1.0.7
## ✓ tidyr   1.1.3     ✓ stringr 1.4.0
## ✓ readr   2.0.1     ✓ forcats 0.5.1
## ✓ purrr   0.3.4</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────── tidyverse_conflicts() ──
## x ggplot2::%+%()   masks psych::%+%()
## x ggplot2::alpha() masks psych::alpha()
## x tidyr::extract() masks pastecs::extract()
## x dplyr::filter()  masks stats::filter()
## x dplyr::first()   masks pastecs::first()
## x dplyr::lag()     masks stats::lag()
## x dplyr::last()    masks pastecs::last()
## x dplyr::recode()  masks car::recode()
## x dplyr::select()  masks MASS::select()
## x purrr::some()    masks car::some()</code></pre>
<div class="sourceCode" id="cb1010"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1010-1"><a href="statistics-reference.html#cb1010-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rstatix)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;rstatix&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:MASS&#39;:
## 
##     select</code></pre>
<pre><code>## The following object is masked from &#39;package:stats&#39;:
## 
##     filter</code></pre>
<div class="sourceCode" id="cb1014"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1014-1"><a href="statistics-reference.html#cb1014-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use gather() to convert data to long format</span></span>
<span id="cb1014-2"><a href="statistics-reference.html#cb1014-2" aria-hidden="true" tabindex="-1"></a>longdata <span class="ot">&lt;-</span> <span class="fu">gather</span>(dataframe, <span class="at">key =</span> <span class="st">&quot;time&quot;</span>, <span class="at">value =</span> <span class="st">&quot;RT&quot;</span>, RT_t1, RT_t2)</span>
<span id="cb1014-3"><a href="statistics-reference.html#cb1014-3" aria-hidden="true" tabindex="-1"></a>longdata</span></code></pre></div>
<pre><code>##    modality id  time     RT
## 1  auditory  1 RT_t1 238.37
## 2  auditory  2 RT_t1 249.06
## 3  auditory  3 RT_t1 238.86
## 4  auditory  4 RT_t1 248.76
## 5  auditory  5 RT_t1 239.34
## 6    speech  6 RT_t1 218.24
## 7    speech  7 RT_t1 218.34
## 8    speech  8 RT_t1 229.05
## 9    speech  9 RT_t1 219.12
## 10   speech 10 RT_t1 218.42
## 11   visual 11 RT_t1 258.34
## 12   visual 12 RT_t1 228.62
## 13   visual 13 RT_t1 239.31
## 14   visual 14 RT_t1 259.14
## 15   visual 15 RT_t1 258.13
## 16 auditory  1 RT_t2 235.37
## 17 auditory  2 RT_t2 246.06
## 18 auditory  3 RT_t2 235.86
## 19 auditory  4 RT_t2 245.76
## 20 auditory  5 RT_t2 236.34
## 21   speech  6 RT_t2 258.64
## 22   speech  7 RT_t2 228.42
## 23   speech  8 RT_t2 239.51
## 24   speech  9 RT_t2 259.94
## 25   speech 10 RT_t2 258.26
## 26   visual 11 RT_t2 216.24
## 27   visual 12 RT_t2 216.34
## 28   visual 13 RT_t2 227.05
## 29   visual 14 RT_t2 217.12
## 30   visual 15 RT_t2 216.42</code></pre>
<div class="sourceCode" id="cb1016"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1016-1"><a href="statistics-reference.html#cb1016-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Tell R that ID and time are factors</span></span>
<span id="cb1016-2"><a href="statistics-reference.html#cb1016-2" aria-hidden="true" tabindex="-1"></a>longdata <span class="ot">&lt;-</span> <span class="fu">convert_as_factor</span>(<span class="at">data =</span> longdata, <span class="at">vars =</span> <span class="fu">c</span>(<span class="st">&quot;id&quot;</span>, <span class="st">&quot;time&quot;</span>, <span class="st">&quot;modality&quot;</span>))</span>
<span id="cb1016-3"><a href="statistics-reference.html#cb1016-3" aria-hidden="true" tabindex="-1"></a><span class="fu">is.factor</span>(longdata<span class="sc">$</span>time)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb1018"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1018-1"><a href="statistics-reference.html#cb1018-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.factor</span>(longdata<span class="sc">$</span>id)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb1020"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1020-1"><a href="statistics-reference.html#cb1020-1" aria-hidden="true" tabindex="-1"></a><span class="fu">is.factor</span>(longdata<span class="sc">$</span>modality)</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<p>With that out of the way, we can now use our dataframe, <code>longdata</code>. First, we will descriptively look at the group means:</p>
<div class="sourceCode" id="cb1022"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1022-1"><a href="statistics-reference.html#cb1022-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show descriptive stats for each main effect and for the intneraction cells</span></span>
<span id="cb1022-2"><a href="statistics-reference.html#cb1022-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pastecs)</span>
<span id="cb1022-3"><a href="statistics-reference.html#cb1022-3" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>modality, stat.desc) <span class="co"># break by levels of modality</span></span></code></pre></div>
<pre><code>## longdata$modality: auditory
##      nbr.val     nbr.null       nbr.na          min          max 
## 1.000000e+01 0.000000e+00 0.000000e+00 2.353700e+02 2.490600e+02 
##        range          sum       median         mean      SE.mean 
## 1.369000e+01 2.413780e+03 2.391000e+02 2.413780e+02 1.719489e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 3.889754e+00 2.956642e+01 5.437501e+00 2.252691e-02 
## -------------------------------------------------------- 
## longdata$modality: speech
##      nbr.val     nbr.null       nbr.na          min          max 
## 1.000000e+01 0.000000e+00 0.000000e+00 2.182400e+02 2.599400e+02 
##        range          sum       median         mean      SE.mean 
## 4.170000e+01 2.347940e+03 2.287350e+02 2.347940e+02 5.682350e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 1.285437e+01 3.228910e+02 1.796917e+01 7.653164e-02 
## -------------------------------------------------------- 
## longdata$modality: visual
##      nbr.val     nbr.null       nbr.na          min          max 
## 1.000000e+01 0.000000e+00 0.000000e+00 2.162400e+02 2.591400e+02 
##        range          sum       median         mean      SE.mean 
## 4.290000e+01 2.336710e+03 2.278350e+02 2.336710e+02 5.899488e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 1.334557e+01 3.480396e+02 1.865582e+01 7.983798e-02</code></pre>
<div class="sourceCode" id="cb1024"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1024-1"><a href="statistics-reference.html#cb1024-1" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>time, stat.desc) <span class="co"># break by levels of time</span></span></code></pre></div>
<pre><code>## longdata$time: RT_t1
##      nbr.val     nbr.null       nbr.na          min          max 
##    15.000000     0.000000     0.000000   218.240000   259.140000 
##        range          sum       median         mean      SE.mean 
##    40.900000  3561.100000   238.860000   237.406667     3.896232 
## CI.mean.0.95          var      std.dev     coef.var 
##     8.356587   227.709410    15.090043     0.063562 
## -------------------------------------------------------- 
## longdata$time: RT_t2
##      nbr.val     nbr.null       nbr.na          min          max 
## 1.500000e+01 0.000000e+00 0.000000e+00 2.162400e+02 2.599400e+02 
##        range          sum       median         mean      SE.mean 
## 4.370000e+01 3.537330e+03 2.358600e+02 2.358220e+02 4.049928e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 8.686231e+00 2.460287e+02 1.568530e+01 6.651331e-02</code></pre>
<div class="sourceCode" id="cb1026"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1026-1"><a href="statistics-reference.html#cb1026-1" aria-hidden="true" tabindex="-1"></a><span class="fu">by</span>(longdata<span class="sc">$</span>RT, <span class="fu">interaction</span>(longdata<span class="sc">$</span>time, longdata<span class="sc">$</span>modality), stat.desc) <span class="co"># interaction cells (all combinations of modality and time)</span></span></code></pre></div>
<pre><code>## interaction(longdata$time, longdata$modality): RT_t1.auditory
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.383700e+02 2.490600e+02 
##        range          sum       median         mean      SE.mean 
## 1.069000e+01 1.214390e+03 2.393400e+02 2.428780e+02 2.467781e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 6.851659e+00 3.044972e+01 5.518126e+00 2.271975e-02 
## -------------------------------------------------------- 
## interaction(longdata$time, longdata$modality): RT_t2.auditory
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.353700e+02 2.460600e+02 
##        range          sum       median         mean      SE.mean 
## 1.069000e+01 1.199390e+03 2.363400e+02 2.398780e+02 2.467781e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 6.851659e+00 3.044972e+01 5.518126e+00 2.300389e-02 
## -------------------------------------------------------- 
## interaction(longdata$time, longdata$modality): RT_t1.speech
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.182400e+02 2.290500e+02 
##        range          sum       median         mean      SE.mean 
## 1.081000e+01 1.103170e+03 2.184200e+02 2.206340e+02 2.109700e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 5.857467e+00 2.225418e+01 4.717434e+00 2.138126e-02 
## -------------------------------------------------------- 
## interaction(longdata$time, longdata$modality): RT_t2.speech
##      nbr.val     nbr.null       nbr.na          min          max 
##    5.0000000    0.0000000    0.0000000  228.4200000  259.9400000 
##        range          sum       median         mean      SE.mean 
##   31.5200000 1244.7700000  258.2600000  248.9540000    6.3716039 
## CI.mean.0.95          var      std.dev     coef.var 
##   17.6904084  202.9866800   14.2473394    0.0572288 
## -------------------------------------------------------- 
## interaction(longdata$time, longdata$modality): RT_t1.visual
##      nbr.val     nbr.null       nbr.na          min          max 
##    5.0000000    0.0000000    0.0000000  228.6200000  259.1400000 
##        range          sum       median         mean      SE.mean 
##   30.5200000 1243.5400000  258.1300000  248.7080000    6.2539039 
## CI.mean.0.95          var      std.dev     coef.var 
##   17.3636209  195.5565700   13.9841542    0.0562272 
## -------------------------------------------------------- 
## interaction(longdata$time, longdata$modality): RT_t2.visual
##      nbr.val     nbr.null       nbr.na          min          max 
## 5.000000e+00 0.000000e+00 0.000000e+00 2.162400e+02 2.270500e+02 
##        range          sum       median         mean      SE.mean 
## 1.081000e+01 1.093170e+03 2.164200e+02 2.186340e+02 2.109700e+00 
## CI.mean.0.95          var      std.dev     coef.var 
## 5.857467e+00 2.225418e+01 4.717434e+00 2.157685e-02</code></pre>
<p>And, we can create graphs of the means. Several versions of the graph are generated below to demonstrate options for customization.</p>
<div class="sourceCode" id="cb1028"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1028-1"><a href="statistics-reference.html#cb1028-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the means of each cell with error bars</span></span>
<span id="cb1028-2"><a href="statistics-reference.html#cb1028-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1028-3"><a href="statistics-reference.html#cb1028-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(longdata, <span class="fu">aes</span>(modality, RT, <span class="at">color=</span>time)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun =</span> mean, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">&quot;errorbar&quot;</span>, <span class="at">width=</span> <span class="fl">0.2</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>)</span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/anovavisC1-1.png" width="672" /></p>
<div class="sourceCode" id="cb1029"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1029-1"><a href="statistics-reference.html#cb1029-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change the colors</span></span>
<span id="cb1029-2"><a href="statistics-reference.html#cb1029-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(longdata, <span class="fu">aes</span>(modality, RT, <span class="at">color=</span>time)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun =</span> mean, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">&quot;errorbar&quot;</span>, <span class="at">width=</span> <span class="fl">0.2</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>) <span class="sc">+</span> <span class="fu">scale_color_manual</span>(<span class="at">values=</span><span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>))  <span class="co"># Note that green is not needed because there are only two levels of time</span></span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/anovavisC1-2.png" width="672" /></p>
<div class="sourceCode" id="cb1030"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1030-1"><a href="statistics-reference.html#cb1030-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create greyscale plots in the classic style</span></span>
<span id="cb1030-2"><a href="statistics-reference.html#cb1030-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(longdata, <span class="fu">aes</span>(modality, RT, <span class="at">color=</span>time)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun =</span> mean, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">&quot;errorbar&quot;</span>, <span class="at">width=</span> <span class="fl">0.2</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>) <span class="sc">+</span> <span class="fu">scale_color_grey</span>() <span class="sc">+</span> <span class="fu">theme_classic</span>() </span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/anovavisC1-3.png" width="672" /></p>
<div class="sourceCode" id="cb1031"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1031-1"><a href="statistics-reference.html#cb1031-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Represent a factor across separate graphs using faceting</span></span>
<span id="cb1031-2"><a href="statistics-reference.html#cb1031-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(longdata, <span class="fu">aes</span>(modality, RT)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun =</span> mean, <span class="at">geom =</span> <span class="st">&quot;point&quot;</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">stat_summary</span>(<span class="at">fun.data =</span> mean_cl_normal, <span class="at">geom =</span> <span class="st">&quot;errorbar&quot;</span>, <span class="at">width=</span> <span class="fl">0.2</span>, <span class="at">position=</span><span class="fu">position_dodge</span>(<span class="dv">1</span>)) <span class="sc">+</span> <span class="fu">labs</span>(<span class="at">x =</span><span class="st">&quot;Condition&quot;</span>, <span class="at">y=</span><span class="st">&quot;Outcome&quot;</span>) <span class="sc">+</span> <span class="fu">facet_wrap</span>(<span class="sc">~</span>time) </span></code></pre></div>
<p><img src="schuster-statistics-remix_files/figure-html/anovavisC1-4.png" width="672" /></p>
<p>A visual interpretation of this graph suggests that visual had the fastest reaction time at both time1 and time2, followed by auditory, and then speech. Are these significantly different from each other? We need to run the ANOVA to find out. Is there an interaction? Meaning, is there a difference in the pattern of means between time1 and time2? We need to test the interaction effect to find out. Visually, the patterns look a bit different; visual reaction time is faster at time 2, for example.</p>
</div>
<div id="hypotheses-9" class="section level4" number="13.8.6.2">
<h4><span class="header-section-number">13.8.6.2</span> Hypotheses</h4>
<p>You need a set of hypotheses for each factor and one for the interaction. Note that the number of means depends on the number of levels for each factor.</p>
<p>For “factor A”:</p>
<p><span class="math inline">\(H_0:\mu_{auditory}=\mu_{speech}=\mu_{visual}\)</span></p>
<p><span class="math inline">\(H_a:H_0\text{ is false}\)</span></p>
<p>For “factor B”:</p>
<p><span class="math inline">\(H_0:\mu_{time1}=\mu_{time2}\)</span></p>
<p><span class="math inline">\(H_a:H_0\text{ is false}\)</span></p>
<p>For the interaction:</p>
<p><span class="math inline">\(H_0:\text{there is no interaction between modality and time}\)</span></p>
<p><span class="math inline">\(H_a:H_0\text{ is false}\)</span></p>
</div>
<div id="assumption-checking" class="section level4" number="13.8.6.3">
<h4><span class="header-section-number">13.8.6.3</span> Assumption Checking</h4>
<p>Levene’s test for homogeneity needs to be done for the between-subjects factor.</p>
<p>Note that the <a href="https://search.r-project.org/CRAN/refmans/DescTools/html/LeveneTest.html">default syntax</a> of Levene’s test uses <code>center = median</code>, so it is technically the Brown-Forsythe-Test. Using <code>center = mean</code> is the original Levene’s test.</p>
<div class="sourceCode" id="cb1032"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1032-1"><a href="statistics-reference.html#cb1032-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span>
<span id="cb1032-2"><a href="statistics-reference.html#cb1032-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1032-3"><a href="statistics-reference.html#cb1032-3" aria-hidden="true" tabindex="-1"></a><span class="fu">leveneTest</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>modality, <span class="at">center =</span> median) <span class="co"># Levene&#39;s for the between-subjects factor, modality</span></span></code></pre></div>
<pre><code>## Levene&#39;s Test for Homogeneity of Variance (center = median)
##       Df F value  Pr(&gt;F)  
## group  2  3.6939 0.03819 *
##       27                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Levene’s test is significant here, so we have violated the assumption of homogeneity of variance. But, because our sample sizes are equal, we will continue with this example.</p>
<p>Sphericity would need to be diagnosed for the within-subjects factor, but in this case, there are only two levels (time1 and time2). Therefore, sphericity does not apply. If it did, we would check it in the default ANOVA output.</p>
</div>
<div id="analysis-8" class="section level4" number="13.8.6.4">
<h4><span class="header-section-number">13.8.6.4</span> Analysis</h4>
<p>We need three omnibus tests here: the interaction effect, the main effect of modality, and the main effect of time. We will start with the first omnibus test, which is a test of the interaction effect.</p>
<p>An alpha level of <span class="math inline">\(\alpha = .05\)</span> will be used.</p>
<p>We are using ezANOVA() in the ez package.</p>
<div class="sourceCode" id="cb1034"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1034-1"><a href="statistics-reference.html#cb1034-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;ez&quot;) # you may need to install the ez package</span></span>
<span id="cb1034-2"><a href="statistics-reference.html#cb1034-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ez)</span>
<span id="cb1034-3"><a href="statistics-reference.html#cb1034-3" aria-hidden="true" tabindex="-1"></a>mixedANOVAmodel <span class="ot">&lt;-</span> <span class="fu">ezANOVA</span>(<span class="at">data =</span> longdata, <span class="at">dv =</span> .(RT), <span class="at">wid =</span> .(id), <span class="at">within =</span> .(time), <span class="at">between =</span> .(modality), <span class="at">type =</span> <span class="dv">3</span>)</span>
<span id="cb1034-4"><a href="statistics-reference.html#cb1034-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1034-5"><a href="statistics-reference.html#cb1034-5" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(mixedANOVAmodel)</span></code></pre></div>
<pre><code>## $ANOVA
##          Effect DFn DFd          F            p p&lt;.05         ges
## 2      modality   2  12  2.2031501 1.531170e-01       0.146748695
## 3          time   1  12  0.2108988 6.542716e-01       0.009256567
## 4 modality:time   2  12 23.9066189 6.520841e-05     * 0.679300094</code></pre>
<p>ezANOVA gives us all three of our omnibus tests in one step. In this case, only the interaction effect is statistically significant.</p>
<div id="omnibus-and-simple-effects-for-the-interaction" class="section level5" number="13.8.6.4.1">
<h5><span class="header-section-number">13.8.6.4.1</span> Omnibus and Simple Effects for the Interaction</h5>
<p>We will start the reporting of our results with the omnibus test for the interaction:</p>
<p>There was a significant interaction effect for modality and time, <span class="math inline">\(F\)</span>(2, 12) = 23.90, <span class="math inline">\(p\)</span> &lt; .001, <span class="math inline">\(\eta^2_G\)</span> = .679. We can conclude that the effect of time depends on modality.</p>
<p>Next, we need post-hoc tests done in a specific way, called <strong>tests of simple effects</strong> (also called <strong>simple main effects</strong>, which means the same thing). Simple effects are the comparison of two cells in the interaction. These cells must vary in only one variable. For example, the comparison of visual at time 1 to visual at time 2 is a simple effect. The comparison of visual at time 1 to auditor at time 2 is another simple effect. Compairing visual at time 1 to auditory at time 2 is <em>not</em> a valid simple effect, because both variables are changing across the comparison. Except that we are looking at simple effects, the multiple comparisons options and procedure is the same.</p>
<p>The approach to multiple comparisons is the same for each effect. We are introducing a new operator, <code>%&gt;%</code>, called the <a href="https://www.datacamp.com/community/tutorials/pipe-r-tutorial">pipe operator</a>. It is an alternative syntax style for passing one function to another. So far, we have been largely storing the results of our functions in new variables and then using those variables as arguments in other functions. With the pipe operator, we do the same thing in one line of code. When you see the pipe operator, you could read it as “pass this result to…”</p>
<div class="sourceCode" id="cb1036"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1036-1"><a href="statistics-reference.html#cb1036-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1036-2"><a href="statistics-reference.html#cb1036-2" aria-hidden="true" tabindex="-1"></a>simpleeffects <span class="ot">&lt;-</span> longdata <span class="sc">%&gt;%</span></span>
<span id="cb1036-3"><a href="statistics-reference.html#cb1036-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(time) <span class="sc">%&gt;%</span></span>
<span id="cb1036-4"><a href="statistics-reference.html#cb1036-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pairwise_t_test</span>(RT <span class="sc">~</span> modality, <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span>
<span id="cb1036-5"><a href="statistics-reference.html#cb1036-5" aria-hidden="true" tabindex="-1"></a>simpleeffects</span></code></pre></div>
<pre><code>## # A tibble: 6 × 10
##   time  .y.   group1   group2    n1    n2        p p.signif    p.adj
## * &lt;fct&gt; &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;int&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;
## 1 RT_t1 RT    auditory speech     5     5 0.00224  **       0.00673 
## 2 RT_t1 RT    auditory visual     5     5 0.331    ns       0.993   
## 3 RT_t1 RT    speech   visual     5     5 0.000379 ***      0.00114 
## 4 RT_t2 RT    auditory speech     5     5 0.146    ns       0.438   
## 5 RT_t2 RT    auditory visual     5     5 0.0034   **       0.0102  
## 6 RT_t2 RT    speech   visual     5     5 0.000225 ***      0.000674
## # … with 1 more variable: p.adj.signif &lt;chr&gt;</code></pre>
<p>The analysis of simple effects, with a Bonferroni adjustment for Type I error, showed a significant difference between auditory (<span class="math inline">\(M\)</span> = 242.87, <span class="math inline">\(SD\)</span> = 5.52) and speech (<span class="math inline">\(M\)</span> = 220.63, <span class="math inline">\(SD\)</span> = 4.72) at time 1, and between visual (<span class="math inline">\(M\)</span> = 248.71, <span class="math inline">\(SD\)</span> = 13.98) and speech at time 1. At time 2, the pattern was different, with a significant difference between auditory (<span class="math inline">\(M\)</span> = 242.87, <span class="math inline">\(SD\)</span> = 5.52) and visual (<span class="math inline">\(M\)</span> = 218.63, <span class="math inline">\(SD\)</span> = 4.72) and a significant difference between visual and speech (<span class="math inline">\(M\)</span> = 248.95, <span class="math inline">\(SD\)</span> = 14.25).</p>
</div>
<div id="omnibus-main-effect-of-time" class="section level5" number="13.8.6.4.2">
<h5><span class="header-section-number">13.8.6.4.2</span> Omnibus main effect of Time</h5>
<p>There was not a significant main effect for time, <span class="math inline">\(F\)</span>(1, 12) = 0.21, <span class="math inline">\(p\)</span> = .654, <span class="math inline">\(\eta^2_G\)</span> = .009. We can make no conclusions about the effects of time collapsing across modality.</p>
<p>If there had been a significant effect for time, we would not have needed post-hoc testing with only two conditions. We could have simply interpreted the means.</p>
</div>
<div id="omnibus-main-effect-of-modality-including-post-hoc-tests" class="section level5" number="13.8.6.4.3">
<h5><span class="header-section-number">13.8.6.4.3</span> Omnibus main effect of Modality including post-hoc tests</h5>
<p>There was not a significant main effect for modality, <span class="math inline">\(F\)</span>(2, 12) = 2.203, <span class="math inline">\(p\)</span> = .153, <span class="math inline">\(\eta^2_G\)</span> = .147. We can make no conclusions about the effects of modality collapsing across levels of time.</p>
<p>If there had been a significant effect for modality, we would have needed post-hoc testing. <strong>This effect was not significant so we stop here</strong>, but to show you how to do post-hoc testing, I am going to include the code.</p>
<div class="sourceCode" id="cb1038"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1038-1"><a href="statistics-reference.html#cb1038-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pairwise.t.test</span>(longdata<span class="sc">$</span>RT, longdata<span class="sc">$</span>modality, <span class="at">paired =</span> <span class="cn">FALSE</span>, <span class="at">p.adjust.method =</span> <span class="st">&quot;bonferroni&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  longdata$RT and longdata$modality 
## 
##        auditory speech
## speech 1.00     -     
## visual 0.81     1.00  
## 
## P value adjustment method: bonferroni</code></pre>
<p>Notice that we used the same pairwise.t.test() function we have always used. When testing a main effect like this, we are ignoring the imapct of the other factor. For this reason, we omit mention of the time factor alltogether.</p>
</div>
</div>
<div id="effect-size-6" class="section level4" number="13.8.6.5">
<h4><span class="header-section-number">13.8.6.5</span> Effect Size</h4>
<p>Eta squared (<span class="math inline">\(\eta^2\)</span>) is the measure of effect size for each omnibus effect.</p>
<p>However, eta squared in an interaction would include variance for other effects in the denominator. Eta squared gets smaller when other factors and/or the interaction effect are significant, so we use a new measure of effect size, <strong>partial eta squared</strong> (<span class="math inline">\(\eta^2_{p}\)</span>). Partial eta squared is calculated as follows:</p>
<p><span class="math inline">\(\eta^2_{p} = \frac{\mbox{SS}_{effect}}{\mbox{SS}_{effect} + \mbox{SS}_{within}}\)</span></p>
<p>Therefore, partial eta squared is an estimate of the effect size for one effect on its own. This is a better measure to report in most factorial models.</p>
<p>Generalized eta squared is the same as partial eta squared for between-subjects factors, but it is not the same in the presence of a within-subjects factor. Unfortunately, the methods I am finding to calculate partial eta squared using ezANOVA are very cumbersome. For the time being, I would recommend reporting generalized eta squared from the ezANOVA procedure while recognizing its limitations.</p>
<p>Finally, you should be aware that eta squared is a biased estimator of effect size. While I still recommend reporting eta squared if only by convention, there are other measures of effect size. Omega squared (<span class="math inline">\(\omega^2\)</span>) works like adjusted <span class="math inline">\(R^2\)</span> to estimate population effect size by correcting for this bias.</p>
</div>
<div id="power-analysis-4" class="section level4" number="13.8.6.6">
<h4><span class="header-section-number">13.8.6.6</span> Power Analysis</h4>
<p>In G*Power, select the F tests family, and then choose “ANOVA: Special effects and interactions.”</p>
<p>There is no calculation for all the pieces at once. Instead, power is calculated once for each effect and once for the interaction. One strategy is to calculate power for each effect and then plan for the largest sample size to ensure all effects are sufficiently powered (I believe this will always be the highest order interaction).</p>
<p>You will need to enter the degrees of freedom. Here is how you calculate it:</p>
<ul>
<li><p>The df for a factor is <span class="math inline">\(k - 1\)</span>, where <span class="math inline">\(k\)</span> is the number of levels of that factor.</p></li>
<li><p>The df for an interaction effect is <span class="math inline">\((k_1-1)(k_2-1)(k_n-1)\)</span>, where <span class="math inline">\(k_n\)</span> is the number of levels of factor number <span class="math inline">\(n\)</span>. You’ll need one of those terms for each factor. This example has three terms for three factors.</p></li>
<li><p>The number of groups is the number of cells in the model. A 2 x 2 ANOVA would have 4 cells. A 3 x 2 x 3 ANOVA would have 18 cells.</p></li>
</ul>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
Akaike, H. 1974. <span>“A New Look at the Statistical Model Identification.”</span> <em>IEEE Transactions on Automatic Control</em> 19: 716–23.
</div>
<div class="csl-entry">
Anscombe, F. J. 1973. <span>“Graphs in Statistical Analysis.”</span> <em>American Statistician</em> 27: 17–21.
</div>
<div class="csl-entry">
Assocation, American Psychological. 2020. <em>Publication Manual of the American Psychological Assocation</em>. 7th ed.
</div>
<div class="csl-entry">
Bickel, P. J., E. A. Hammel, and J. W. O’Connell. 1975. <span>“Sex Bias in Graduate Admissions: Data from <span>B</span>erkeley.”</span> <em>Science</em> 187: 398–404.
</div>
<div class="csl-entry">
Box, J. F. 1987. <span>“Guinness, Gosset, Fisher, and Small Samples.”</span> <em>Statistical Science</em> 2: 45–52.
</div>
<div class="csl-entry">
Brown, M. B., and A. B. Forsythe. 1974. <span>“Robust Tests for Equality of Variances.”</span> <em>Journal of the American Statistical Association</em> 69: 364–67.
</div>
<div class="csl-entry">
Campbell, D. T., and J. C. Stanley. 1963. <em>Experimental and Quasi-Experimental Designs for Research</em>. Boston, MA: Houghton Mifflin.
</div>
<div class="csl-entry">
Cohen, Barry H. 2013. <em>Explaining Psychological Statistics</em>. John Wiley; Sons.
</div>
<div class="csl-entry">
Cohen, J. 1988. <em>Statistical Power Analysis for the Behavioral Sciences</em>. 2nd ed. Lawrence Erlbaum.
</div>
<div class="csl-entry">
Cook, R. D., and S. Weisberg. 1983. <span>“Diagnostics for Heteroscedasticity in Regression.”</span> <em>Biometrika</em> 70: 1–10.
</div>
<div class="csl-entry">
Cook, Thomas D, Donald Thomas Campbell, and William Shadish. 2002. <em>Experimental and Quasi-Experimental Designs for Generalized Causal Inference</em>. Houghton Mifflin Boston, MA.
</div>
<div class="csl-entry">
Dunn, O. J. 1961. <span>“Multiple Comparisons Among Means.”</span> <em>Journal of the American Statistical Association</em> 56: 52–64.
</div>
<div class="csl-entry">
Ellis, P. D. 2010. <em>The Essential Guide to Effect Sizes: Statistical Power, Meta-Analysis, and the Interpretation of Research Results</em>. Cambridge, UK: Cambridge University Press.
</div>
<div class="csl-entry">
Ellman, Michael. 2002. <span>“Soviet Repression Statistics: Some Comments.”</span> <em>Europe-Asia Studies</em> 54 (7): 1151–72.
</div>
<div class="csl-entry">
Fisher, R. A. 1922. <span>“On the Mathematical Foundation of Theoretical Statistics.”</span> <em>Philosophical Transactions of the Royal Society A</em> 222: 309–68.
</div>
<div class="csl-entry">
Fox, J., and S. Weisberg. 2011. <em>An <span>R</span> Companion to Applied Regression</em>. 2nd ed. Los Angeles: Sage.
</div>
<div class="csl-entry">
Galton, Francis. 1886. <span>“Regression Towards Mediocrity in Hereditary Stature.”</span> <a href="https://doi.org/10.2307/2841583">https://doi.org/10.2307/2841583</a>.
</div>
<div class="csl-entry">
Gelman, A., and H. Stern. 2006. <span>“The Difference Between <span>‘Significant’</span> and <span>‘Not Significant’</span> Is Not Itself Statistically Significant.”</span> <em>The American Statistician</em> 60: 328–31.
</div>
<div class="csl-entry">
Hays, W. L. 1994. <em>Statistics</em>. 5th ed. Fort Worth, TX: Harcourt Brace.
</div>
<div class="csl-entry">
Hedges, L. V. 1981. <span>“Distribution Theory for Glass’s Estimator of Effect Size and Related Estimators.”</span> <em>Journal of Educational Statistics</em> 6: 107–28.
</div>
<div class="csl-entry">
Hedges, L. V., and I. Olkin. 1985. <em>Statistical Methods for Meta-Analysis</em>. New York: Academic Press.
</div>
<div class="csl-entry">
Holm, S. 1979. <span>“A Simple Sequentially Rejective Multiple Test Procedure.”</span> <em>Scandinavian Journal of Statistics</em> 6: 65–70.
</div>
<div class="csl-entry">
Hsu, J. C. 1996. <em>Multiple Comparisons: Theory and Methods</em>. London, UK: Chapman; Hall.
</div>
<div class="csl-entry">
Keynes, John Maynard. 1923. <em>A Tract on Monetary Reform</em>. London: Macmillan; Company.
</div>
<div class="csl-entry">
Kozma, A., and M. J. Stones. 1983. <span>“Predictors of Happiness.”</span> <em>Journal of Gerentology</em> 38. <a href="https://doi.org/10.1093/geronj/38.5.626">https://doi.org/10.1093/geronj/38.5.626</a>.
</div>
<div class="csl-entry">
Kruskal, W. H., and W. A. Wallis. 1952. <span>“Use of Ranks in One-Criterion Variance Analysis.”</span> <em>Journal of the American Statistical Association</em> 47: 583–621.
</div>
<div class="csl-entry">
Lehmann, Erich L. 2011. <em>Fisher, <span>N</span>eyman, and the Creation of Classical Statistics</em>. Springer.
</div>
<div class="csl-entry">
Levene, H. 1960. <span>“Robust Tests for Equality of Variances.”</span> In <em>Contributions to Probability and Statistics: Essays in Honor of Harold Hotelling</em>, edited by I. Olkin et al, 278–92. Palo Alto, CA: Stanford University Press.
</div>
<div class="csl-entry">
Long, J. S., and L. H. Ervin. 2000. <span>“Using Heteroscedasticity Consistent Standard Errors in Thee Linear Regression Model.”</span> <em>The American Statistician</em> 54: 217–24.
</div>
<div class="csl-entry">
McGrath, R. E., and G. J. Meyer. 2006. <span>“When Effect Sizes Disagree: The Case of <span class="math inline">\(r\)</span> and <span class="math inline">\(d\)</span>.”</span> <em>Psychological Methods</em> 11: 386–401.
</div>
<div class="csl-entry">
Meehl, P. H. 1967. <span>“Theory Testing in Psychology and Physics: A Methodological Paradox.”</span> <em>Philosophy of Science</em> 34: 103–15.
</div>
<div class="csl-entry">
Navarro, D. 2018. <em>Learning Statistics with r: A Tutorial for Psychology Students and Other Beginners (Version 0.6)</em>. <a href="https://learningstatisticswithr.com">https://learningstatisticswithr.com</a>.
</div>
<div class="csl-entry">
R Core Team. 2013. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing.
</div>
<div class="csl-entry">
Sahai, H., and M. I. Ageel. 2000. <em>The Analysis of Variance: Fixed, Random and Mixed Models</em>. Boston: Birkhauser.
</div>
<div class="csl-entry">
Shaffer, J. P. 1995. <span>“Multiple Hypothesis Testing.”</span> <em>Annual Review of Psychology</em> 46: 561–84.
</div>
<div class="csl-entry">
Shapiro, S. S., and M. B. Wilk. 1965. <span>“An Analysis of Variance Test for Normality (Complete Samples).”</span> <em>Biometrika</em> 52: 591–611.
</div>
<div class="csl-entry">
Stevens, S. S. 1946. <span>“On the Theory of Scales of Measurement.”</span> <em>Science</em> 103: 677–80.
</div>
<div class="csl-entry">
Stigler, S. M. 1986. <em>The History of Statistics</em>. Cambridge, MA: Harvard University Press.
</div>
<div class="csl-entry">
Student, A. 1908. <span>“The Probable Error of a Mean.”</span> <em>Biometrika</em> 6: 1–2.
</div>
<div class="csl-entry">
Welch, B. L. 1947. <span>“The Generalization of <span>‘<span>S</span>tudent’s’</span> Problem When Several Different Population Variances Are Involved.”</span> <em>Biometrika</em> 34: 28–35.
</div>
<div class="csl-entry">
———. 1951. <span>“On the Comparison of Several Mean Values: An Alternative Approach.”</span> <em>Biometrika</em> 38: 330–36.
</div>
<div class="csl-entry">
White, H. 1980. <span>“A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity.”</span> <em>Econometrika</em> 48: 817–38.
</div>
</div>
</div>
</div>
</div>
</div>






































































































































































<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Cohen2013" class="csl-entry">
Cohen, Barry H. 2013. <em>Explaining Psychological Statistics</em>. John Wiley; Sons.
</div>
<div id="ref-Navarro2018" class="csl-entry">
Navarro, D. 2018. <em>Learning Statistics with r: A Tutorial for Psychology Students and Other Beginners (Version 0.6)</em>. <a href="https://learningstatisticswithr.com">https://learningstatisticswithr.com</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="factorial-analysis-of-variance-anova.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/50-statguide.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["schuster-statistics-remix.pdf", "schuster-statistics-remix.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
